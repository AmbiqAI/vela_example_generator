Tensor 'input_1' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/average_pooling2d/AvgPool' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/flatten/Reshape' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/dense/BiasAdd' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'Identity' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.

[ Before Graph Optimisation ]
0     Conv2D               functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
1     Relu                 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
2     DepthwiseConv2D      functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
3     Relu                 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
4     Conv2D               functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
5     Relu                 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
6     DepthwiseConv2D      functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
7     Relu                 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
8     Conv2D               functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
9     Relu                 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
10    DepthwiseConv2D      functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
11    Relu                 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
12    Conv2D               functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
13    Relu                 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
14    DepthwiseConv2D      functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
15    Relu                 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
16    Conv2D               functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
17    Relu                 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
18    AvgPool              functional_1/average_pooling2d/AvgPool
19    Reshape              functional_1/flatten/Reshape  
20    FullyConnected       functional_1/dense/BiasAdd    
21    Softmax              Identity                      


[ After Graph Optimization ]
0     Conv2D               functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
1     Relu                 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
2     DepthwiseConv2D      functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
3     Relu                 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
4     Conv2D               functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
5     Relu                 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
6     DepthwiseConv2D      functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
7     Relu                 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
8     Conv2D               functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
9     Relu                 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
10    DepthwiseConv2D      functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
11    Relu                 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
12    Conv2D               functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
13    Relu                 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
14    DepthwiseConv2D      functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
15    Relu                 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
16    Conv2D               functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
17    Relu                 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
18    AvgPool              functional_1/average_pooling2d/AvgPool
19    FullyConnected       functional_1/dense/BiasAdd    
20    MaxPool              functional_1/dense/BiasAdd/maxpool
21    Sub                  functional_1/dense/BiasAdd/Sub
22    LUT                  functional_1/dense/BiasAdd/Sub/lut
23    Asr                  functional_1/dense/BiasAdd/Sub/lut/Asr
24    ReduceSum            functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
25    CLZ                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
26    Sub                  headroom_offset/Sub           
27    Sub                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ/Sub
28    SHL                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
29    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul
30    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
31    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
32    Sub                  F2_one/Sub                    
33    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
34    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul
35    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
36    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
37    Sub                  F2_one/Sub                    
38    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
39    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul
40    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
41    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
42    Sub                  F2_one/Sub                    
43    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
44    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul
45    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add
46    Mul                  functional_1/dense/BiasAdd/Sub/lut/Mul
47    Asr                  Identity                      


[ Graph With Tensor Quantization ]
0 Conv2D functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
    Input 00 Int8 scale: [(scale:1255639936, shift:31)], zero_point: [83], quantMin: [], quantMax: [], dimension: 0 input_1
    Input 01 Int8 scale: [(scale:1464379008, shift:40), (scale:1627438592, shift:41), (scale:2075258880, shift:42), (scale:1168237824, shift:41), (scale:1974605056, shift:42), (scale:1721740160, shift:41), (scale:1753228160, shift:40), (scale:1488934784, shift:41), (scale:1158502912, shift:41), (scale:1188821888, shift:42), (scale:2093692416, shift:41), (scale:1192383104, shift:41), (scale:1241635712, shift:40), (scale:1341249536, shift:41), (scale:1510890880, shift:41), (scale:1695192704, shift:42), (scale:1737978496, shift:40), (scale:1398920704, shift:42), (scale:1746344320, shift:42), (scale:1183181312, shift:41), (scale:1977891584, shift:42), (scale:2113310208, shift:41), (scale:1867738624, shift:42), (scale:2071492864, shift:40), (scale:1785629696, shift:42), (scale:1601047552, shift:41), (scale:2084708864, shift:42), (scale:1776369664, shift:41), (scale:1110910976, shift:40), (scale:1188599936, shift:40), (scale:1304962560, shift:41), (scale:2105906560, shift:41), (scale:1524456576, shift:41), (scale:1199206144, shift:41), (scale:1698997888, shift:41), (scale:1483576448, shift:41), (scale:1413839616, shift:40), (scale:1961673344, shift:42), (scale:1395400576, shift:42), (scale:1804189824, shift:42), (scale:1684543488, shift:42), (scale:1297103488, shift:41), (scale:1180393728, shift:41), (scale:1112020992, shift:39), (scale:1304851456, shift:40), (scale:1339063296, shift:40), (scale:1462929152, shift:41), (scale:1156472320, shift:41), (scale:1637322240, shift:41), (scale:1713849088, shift:40), (scale:1621298432, shift:41), (scale:1104686080, shift:40), (scale:1114051584, shift:40), (scale:1806657408, shift:42), (scale:1706757760, shift:41), (scale:1979592448, shift:40), (scale:1814144384, shift:42), (scale:1384162944, shift:41), (scale:1765874944, shift:41), (scale:1857623040, shift:42), (scale:1349751680, shift:41), (scale:1080475776, shift:41), (scale:2000449024, shift:41), (scale:1812903424, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/conv2d/Conv2D
    Input 02 Int32 scale: [(scale:1712453376, shift:41), (scale:1903136128, shift:42), (scale:1213409920, shift:42), (scale:1366144128, shift:42), (scale:1154557312, shift:42), (scale:2013412992, shift:42), (scale:2050235264, shift:41), (scale:1741169024, shift:42), (scale:1354760064, shift:42), (scale:1390215296, shift:43), (scale:1224188032, shift:41), (scale:1394379776, shift:42), (scale:1451976064, shift:41), (scale:1568465024, shift:42), (scale:1766844544, shift:42), (scale:1982368256, shift:43), (scale:2032402176, shift:41), (scale:1635906048, shift:43), (scale:2042185216, shift:43), (scale:1383619072, shift:42), (scale:1156478976, shift:42), (scale:1235658624, shift:41), (scale:1092072192, shift:42), (scale:1211207936, shift:40), (scale:2088125696, shift:43), (scale:1872274304, shift:42), (scale:1218935296, shift:42), (scale:2077297024, shift:42), (scale:1299105792, shift:41), (scale:1389955712, shift:41), (scale:1526030848, shift:42), (scale:1231329664, shift:41), (scale:1782708352, shift:42), (scale:1402358656, shift:42), (scale:1986818048, shift:42), (scale:1734902912, shift:42), (scale:1653352320, shift:41), (scale:1146996096, shift:42), (scale:1631789568, shift:43), (scale:2109830016, shift:43), (scale:1969915008, shift:43), (scale:1516840320, shift:42), (scale:1380359296, shift:42), (scale:1300403840, shift:40), (scale:1525900928, shift:41), (scale:1565908352, shift:41), (scale:1710757888, shift:42), (scale:1352385408, shift:42), (scale:1914694144, shift:42), (scale:2004185088, shift:41), (scale:1895955840, shift:42), (scale:1291826304, shift:41), (scale:1302778368, shift:41), (scale:2112715648, shift:43), (scale:1995892480, shift:42), (scale:1157473408, shift:40), (scale:2121470976, shift:43), (scale:1618648192, shift:42), (scale:2065024384, shift:42), (scale:1086157568, shift:42), (scale:1578407424, shift:42), (scale:1263514624, shift:42), (scale:1169668352, shift:41), (scale:2120019840, shift:43)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D
    Output 00 Int8 scale: [(scale:1352492032, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
1 Relu functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
    Input 00 Int8 scale: [(scale:1352492032, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
    Output 00 Int8 scale: [(scale:1352492032, shift:34)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
2 DepthwiseConv2D functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1352492032, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
    Input 01 Int8 scale: [(scale:1175311872, shift:37), (scale:1421834240, shift:38), (scale:1271638528, shift:37), (scale:1767601536, shift:37), (scale:1557757056, shift:37), (scale:1964024960, shift:37), (scale:1340253440, shift:37), (scale:1632174336, shift:38), (scale:1362240512, shift:37), (scale:1455178240, shift:38), (scale:1301060352, shift:37), (scale:1534470784, shift:37), (scale:1505380864, shift:37), (scale:1607027712, shift:37), (scale:2074724736, shift:38), (scale:1142046336, shift:37), (scale:1205169408, shift:37), (scale:1980826496, shift:37), (scale:1788229376, shift:37), (scale:1879952768, shift:37), (scale:2140038912, shift:37), (scale:1967693440, shift:38), (scale:1371067008, shift:36), (scale:1222602752, shift:37), (scale:2044833408, shift:37), (scale:1474644096, shift:38), (scale:1265859456, shift:37), (scale:1932803968, shift:37), (scale:1682347648, shift:37), (scale:1849218560, shift:37), (scale:1137651584, shift:37), (scale:1620537088, shift:38), (scale:1330349056, shift:37), (scale:1458722176, shift:37), (scale:1262768512, shift:37), (scale:1439908864, shift:37), (scale:1143717888, shift:37), (scale:1255351168, shift:38), (scale:1737809280, shift:37), (scale:1521102720, shift:37), (scale:1310250368, shift:36), (scale:1701335296, shift:37), (scale:1126833920, shift:36), (scale:1467101824, shift:37), (scale:1102162304, shift:37), (scale:1211554304, shift:37), (scale:2127924352, shift:38), (scale:1508294144, shift:38), (scale:1134804864, shift:36), (scale:1403477120, shift:37), (scale:1413260928, shift:37), (scale:1539753600, shift:36), (scale:1543505408, shift:37), (scale:2064233344, shift:38), (scale:1818934528, shift:38), (scale:1809568256, shift:38), (scale:1679345920, shift:37), (scale:2092672000, shift:38), (scale:1182935296, shift:36), (scale:1790981376, shift:37), (scale:1380477440, shift:37), (scale:1797254400, shift:38), (scale:1616903808, shift:37), (scale:1895568512, shift:37)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 3 functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource
    Input 02 Int32 scale: [(scale:1480430336, shift:41), (scale:1790951424, shift:42), (scale:1601763968, shift:41), (scale:1113241088, shift:40), (scale:1962160640, shift:41), (scale:1236949120, shift:40), (scale:1688191744, shift:41), (scale:2055897216, shift:42), (scale:1715886848, shift:41), (scale:1832951808, shift:42), (scale:1638823936, shift:41), (scale:1932829184, shift:41), (scale:1896187264, shift:41), (scale:2024222336, shift:41), (scale:1306668288, shift:41), (scale:1438528768, shift:41), (scale:1518039040, shift:41), (scale:1247530880, shift:40), (scale:1126232576, shift:40), (scale:1184000256, shift:40), (scale:1347803264, shift:40), (scale:1239259648, shift:41), (scale:1727004672, shift:40), (scale:1539998208, shift:41), (scale:1287842560, shift:40), (scale:1857471104, shift:42), (scale:1594484608, shift:41), (scale:1217286144, shift:40), (scale:2119095808, shift:41), (scale:1164643712, shift:40), (scale:1432993152, shift:41), (scale:2041238784, shift:42), (scale:1675716096, shift:41), (scale:1837415680, shift:41), (scale:1590591232, shift:41), (scale:1813718400, shift:41), (scale:1440634368, shift:41), (scale:1581248256, shift:42), (scale:1094477824, shift:40), (scale:1915990656, shift:41), (scale:1650399744, shift:40), (scale:2143012736, shift:41), (scale:1419367168, shift:40), (scale:1847970816, shift:41), (scale:1388290688, shift:41), (scale:1526081536, shift:41), (scale:1340173568, shift:41), (scale:1899856896, shift:42), (scale:1429407488, shift:40), (scale:1767828736, shift:41), (scale:1780152448, shift:41), (scale:1939483392, shift:40), (scale:1944209280, shift:41), (scale:1300060672, shift:41), (scale:1145570688, shift:41), (scale:1139671808, shift:41), (scale:2115314816, shift:41), (scale:1317971456, shift:41), (scale:1490032768, shift:40), (scale:1127965824, shift:40), (scale:1738858112, shift:41), (scale:1131916544, shift:41), (scale:2036662272, shift:41), (scale:1193835136, shift:40)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource
    Output 00 Int8 scale: [(scale:1422750976, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
3 Relu functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1422750976, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
    Output 00 Int8 scale: [(scale:1422750976, shift:34)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
4 Conv2D functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
    Input 00 Int8 scale: [(scale:1422750976, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
    Input 01 Int8 scale: [(scale:1270611200, shift:39), (scale:2030643712, shift:39), (scale:1644547200, shift:39), (scale:1274715008, shift:39), (scale:2034716288, shift:39), (scale:1319735296, shift:39), (scale:1097028992, shift:39), (scale:1806930304, shift:39), (scale:1675453184, shift:39), (scale:2144237824, shift:39), (scale:1841686400, shift:39), (scale:1626432000, shift:39), (scale:1143902976, shift:38), (scale:1698825600, shift:39), (scale:1795597696, shift:39), (scale:1543490048, shift:39), (scale:1347438720, shift:39), (scale:1668319104, shift:39), (scale:2038381824, shift:39), (scale:1589206784, shift:39), (scale:1710085504, shift:39), (scale:1645939584, shift:39), (scale:1300315648, shift:38), (scale:1830330496, shift:39), (scale:1526757248, shift:39), (scale:1863892992, shift:39), (scale:1325160448, shift:39), (scale:1427883392, shift:39), (scale:1518774144, shift:39), (scale:1850537472, shift:39), (scale:2038893184, shift:39), (scale:2012493696, shift:39), (scale:1608130816, shift:39), (scale:1479658112, shift:39), (scale:1104901376, shift:38), (scale:1808917120, shift:39), (scale:1817939712, shift:39), (scale:2125389056, shift:39), (scale:2083040256, shift:39), (scale:1571339776, shift:39), (scale:1132971264, shift:38), (scale:2043926656, shift:39), (scale:1689693696, shift:39), (scale:1087454464, shift:38), (scale:1903368448, shift:39), (scale:1731485568, shift:39), (scale:1077008384, shift:39), (scale:1954194944, shift:39), (scale:1262896768, shift:39), (scale:1708360064, shift:39), (scale:1683638400, shift:39), (scale:1548113408, shift:39), (scale:1464501632, shift:39), (scale:2042817536, shift:39), (scale:2064977792, shift:39), (scale:1936098048, shift:39), (scale:1109349504, shift:39), (scale:1603760256, shift:39), (scale:1557180928, shift:39), (scale:1261184000, shift:39), (scale:1872705280, shift:39), (scale:1398821760, shift:39), (scale:1747156736, shift:39), (scale:1785712640, shift:39)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/conv2d_1/Conv2D
    Input 02 Int32 scale: [(scale:1683610752, shift:43), (scale:1345342208, shift:42), (scale:1089545472, shift:42), (scale:1689048448, shift:43), (scale:1348040320, shift:42), (scale:1748702208, shift:43), (scale:1453607424, shift:43), (scale:1197127552, shift:42), (scale:1110021376, shift:42), (scale:1420600576, shift:42), (scale:1220154112, shift:42), (scale:1077543808, shift:42), (scale:1515717376, shift:42), (scale:1125506048, shift:42), (scale:1189619456, shift:42), (scale:2045186176, shift:43), (scale:1785410304, shift:43), (scale:1105294848, shift:42), (scale:1350468864, shift:42), (scale:2105762688, shift:43), (scale:1132965888, shift:42), (scale:1090467968, shift:42), (scale:1722970368, shift:42), (scale:1212630656, shift:42), (scale:2023014528, shift:43), (scale:1234866432, shift:42), (scale:1755890688, shift:43), (scale:1892002816, shift:43), (scale:2012436608, shift:43), (scale:1226018176, shift:42), (scale:1350807680, shift:42), (scale:1333317376, shift:42), (scale:2130837760, shift:43), (scale:1960606336, shift:43), (scale:1464038656, shift:42), (scale:1198443904, shift:42), (scale:1204421504, shift:42), (scale:1408112896, shift:42), (scale:1380055936, shift:42), (scale:2082088192, shift:43), (scale:1501232384, shift:42), (scale:1354142336, shift:42), (scale:1119456000, shift:42), (scale:1440920832, shift:42), (scale:1261019776, shift:42), (scale:1147143936, shift:42), (scale:1427079296, shift:43), (scale:1294693376, shift:42), (scale:1673388800, shift:43), (scale:1131822848, shift:42), (scale:1115444224, shift:42), (scale:2051312384, shift:43), (scale:1940523392, shift:43), (scale:1353407616, shift:42), (scale:1368089216, shift:42), (scale:1282703744, shift:42), (scale:1469932544, shift:43), (scale:2125046656, shift:43), (scale:2063327232, shift:43), (scale:1671119360, shift:43), (scale:1240704768, shift:42), (scale:1853494912, shift:43), (scale:1157526400, shift:42), (scale:1183070464, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D
    Output 00 Int8 scale: [(scale:2062467200, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
5 Relu functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
    Input 00 Int8 scale: [(scale:2062467200, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
    Output 00 Int8 scale: [(scale:2062467200, shift:35)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
6 DepthwiseConv2D functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:2062467200, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
    Input 01 Int8 scale: [(scale:1792217088, shift:38), (scale:1776190720, shift:38), (scale:1770845568, shift:37), (scale:1272406144, shift:37), (scale:1814885248, shift:38), (scale:1965241728, shift:37), (scale:1624973184, shift:38), (scale:1544612480, shift:38), (scale:1698108160, shift:37), (scale:1817450240, shift:38), (scale:2040592768, shift:38), (scale:2053262464, shift:38), (scale:1941416064, shift:38), (scale:1878308864, shift:38), (scale:1215870208, shift:37), (scale:1190906112, shift:37), (scale:2133784704, shift:38), (scale:1085578624, shift:37), (scale:1814735360, shift:38), (scale:1483078016, shift:38), (scale:1287174528, shift:38), (scale:1270013696, shift:36), (scale:1952631296, shift:38), (scale:1834623872, shift:38), (scale:2137792128, shift:38), (scale:1287734656, shift:37), (scale:2137980672, shift:38), (scale:1595241984, shift:38), (scale:1935896320, shift:38), (scale:1157065856, shift:37), (scale:1493662336, shift:38), (scale:1802953344, shift:38), (scale:1137304064, shift:36), (scale:1906626688, shift:38), (scale:1792789248, shift:38), (scale:1535577088, shift:37), (scale:1342918912, shift:38), (scale:1487831552, shift:38), (scale:2146545408, shift:38), (scale:1384833664, shift:38), (scale:1199503360, shift:37), (scale:1423974528, shift:37), (scale:1109840768, shift:37), (scale:1148437888, shift:38), (scale:1714945024, shift:38), (scale:1258835584, shift:37), (scale:1484821760, shift:37), (scale:1762760576, shift:38), (scale:1948180736, shift:38), (scale:1615223296, shift:38), (scale:1544111488, shift:37), (scale:1810116224, shift:37), (scale:1129528320, shift:37), (scale:1880874624, shift:38), (scale:1576878592, shift:38), (scale:1967843072, shift:38), (scale:1340814848, shift:37), (scale:1297278464, shift:37), (scale:1349762944, shift:37), (scale:2047192576, shift:38), (scale:2040242432, shift:38), (scale:2015957760, shift:38), (scale:1827989504, shift:38), (scale:2056193920, shift:38)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 3 functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource
    Input 02 Int32 scale: [(scale:1721265280, shift:42), (scale:1705873280, shift:42), (scale:1700739840, shift:41), (scale:1222033024, shift:41), (scale:1743036032, shift:42), (scale:1887440000, shift:41), (scale:1560642304, shift:42), (scale:1483463040, shift:42), (scale:1630881920, shift:41), (scale:1745499392, shift:42), (scale:1959808000, shift:42), (scale:1971976064, shift:42), (scale:1864557568, shift:42), (scale:1803948800, shift:42), (scale:1167735296, shift:41), (scale:1143759488, shift:41), (scale:2049310592, shift:42), (scale:2085203584, shift:42), (scale:1742892032, shift:42), (scale:1424364672, shift:42), (scale:1236216704, shift:42), (scale:1219735296, shift:40), (scale:1875328896, shift:42), (scale:1761993216, shift:42), (scale:2053159296, shift:42), (scale:1236754688, shift:41), (scale:2053340416, shift:42), (scale:1532088192, shift:42), (scale:1859256320, shift:42), (scale:1111258880, shift:41), (scale:1434529920, shift:42), (scale:1731576448, shift:42), (scale:1092279424, shift:40), (scale:1831145472, shift:42), (scale:1721814784, shift:42), (scale:1474785280, shift:41), (scale:1289754240, shift:42), (scale:1428930048, shift:42), (scale:2061566080, shift:42), (scale:1330009728, shift:42), (scale:1152016384, shift:41), (scale:1367601024, shift:41), (scale:2131806848, shift:42), (scale:1102972544, shift:42), (scale:1647052288, shift:42), (scale:1208999680, shift:41), (scale:1426039296, shift:41), (scale:1692974848, shift:42), (scale:1871054464, shift:42), (scale:1551278464, shift:42), (scale:1482981888, shift:41), (scale:1738455808, shift:41), (scale:1084811520, shift:41), (scale:1806412928, shift:42), (scale:1514451712, shift:42), (scale:1889938432, shift:42), (scale:1287733504, shift:41), (scale:1245920640, shift:41), (scale:1296327296, shift:41), (scale:1966146560, shift:42), (scale:1959471488, shift:42), (scale:1936148224, shift:42), (scale:1755621504, shift:42), (scale:1974791552, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource
    Output 00 Int8 scale: [(scale:1078209024, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
7 Relu functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1078209024, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
    Output 00 Int8 scale: [(scale:1078209024, shift:34)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
8 Conv2D functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
    Input 00 Int8 scale: [(scale:1078209024, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
    Input 01 Int8 scale: [(scale:1612059136, shift:39), (scale:1775348480, shift:39), (scale:1644174208, shift:39), (scale:1761611136, shift:39), (scale:1954601984, shift:39), (scale:1292690944, shift:38), (scale:1128286592, shift:38), (scale:1686442880, shift:39), (scale:1895414912, shift:39), (scale:1503374720, shift:39), (scale:1264453248, shift:38), (scale:1539396992, shift:39), (scale:1422953856, shift:39), (scale:2026836224, shift:39), (scale:1614476672, shift:38), (scale:1475159552, shift:39), (scale:1108204544, shift:38), (scale:1272150016, shift:39), (scale:2097000960, shift:39), (scale:1201109120, shift:39), (scale:1217869696, shift:38), (scale:1302342400, shift:39), (scale:1457591040, shift:39), (scale:1382811776, shift:38), (scale:2041387008, shift:39), (scale:1850732928, shift:39), (scale:1673627776, shift:39), (scale:1730418048, shift:39), (scale:1566262144, shift:39), (scale:1545316608, shift:39), (scale:1586464256, shift:39), (scale:1925055872, shift:39), (scale:1139282432, shift:38), (scale:1972102272, shift:39), (scale:1941824000, shift:39), (scale:1075758592, shift:38), (scale:1547401984, shift:39), (scale:1668819200, shift:39), (scale:1792876032, shift:39), (scale:1926764416, shift:39), (scale:1719825408, shift:39), (scale:2022496000, shift:39), (scale:2003473920, shift:39), (scale:1557260928, shift:39), (scale:2140785664, shift:39), (scale:1805093376, shift:39), (scale:1751383808, shift:39), (scale:1919804800, shift:39), (scale:1348167552, shift:39), (scale:1570661376, shift:39), (scale:1651373440, shift:39), (scale:1701611904, shift:39), (scale:1920178944, shift:39), (scale:1074890112, shift:38), (scale:1531035008, shift:39), (scale:1860359168, shift:39), (scale:1651859840, shift:39), (scale:1482249856, shift:39), (scale:1822327552, shift:39), (scale:2091655936, shift:39), (scale:1734109440, shift:39), (scale:1922042880, shift:39), (scale:1608719744, shift:39), (scale:1604003584, shift:39)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/conv2d_2/Conv2D
    Input 02 Int32 scale: [(scale:1618765952, shift:43), (scale:1782734592, shift:43), (scale:1651014656, shift:43), (scale:1768940160, shift:43), (scale:1962733952, shift:43), (scale:1298069120, shift:42), (scale:1132980736, shift:42), (scale:1693459200, shift:43), (scale:1903300608, shift:43), (scale:1509629312, shift:43), (scale:1269713920, shift:42), (scale:1545801472, shift:43), (scale:1428873856, shift:43), (scale:2035268736, shift:43), (scale:1621193600, shift:42), (scale:1481296768, shift:43), (scale:1112815104, shift:42), (scale:1277442688, shift:43), (scale:2105725312, shift:43), (scale:1206106240, shift:43), (scale:1222936576, shift:42), (scale:1307760640, shift:43), (scale:1463655168, shift:43), (scale:1388564864, shift:42), (scale:2049880064, shift:43), (scale:1858432768, shift:43), (scale:1680590720, shift:43), (scale:1737617280, shift:43), (scale:1572778368, shift:43), (scale:1551745792, shift:43), (scale:1593064576, shift:43), (scale:1933064832, shift:43), (scale:1144022272, shift:42), (scale:1980307072, shift:43), (scale:1949902720, shift:43), (scale:1080234240, shift:42), (scale:1553839744, shift:43), (scale:1675762176, shift:43), (scale:1800335104, shift:43), (scale:1934780544, shift:43), (scale:1726980608, shift:43), (scale:2030910464, shift:43), (scale:2011809152, shift:43), (scale:1563739776, shift:43), (scale:1074846080, shift:42), (scale:1812603264, shift:43), (scale:1758670336, shift:43), (scale:1927792000, shift:43), (scale:1353776512, shift:43), (scale:1577195904, shift:43), (scale:1658243840, shift:43), (scale:1708691328, shift:43), (scale:1928167680, shift:43), (scale:1079362048, shift:42), (scale:1537404672, shift:43), (scale:1868099072, shift:43), (scale:1658732288, shift:43), (scale:1488416640, shift:43), (scale:1829909120, shift:43), (scale:2100358016, shift:43), (scale:1741324032, shift:43), (scale:1930039296, shift:43), (scale:1615412608, shift:43), (scale:1610676864, shift:43)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D
    Output 00 Int8 scale: [(scale:1285115648, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
9 Relu functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
    Input 00 Int8 scale: [(scale:1285115648, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
    Output 00 Int8 scale: [(scale:1285115648, shift:35)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
10 DepthwiseConv2D functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1285115648, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
    Input 01 Int8 scale: [(scale:1443064832, shift:37), (scale:1626474368, shift:38), (scale:1108856064, shift:37), (scale:1742836864, shift:38), (scale:1459007360, shift:38), (scale:1451106048, shift:37), (scale:1124030336, shift:38), (scale:2024264832, shift:38), (scale:1164180352, shift:38), (scale:1202871936, shift:37), (scale:1335792000, shift:37), (scale:2052092800, shift:38), (scale:1648422784, shift:38), (scale:1825270272, shift:38), (scale:2051987840, shift:38), (scale:2055072128, shift:38), (scale:1264699136, shift:37), (scale:1197251456, shift:37), (scale:2038382080, shift:38), (scale:1341286272, shift:38), (scale:1672669312, shift:38), (scale:2069471744, shift:38), (scale:1159708800, shift:38), (scale:1285290240, shift:37), (scale:1156410496, shift:38), (scale:1311717504, shift:38), (scale:1907664640, shift:38), (scale:1966439680, shift:38), (scale:1596604928, shift:37), (scale:2138117248, shift:38), (scale:1280972544, shift:38), (scale:2083718272, shift:38), (scale:2140180480, shift:38), (scale:1398972032, shift:38), (scale:1729058176, shift:38), (scale:1231629440, shift:38), (scale:1232161152, shift:37), (scale:1298262784, shift:37), (scale:1675111552, shift:38), (scale:2049285120, shift:39), (scale:1503264128, shift:38), (scale:1371875456, shift:38), (scale:1575143168, shift:38), (scale:1098279680, shift:38), (scale:1433077376, shift:38), (scale:1883795072, shift:38), (scale:1696941184, shift:38), (scale:1170690176, shift:37), (scale:1684608384, shift:38), (scale:1374521728, shift:37), (scale:1736215040, shift:38), (scale:1719291136, shift:37), (scale:1302240384, shift:38), (scale:1617303296, shift:38), (scale:1243250816, shift:37), (scale:1997172736, shift:38), (scale:2072570240, shift:38), (scale:2034194176, shift:38), (scale:1328418944, shift:38), (scale:2034920448, shift:38), (scale:1127586304, shift:37), (scale:1889290880, shift:38), (scale:1501662208, shift:37), (scale:2107579136, shift:38)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 3 functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource
    Input 02 Int32 scale: [(scale:1727142528, shift:42), (scale:1946657536, shift:43), (scale:1327142400, shift:42), (scale:2085926912, shift:43), (scale:1746223488, shift:43), (scale:1736766720, shift:42), (scale:1345303808, shift:43), (scale:1211377920, shift:42), (scale:1393357696, shift:43), (scale:1439665920, shift:42), (scale:1598752256, shift:42), (scale:1228030976, shift:42), (scale:1972926720, shift:43), (scale:1092293888, shift:42), (scale:1227968256, shift:42), (scale:1229813888, shift:42), (scale:1513664256, shift:42), (scale:1432939008, shift:42), (scale:1219826176, shift:42), (scale:1605328128, shift:43), (scale:2001946368, shift:43), (scale:1238431104, shift:42), (scale:1388005888, shift:43), (scale:1538308864, shift:42), (scale:1384058240, shift:43), (scale:1569938560, shift:43), (scale:1141601152, shift:42), (scale:1176773760, shift:42), (scale:1910908160, shift:42), (scale:1279510528, shift:42), (scale:1533141248, shift:43), (scale:1246956672, shift:42), (scale:1280745216, shift:42), (scale:1674369792, shift:43), (scale:2069435776, shift:43), (scale:1474084608, shift:43), (scale:1474721024, shift:42), (scale:1553835136, shift:42), (scale:2004869376, shift:43), (scale:1226350848, shift:43), (scale:1799192576, shift:43), (scale:1641939072, shift:43), (scale:1885221504, shift:43), (scale:1314483968, shift:43), (scale:1715188992, shift:43), (scale:1127316864, shift:42), (scale:2030996352, shift:43), (scale:1401148928, shift:42), (scale:2016235648, shift:43), (scale:1645106304, shift:42), (scale:2078001536, shift:43), (scale:2057746048, shift:42), (scale:1558595840, shift:43), (scale:1935681152, shift:43), (scale:1487993728, shift:42), (scale:1195165312, shift:42), (scale:1240285312, shift:42), (scale:1217319936, shift:42), (scale:1589927808, shift:43), (scale:1217754624, shift:42), (scale:1349559808, shift:42), (scale:1130605696, shift:42), (scale:1797275264, shift:42), (scale:1261235584, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource
    Output 00 Int8 scale: [(scale:1577148544, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
11 Relu functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1577148544, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
    Output 00 Int8 scale: [(scale:1577148544, shift:35)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
12 Conv2D functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
    Input 00 Int8 scale: [(scale:1577148544, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
    Input 01 Int8 scale: [(scale:1863724800, shift:39), (scale:2109638656, shift:40), (scale:1961520512, shift:39), (scale:1195189760, shift:38), (scale:1224187648, shift:38), (scale:1673181696, shift:39), (scale:2047420160, shift:39), (scale:1879607424, shift:39), (scale:1687176832, shift:39), (scale:1303134976, shift:39), (scale:1803716352, shift:39), (scale:1946363264, shift:39), (scale:2055114112, shift:39), (scale:1833580672, shift:39), (scale:1628952192, shift:39), (scale:1837843712, shift:39), (scale:1468153216, shift:39), (scale:1354978560, shift:39), (scale:1218520576, shift:39), (scale:1522567424, shift:39), (scale:1594123648, shift:39), (scale:2067559680, shift:39), (scale:1099234176, shift:38), (scale:1278900480, shift:39), (scale:2117757568, shift:39), (scale:1937855616, shift:40), (scale:1528192384, shift:39), (scale:1541464832, shift:39), (scale:2048757120, shift:39), (scale:1107013248, shift:38), (scale:1494630144, shift:39), (scale:1153654912, shift:38), (scale:1581562368, shift:39), (scale:1610798592, shift:39), (scale:1462448000, shift:39), (scale:1332861952, shift:39), (scale:1681374336, shift:39), (scale:1530865920, shift:39), (scale:1903420800, shift:39), (scale:1855637248, shift:39), (scale:1698240384, shift:39), (scale:1760665728, shift:39), (scale:1704585856, shift:39), (scale:1782982016, shift:39), (scale:1218571776, shift:38), (scale:1990299136, shift:39), (scale:1376934784, shift:39), (scale:2090388352, shift:39), (scale:1227487872, shift:39), (scale:2077491072, shift:39), (scale:1703966080, shift:39), (scale:1544664192, shift:39), (scale:1706559360, shift:39), (scale:1946924800, shift:39), (scale:1942351744, shift:39), (scale:1713386752, shift:39), (scale:1400965248, shift:39), (scale:1098118784, shift:38), (scale:1836725760, shift:39), (scale:1170026112, shift:38), (scale:1708500736, shift:39), (scale:1634204032, shift:39), (scale:1216194688, shift:39), (scale:1777225472, shift:39)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/conv2d_3/Conv2D
    Input 02 Int32 scale: [(scale:1368751232, shift:43), (scale:1549354496, shift:44), (scale:1440574080, shift:43), (scale:1755535360, shift:43), (scale:1798128512, shift:43), (scale:1228813056, shift:43), (scale:1503660160, shift:43), (scale:1380415744, shift:43), (scale:1239091328, shift:43), (scale:1914088960, shift:44), (scale:1324679936, shift:43), (scale:1429442304, shift:43), (scale:1509310848, shift:43), (scale:1346612864, shift:43), (scale:1196330240, shift:43), (scale:1349743744, shift:43), (scale:1078236672, shift:43), (scale:1990238592, shift:44), (scale:1789804544, shift:44), (scale:1118199424, shift:43), (scale:1170751488, shift:43), (scale:1518451072, shift:43), (scale:1614592640, shift:43), (scale:1878492544, shift:44), (scale:1555317248, shift:43), (scale:1423194112, shift:44), (scale:1122330496, shift:43), (scale:1132077952, shift:43), (scale:1504642048, shift:43), (scale:1626018688, shift:43), (scale:1097681792, shift:43), (scale:1694527616, shift:43), (scale:1161526272, shift:43), (scale:1182997888, shift:43), (scale:1074046720, shift:43), (scale:1957752960, shift:44), (scale:1234829952, shift:43), (scale:1124294016, shift:43), (scale:1397904640, shift:43), (scale:1362811520, shift:43), (scale:1247216640, shift:43), (scale:1293062912, shift:43), (scale:1251876864, shift:43), (scale:1309452288, shift:43), (scale:1789879680, shift:43), (scale:1461709568, shift:43), (scale:2022488704, shift:44), (scale:1535216768, shift:43), (scale:1802976000, shift:44), (scale:1525744768, shift:43), (scale:1251421696, shift:43), (scale:1134427648, shift:43), (scale:1253326208, shift:43), (scale:1429854720, shift:43), (scale:1426496128, shift:43), (scale:1258340352, shift:43), (scale:2057785472, shift:44), (scale:1612954240, shift:43), (scale:1348922624, shift:43), (scale:1718574208, shift:43), (scale:1254752000, shift:43), (scale:1200187264, shift:43), (scale:1786388224, shift:44), (scale:1305224576, shift:43)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D
    Output 00 Int8 scale: [(scale:1132866816, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
13 Relu functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
    Input 00 Int8 scale: [(scale:1132866816, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
    Output 00 Int8 scale: [(scale:1132866816, shift:35)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
14 DepthwiseConv2D functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1132866816, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
    Input 01 Int8 scale: [(scale:1769574528, shift:38), (scale:1436196608, shift:39), (scale:1332834944, shift:38), (scale:1882794880, shift:39), (scale:1135717888, shift:38), (scale:1140824448, shift:37), (scale:1855011072, shift:38), (scale:1521033088, shift:38), (scale:1664806784, shift:37), (scale:1240847744, shift:38), (scale:1423400320, shift:37), (scale:1118663936, shift:38), (scale:1524085376, shift:38), (scale:1225579008, shift:38), (scale:1079566208, shift:37), (scale:1432325888, shift:38), (scale:1504566272, shift:38), (scale:1597768960, shift:38), (scale:1453890944, shift:38), (scale:1279862528, shift:37), (scale:1646897408, shift:38), (scale:1187813376, shift:38), (scale:1901231616, shift:39), (scale:1535823488, shift:38), (scale:2004544512, shift:38), (scale:1255474688, shift:38), (scale:1848587392, shift:38), (scale:1125385472, shift:38), (scale:1181533824, shift:37), (scale:1731459456, shift:38), (scale:1243043200, shift:37), (scale:1215114752, shift:38), (scale:1898641792, shift:38), (scale:1976091264, shift:38), (scale:1287099136, shift:37), (scale:1961423616, shift:38), (scale:1667680000, shift:38), (scale:1447564544, shift:38), (scale:1338771968, shift:37), (scale:1458316800, shift:38), (scale:1691923328, shift:38), (scale:1093794688, shift:37), (scale:1339741568, shift:38), (scale:1621158656, shift:38), (scale:1262748160, shift:38), (scale:1245180544, shift:38), (scale:1669311872, shift:37), (scale:1121074048, shift:37), (scale:1222070784, shift:37), (scale:1197417984, shift:38), (scale:1975216768, shift:37), (scale:1576311296, shift:38), (scale:1419405312, shift:38), (scale:1565064832, shift:37), (scale:1182171392, shift:37), (scale:1713001472, shift:37), (scale:1074690304, shift:37), (scale:1725377024, shift:38), (scale:1729641472, shift:38), (scale:1532081664, shift:38), (scale:2083963392, shift:38), (scale:1782348288, shift:38), (scale:1676304512, shift:37), (scale:1076491648, shift:37)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 3 functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource
    Input 02 Int32 scale: [(scale:1867015168, shift:43), (scale:1515280000, shift:44), (scale:1406226816, shift:43), (scale:1986469888, shift:44), (scale:1198255616, shift:43), (scale:1203643264, shift:42), (scale:1957156224, shift:43), (scale:1604787968, shift:43), (scale:1756478464, shift:42), (scale:1309174272, shift:43), (scale:1501779072, shift:42), (scale:1180262528, shift:43), (scale:1608008320, shift:43), (scale:1293064832, shift:43), (scale:1139011968, shift:42), (scale:1511196160, shift:43), (scale:1587414400, shift:43), (scale:1685749248, shift:43), (scale:1533948672, shift:43), (scale:1350337408, shift:42), (scale:1737582848, shift:43), (scale:1253219712, shift:43), (scale:2005921920, shift:44), (scale:1620392704, shift:43), (scale:2114923648, shift:43), (scale:1324606720, shift:43), (scale:1950378880, shift:43), (scale:1187354240, shift:43), (scale:1246594304, shift:42), (scale:1826801280, shift:43), (scale:1311490688, shift:42), (scale:1282024320, shift:43), (scale:2003189376, shift:43), (scale:2084903680, shift:43), (scale:1357972480, shift:42), (scale:2069428352, shift:43), (scale:1759509888, shift:43), (scale:1527273856, shift:43), (scale:1412490752, shift:42), (scale:1538618240, shift:43), (scale:1785088128, shift:43), (scale:1154023936, shift:42), (scale:1413513728, shift:43), (scale:1710426880, shift:43), (scale:1332280704, shift:43), (scale:1313745664, shift:43), (scale:1761231616, shift:42), (scale:1182805376, shift:42), (scale:1289363456, shift:42), (scale:1263353088, shift:43), (scale:2083980928, shift:42), (scale:1663110016, shift:43), (scale:1497564032, shift:43), (scale:1651244288, shift:42), (scale:1247266944, shift:42), (scale:1807326976, shift:42), (scale:1133867520, shift:42), (scale:1820384000, shift:43), (scale:1824883200, shift:43), (scale:1616444928, shift:43), (scale:1099357824, shift:42), (scale:1880492288, shift:43), (scale:1768609280, shift:42), (scale:1135768064, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource
    Output 00 Int8 scale: [(scale:1609549056, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
15 Relu functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1609549056, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
    Output 00 Int8 scale: [(scale:1609549056, shift:35)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
16 Conv2D functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
    Input 00 Int8 scale: [(scale:1609549056, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
    Input 01 Int8 scale: [(scale:1103490560, shift:37), (scale:1089363840, shift:37), (scale:1941939968, shift:38), (scale:1134922112, shift:37), (scale:1322422528, shift:37), (scale:1349955072, shift:37), (scale:2142559232, shift:38), (scale:1213446272, shift:37), (scale:1076710272, shift:37), (scale:1197436800, shift:37), (scale:2025992576, shift:38), (scale:1132253696, shift:37), (scale:1151798656, shift:37), (scale:1741811840, shift:38), (scale:1472237696, shift:37), (scale:1945139584, shift:38), (scale:2004086912, shift:38), (scale:1158968064, shift:37), (scale:1331554304, shift:37), (scale:2059459712, shift:38), (scale:1826549760, shift:38), (scale:1309050496, shift:37), (scale:1278068608, shift:37), (scale:1465158784, shift:37), (scale:1969339520, shift:38), (scale:1781134208, shift:38), (scale:1081625472, shift:37), (scale:1401820288, shift:38), (scale:1138978432, shift:37), (scale:1437350400, shift:37), (scale:1752152832, shift:38), (scale:2023836032, shift:38), (scale:1261702272, shift:37), (scale:2069750144, shift:38), (scale:1704135424, shift:38), (scale:1183723520, shift:37), (scale:1783816064, shift:37), (scale:1640697856, shift:38), (scale:2132520064, shift:38), (scale:1130913408, shift:37), (scale:2000672128, shift:38), (scale:2056496896, shift:38), (scale:1687575424, shift:38), (scale:1778191872, shift:38), (scale:1227293824, shift:37), (scale:1932541952, shift:38), (scale:2127057408, shift:38), (scale:1173656704, shift:37), (scale:1674942464, shift:38), (scale:1131779456, shift:37), (scale:1077545856, shift:37), (scale:1163039104, shift:37), (scale:1117279872, shift:37), (scale:1211461888, shift:37), (scale:1098282496, shift:37), (scale:2108566528, shift:38), (scale:1250008960, shift:37), (scale:1251099520, shift:37), (scale:1328415616, shift:37), (scale:2087376384, shift:38), (scale:1938866688, shift:38), (scale:1269583104, shift:37), (scale:1581113216, shift:38), (scale:1269816064, shift:37)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/conv2d_4/Conv2D
    Input 02 Int32 scale: [(scale:1654142720, shift:42), (scale:1632966656, shift:42), (scale:1455493120, shift:42), (scale:1701258880, shift:42), (scale:1982323712, shift:42), (scale:2023595264, shift:42), (scale:1605858176, shift:42), (scale:1818967296, shift:42), (scale:1613998848, shift:42), (scale:1794968960, shift:42), (scale:1518490880, shift:42), (scale:1697258880, shift:42), (scale:1726556928, shift:42), (scale:1305496192, shift:42), (scale:1103449088, shift:41), (scale:1457891200, shift:42), (scale:1502072576, shift:42), (scale:1737303936, shift:42), (scale:1996012416, shift:42), (scale:1543574656, shift:42), (scale:1369007616, shift:42), (scale:1962278912, shift:42), (scale:1915836800, shift:42), (scale:1098143360, shift:41), (scale:1476029184, shift:42), (scale:1334968448, shift:42), (scale:1621366656, shift:42), (scale:2101341696, shift:43), (scale:1707339392, shift:42), (scale:1077300864, shift:41), (scale:1313246720, shift:42), (scale:1516874624, shift:42), (scale:1891303552, shift:42), (scale:1551287424, shift:42), (scale:1277257472, shift:42), (scale:1774412672, shift:42), (scale:1336978560, shift:41), (scale:1229710720, shift:42), (scale:1598333824, shift:42), (scale:1695249792, shift:42), (scale:1499513088, shift:42), (scale:1541354112, shift:42), (scale:1264845696, shift:42), (scale:1332763136, shift:42), (scale:1839724928, shift:42), (scale:1448449280, shift:42), (scale:1594239488, shift:42), (scale:1759322368, shift:42), (scale:1255377280, shift:42), (scale:1696547968, shift:42), (scale:1615251328, shift:42), (scale:1743406464, shift:42), (scale:1674813056, shift:42), (scale:1815992704, shift:42), (scale:1646335744, shift:42), (scale:1580380544, shift:42), (scale:1873775104, shift:42), (scale:1875409920, shift:42), (scale:1991307520, shift:42), (scale:1564498432, shift:42), (scale:1453189632, shift:42), (scale:1903116928, shift:42), (scale:1185051776, shift:42), (scale:1903466240, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D
    Output 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
17 Relu functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
    Input 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
    Output 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
18 AvgPool functional_1/average_pooling2d/AvgPool
    Input 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
    Output 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/average_pooling2d/AvgPool
19 FullyConnected functional_1/dense/BiasAdd
    Input 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/average_pooling2d/AvgPool
    Input 01 Int8 scale: [(scale:1152529408, shift:37)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/MatMul
    Input 02 Int32 scale: [(scale:1479592576, shift:41)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/ReadVariableOp/resource
    Output 00 Int8 scale: [(scale:1242899200, shift:33)], zero_point: [14], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd
20 MaxPool functional_1/dense/BiasAdd/maxpool
    Input 00 Int8 scale: [(scale:1242899200, shift:33)], zero_point: [14], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd
    Output 00 Int8 scale: [], zero_point: [14], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/maxpool
21 Sub functional_1/dense/BiasAdd/Sub
    Input 00 Int8 scale: [(scale:1242899200, shift:33)], zero_point: [14], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd
    Input 01 Int8 scale: [], zero_point: [14], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/maxpool
    Output 00 Int8 scale: [(scale:1, shift:0)], zero_point: [127], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub
22 LUT functional_1/dense/BiasAdd/Sub/lut
    Input 00 Int8 scale: [(scale:1, shift:0)], zero_point: [127], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 exp_lut
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [127], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut
23 Asr functional_1/dense/BiasAdd/Sub/lut/Asr
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 right_shift12
    Output 00 Int32 scale: [], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr
24 ReduceSum functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr
    Output 00 Int32 scale: [], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
25 CLZ functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
    Output 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
26 Sub headroom_offset/Sub
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 headroom_offset
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
    Output 00 Int32 scale: [], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 headroom_offset/Sub
27 Sub functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ/Sub
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 one_const
    Output 00 Int32 scale: [], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ/Sub
28 SHL functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ/Sub
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
29 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 neg_32_over_17
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul
30 Add functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
    Input 00 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 const_48_over_17
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
31 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
32 Sub F2_one/Sub
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one
    Input 01 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
33 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
34 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul
    Input 00 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 four
    Output 00 Int32 scale: [], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul
35 Add functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
36 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
37 Sub F2_one/Sub
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one
    Input 01 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
38 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
39 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul
    Input 00 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 four
    Output 00 Int32 scale: [], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul
40 Add functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
41 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
42 Sub F2_one/Sub
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one
    Input 01 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
43 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
44 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul
    Input 00 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 four
    Output 00 Int32 scale: [], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul
45 Add functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add
46 Mul functional_1/dense/BiasAdd/Sub/lut/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Mul
47 Asr Identity
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Mul
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 headroom_offset/Sub
    Output 00 Int8 scale: [(scale:1073741824, shift:38)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 Identity


[ Before Graph Optimisation ]
0     Conv2D               functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
1     Relu                 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
2     DepthwiseConv2D      functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
3     Relu                 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
4     Conv2D               functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
5     Relu                 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
6     DepthwiseConv2D      functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
7     Relu                 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
8     Conv2D               functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
9     Relu                 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
10    DepthwiseConv2D      functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
11    Relu                 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
12    Conv2D               functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
13    Relu                 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
14    DepthwiseConv2D      functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
15    Relu                 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
16    Conv2D               functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
17    Relu                 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
18    AvgPool              functional_1/average_pooling2d/AvgPool
19    FullyConnected       functional_1/dense/BiasAdd    
20    MaxPool              functional_1/dense/BiasAdd/maxpool
21    Sub                  functional_1/dense/BiasAdd/Sub
22    LUT                  functional_1/dense/BiasAdd/Sub/lut
23    Asr                  functional_1/dense/BiasAdd/Sub/lut/Asr
24    ReduceSum            functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
25    CLZ                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
26    Sub                  headroom_offset/Sub           
27    Sub                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ/Sub
28    SHL                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
29    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul
30    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
31    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
32    Sub                  F2_one/Sub                    
33    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
34    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul
35    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
36    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
37    Sub                  F2_one/Sub                    
38    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
39    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul
40    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
41    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
42    Sub                  F2_one/Sub                    
43    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
44    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul
45    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add
46    Mul                  functional_1/dense/BiasAdd/Sub/lut/Mul
47    Asr                  Identity                      


[ After Graph Optimization ]
0     Conv2D               functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
1     Relu                 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
2     DepthwiseConv2D      functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
3     Relu                 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
4     Conv2D               functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
5     Relu                 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
6     DepthwiseConv2D      functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
7     Relu                 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
8     Conv2D               functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
9     Relu                 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
10    DepthwiseConv2D      functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
11    Relu                 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
12    Conv2D               functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
13    Relu                 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
14    DepthwiseConv2D      functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
15    Relu                 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
16    Conv2D               functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
17    Relu                 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
18    AvgPool              functional_1/average_pooling2d/AvgPool
19    FullyConnected       functional_1/dense/BiasAdd    
20    MaxPool              functional_1/dense/BiasAdd/maxpool
21    Sub                  functional_1/dense/BiasAdd/Sub
22    LUT                  functional_1/dense/BiasAdd/Sub/lut
23    Asr                  functional_1/dense/BiasAdd/Sub/lut/Asr
24    ReduceSum            functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
25    CLZ                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
26    Sub                  headroom_offset/Sub           
27    Sub                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ/Sub
28    SHL                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
29    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul
30    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
31    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
32    Sub                  F2_one/Sub                    
33    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
34    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul
35    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
36    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
37    Sub                  F2_one/Sub                    
38    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
39    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul
40    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
41    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
42    Sub                  F2_one/Sub                    
43    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
44    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul
45    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add
46    Mul                  functional_1/dense/BiasAdd/Sub/lut/Mul
47    Asr                  Identity                      


[ Graph With Tensor Quantization ]
0 Conv2D functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
    Input 00 Int8 scale: [(scale:1255639936, shift:31)], zero_point: [83], quantMin: [], quantMax: [], dimension: 0 input_1
    Input 01 Int8 scale: [(scale:1464379008, shift:40), (scale:1627438592, shift:41), (scale:2075258880, shift:42), (scale:1168237824, shift:41), (scale:1974605056, shift:42), (scale:1721740160, shift:41), (scale:1753228160, shift:40), (scale:1488934784, shift:41), (scale:1158502912, shift:41), (scale:1188821888, shift:42), (scale:2093692416, shift:41), (scale:1192383104, shift:41), (scale:1241635712, shift:40), (scale:1341249536, shift:41), (scale:1510890880, shift:41), (scale:1695192704, shift:42), (scale:1737978496, shift:40), (scale:1398920704, shift:42), (scale:1746344320, shift:42), (scale:1183181312, shift:41), (scale:1977891584, shift:42), (scale:2113310208, shift:41), (scale:1867738624, shift:42), (scale:2071492864, shift:40), (scale:1785629696, shift:42), (scale:1601047552, shift:41), (scale:2084708864, shift:42), (scale:1776369664, shift:41), (scale:1110910976, shift:40), (scale:1188599936, shift:40), (scale:1304962560, shift:41), (scale:2105906560, shift:41), (scale:1524456576, shift:41), (scale:1199206144, shift:41), (scale:1698997888, shift:41), (scale:1483576448, shift:41), (scale:1413839616, shift:40), (scale:1961673344, shift:42), (scale:1395400576, shift:42), (scale:1804189824, shift:42), (scale:1684543488, shift:42), (scale:1297103488, shift:41), (scale:1180393728, shift:41), (scale:1112020992, shift:39), (scale:1304851456, shift:40), (scale:1339063296, shift:40), (scale:1462929152, shift:41), (scale:1156472320, shift:41), (scale:1637322240, shift:41), (scale:1713849088, shift:40), (scale:1621298432, shift:41), (scale:1104686080, shift:40), (scale:1114051584, shift:40), (scale:1806657408, shift:42), (scale:1706757760, shift:41), (scale:1979592448, shift:40), (scale:1814144384, shift:42), (scale:1384162944, shift:41), (scale:1765874944, shift:41), (scale:1857623040, shift:42), (scale:1349751680, shift:41), (scale:1080475776, shift:41), (scale:2000449024, shift:41), (scale:1812903424, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/conv2d/Conv2D
    Input 02 Int32 scale: [(scale:1712453376, shift:41), (scale:1903136128, shift:42), (scale:1213409920, shift:42), (scale:1366144128, shift:42), (scale:1154557312, shift:42), (scale:2013412992, shift:42), (scale:2050235264, shift:41), (scale:1741169024, shift:42), (scale:1354760064, shift:42), (scale:1390215296, shift:43), (scale:1224188032, shift:41), (scale:1394379776, shift:42), (scale:1451976064, shift:41), (scale:1568465024, shift:42), (scale:1766844544, shift:42), (scale:1982368256, shift:43), (scale:2032402176, shift:41), (scale:1635906048, shift:43), (scale:2042185216, shift:43), (scale:1383619072, shift:42), (scale:1156478976, shift:42), (scale:1235658624, shift:41), (scale:1092072192, shift:42), (scale:1211207936, shift:40), (scale:2088125696, shift:43), (scale:1872274304, shift:42), (scale:1218935296, shift:42), (scale:2077297024, shift:42), (scale:1299105792, shift:41), (scale:1389955712, shift:41), (scale:1526030848, shift:42), (scale:1231329664, shift:41), (scale:1782708352, shift:42), (scale:1402358656, shift:42), (scale:1986818048, shift:42), (scale:1734902912, shift:42), (scale:1653352320, shift:41), (scale:1146996096, shift:42), (scale:1631789568, shift:43), (scale:2109830016, shift:43), (scale:1969915008, shift:43), (scale:1516840320, shift:42), (scale:1380359296, shift:42), (scale:1300403840, shift:40), (scale:1525900928, shift:41), (scale:1565908352, shift:41), (scale:1710757888, shift:42), (scale:1352385408, shift:42), (scale:1914694144, shift:42), (scale:2004185088, shift:41), (scale:1895955840, shift:42), (scale:1291826304, shift:41), (scale:1302778368, shift:41), (scale:2112715648, shift:43), (scale:1995892480, shift:42), (scale:1157473408, shift:40), (scale:2121470976, shift:43), (scale:1618648192, shift:42), (scale:2065024384, shift:42), (scale:1086157568, shift:42), (scale:1578407424, shift:42), (scale:1263514624, shift:42), (scale:1169668352, shift:41), (scale:2120019840, shift:43)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D
    Output 00 Int8 scale: [(scale:1352492032, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
1 Relu functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
    Input 00 Int8 scale: [(scale:1352492032, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
    Output 00 Int8 scale: [(scale:1352492032, shift:34)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
2 DepthwiseConv2D functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1352492032, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
    Input 01 Int8 scale: [(scale:1175311872, shift:37), (scale:1421834240, shift:38), (scale:1271638528, shift:37), (scale:1767601536, shift:37), (scale:1557757056, shift:37), (scale:1964024960, shift:37), (scale:1340253440, shift:37), (scale:1632174336, shift:38), (scale:1362240512, shift:37), (scale:1455178240, shift:38), (scale:1301060352, shift:37), (scale:1534470784, shift:37), (scale:1505380864, shift:37), (scale:1607027712, shift:37), (scale:2074724736, shift:38), (scale:1142046336, shift:37), (scale:1205169408, shift:37), (scale:1980826496, shift:37), (scale:1788229376, shift:37), (scale:1879952768, shift:37), (scale:2140038912, shift:37), (scale:1967693440, shift:38), (scale:1371067008, shift:36), (scale:1222602752, shift:37), (scale:2044833408, shift:37), (scale:1474644096, shift:38), (scale:1265859456, shift:37), (scale:1932803968, shift:37), (scale:1682347648, shift:37), (scale:1849218560, shift:37), (scale:1137651584, shift:37), (scale:1620537088, shift:38), (scale:1330349056, shift:37), (scale:1458722176, shift:37), (scale:1262768512, shift:37), (scale:1439908864, shift:37), (scale:1143717888, shift:37), (scale:1255351168, shift:38), (scale:1737809280, shift:37), (scale:1521102720, shift:37), (scale:1310250368, shift:36), (scale:1701335296, shift:37), (scale:1126833920, shift:36), (scale:1467101824, shift:37), (scale:1102162304, shift:37), (scale:1211554304, shift:37), (scale:2127924352, shift:38), (scale:1508294144, shift:38), (scale:1134804864, shift:36), (scale:1403477120, shift:37), (scale:1413260928, shift:37), (scale:1539753600, shift:36), (scale:1543505408, shift:37), (scale:2064233344, shift:38), (scale:1818934528, shift:38), (scale:1809568256, shift:38), (scale:1679345920, shift:37), (scale:2092672000, shift:38), (scale:1182935296, shift:36), (scale:1790981376, shift:37), (scale:1380477440, shift:37), (scale:1797254400, shift:38), (scale:1616903808, shift:37), (scale:1895568512, shift:37)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 3 functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource
    Input 02 Int32 scale: [(scale:1480430336, shift:41), (scale:1790951424, shift:42), (scale:1601763968, shift:41), (scale:1113241088, shift:40), (scale:1962160640, shift:41), (scale:1236949120, shift:40), (scale:1688191744, shift:41), (scale:2055897216, shift:42), (scale:1715886848, shift:41), (scale:1832951808, shift:42), (scale:1638823936, shift:41), (scale:1932829184, shift:41), (scale:1896187264, shift:41), (scale:2024222336, shift:41), (scale:1306668288, shift:41), (scale:1438528768, shift:41), (scale:1518039040, shift:41), (scale:1247530880, shift:40), (scale:1126232576, shift:40), (scale:1184000256, shift:40), (scale:1347803264, shift:40), (scale:1239259648, shift:41), (scale:1727004672, shift:40), (scale:1539998208, shift:41), (scale:1287842560, shift:40), (scale:1857471104, shift:42), (scale:1594484608, shift:41), (scale:1217286144, shift:40), (scale:2119095808, shift:41), (scale:1164643712, shift:40), (scale:1432993152, shift:41), (scale:2041238784, shift:42), (scale:1675716096, shift:41), (scale:1837415680, shift:41), (scale:1590591232, shift:41), (scale:1813718400, shift:41), (scale:1440634368, shift:41), (scale:1581248256, shift:42), (scale:1094477824, shift:40), (scale:1915990656, shift:41), (scale:1650399744, shift:40), (scale:2143012736, shift:41), (scale:1419367168, shift:40), (scale:1847970816, shift:41), (scale:1388290688, shift:41), (scale:1526081536, shift:41), (scale:1340173568, shift:41), (scale:1899856896, shift:42), (scale:1429407488, shift:40), (scale:1767828736, shift:41), (scale:1780152448, shift:41), (scale:1939483392, shift:40), (scale:1944209280, shift:41), (scale:1300060672, shift:41), (scale:1145570688, shift:41), (scale:1139671808, shift:41), (scale:2115314816, shift:41), (scale:1317971456, shift:41), (scale:1490032768, shift:40), (scale:1127965824, shift:40), (scale:1738858112, shift:41), (scale:1131916544, shift:41), (scale:2036662272, shift:41), (scale:1193835136, shift:40)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource
    Output 00 Int8 scale: [(scale:1422750976, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
3 Relu functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1422750976, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
    Output 00 Int8 scale: [(scale:1422750976, shift:34)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
4 Conv2D functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
    Input 00 Int8 scale: [(scale:1422750976, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
    Input 01 Int8 scale: [(scale:1270611200, shift:39), (scale:2030643712, shift:39), (scale:1644547200, shift:39), (scale:1274715008, shift:39), (scale:2034716288, shift:39), (scale:1319735296, shift:39), (scale:1097028992, shift:39), (scale:1806930304, shift:39), (scale:1675453184, shift:39), (scale:2144237824, shift:39), (scale:1841686400, shift:39), (scale:1626432000, shift:39), (scale:1143902976, shift:38), (scale:1698825600, shift:39), (scale:1795597696, shift:39), (scale:1543490048, shift:39), (scale:1347438720, shift:39), (scale:1668319104, shift:39), (scale:2038381824, shift:39), (scale:1589206784, shift:39), (scale:1710085504, shift:39), (scale:1645939584, shift:39), (scale:1300315648, shift:38), (scale:1830330496, shift:39), (scale:1526757248, shift:39), (scale:1863892992, shift:39), (scale:1325160448, shift:39), (scale:1427883392, shift:39), (scale:1518774144, shift:39), (scale:1850537472, shift:39), (scale:2038893184, shift:39), (scale:2012493696, shift:39), (scale:1608130816, shift:39), (scale:1479658112, shift:39), (scale:1104901376, shift:38), (scale:1808917120, shift:39), (scale:1817939712, shift:39), (scale:2125389056, shift:39), (scale:2083040256, shift:39), (scale:1571339776, shift:39), (scale:1132971264, shift:38), (scale:2043926656, shift:39), (scale:1689693696, shift:39), (scale:1087454464, shift:38), (scale:1903368448, shift:39), (scale:1731485568, shift:39), (scale:1077008384, shift:39), (scale:1954194944, shift:39), (scale:1262896768, shift:39), (scale:1708360064, shift:39), (scale:1683638400, shift:39), (scale:1548113408, shift:39), (scale:1464501632, shift:39), (scale:2042817536, shift:39), (scale:2064977792, shift:39), (scale:1936098048, shift:39), (scale:1109349504, shift:39), (scale:1603760256, shift:39), (scale:1557180928, shift:39), (scale:1261184000, shift:39), (scale:1872705280, shift:39), (scale:1398821760, shift:39), (scale:1747156736, shift:39), (scale:1785712640, shift:39)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/conv2d_1/Conv2D
    Input 02 Int32 scale: [(scale:1683610752, shift:43), (scale:1345342208, shift:42), (scale:1089545472, shift:42), (scale:1689048448, shift:43), (scale:1348040320, shift:42), (scale:1748702208, shift:43), (scale:1453607424, shift:43), (scale:1197127552, shift:42), (scale:1110021376, shift:42), (scale:1420600576, shift:42), (scale:1220154112, shift:42), (scale:1077543808, shift:42), (scale:1515717376, shift:42), (scale:1125506048, shift:42), (scale:1189619456, shift:42), (scale:2045186176, shift:43), (scale:1785410304, shift:43), (scale:1105294848, shift:42), (scale:1350468864, shift:42), (scale:2105762688, shift:43), (scale:1132965888, shift:42), (scale:1090467968, shift:42), (scale:1722970368, shift:42), (scale:1212630656, shift:42), (scale:2023014528, shift:43), (scale:1234866432, shift:42), (scale:1755890688, shift:43), (scale:1892002816, shift:43), (scale:2012436608, shift:43), (scale:1226018176, shift:42), (scale:1350807680, shift:42), (scale:1333317376, shift:42), (scale:2130837760, shift:43), (scale:1960606336, shift:43), (scale:1464038656, shift:42), (scale:1198443904, shift:42), (scale:1204421504, shift:42), (scale:1408112896, shift:42), (scale:1380055936, shift:42), (scale:2082088192, shift:43), (scale:1501232384, shift:42), (scale:1354142336, shift:42), (scale:1119456000, shift:42), (scale:1440920832, shift:42), (scale:1261019776, shift:42), (scale:1147143936, shift:42), (scale:1427079296, shift:43), (scale:1294693376, shift:42), (scale:1673388800, shift:43), (scale:1131822848, shift:42), (scale:1115444224, shift:42), (scale:2051312384, shift:43), (scale:1940523392, shift:43), (scale:1353407616, shift:42), (scale:1368089216, shift:42), (scale:1282703744, shift:42), (scale:1469932544, shift:43), (scale:2125046656, shift:43), (scale:2063327232, shift:43), (scale:1671119360, shift:43), (scale:1240704768, shift:42), (scale:1853494912, shift:43), (scale:1157526400, shift:42), (scale:1183070464, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D
    Output 00 Int8 scale: [(scale:2062467200, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
5 Relu functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
    Input 00 Int8 scale: [(scale:2062467200, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
    Output 00 Int8 scale: [(scale:2062467200, shift:35)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
6 DepthwiseConv2D functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:2062467200, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
    Input 01 Int8 scale: [(scale:1792217088, shift:38), (scale:1776190720, shift:38), (scale:1770845568, shift:37), (scale:1272406144, shift:37), (scale:1814885248, shift:38), (scale:1965241728, shift:37), (scale:1624973184, shift:38), (scale:1544612480, shift:38), (scale:1698108160, shift:37), (scale:1817450240, shift:38), (scale:2040592768, shift:38), (scale:2053262464, shift:38), (scale:1941416064, shift:38), (scale:1878308864, shift:38), (scale:1215870208, shift:37), (scale:1190906112, shift:37), (scale:2133784704, shift:38), (scale:1085578624, shift:37), (scale:1814735360, shift:38), (scale:1483078016, shift:38), (scale:1287174528, shift:38), (scale:1270013696, shift:36), (scale:1952631296, shift:38), (scale:1834623872, shift:38), (scale:2137792128, shift:38), (scale:1287734656, shift:37), (scale:2137980672, shift:38), (scale:1595241984, shift:38), (scale:1935896320, shift:38), (scale:1157065856, shift:37), (scale:1493662336, shift:38), (scale:1802953344, shift:38), (scale:1137304064, shift:36), (scale:1906626688, shift:38), (scale:1792789248, shift:38), (scale:1535577088, shift:37), (scale:1342918912, shift:38), (scale:1487831552, shift:38), (scale:2146545408, shift:38), (scale:1384833664, shift:38), (scale:1199503360, shift:37), (scale:1423974528, shift:37), (scale:1109840768, shift:37), (scale:1148437888, shift:38), (scale:1714945024, shift:38), (scale:1258835584, shift:37), (scale:1484821760, shift:37), (scale:1762760576, shift:38), (scale:1948180736, shift:38), (scale:1615223296, shift:38), (scale:1544111488, shift:37), (scale:1810116224, shift:37), (scale:1129528320, shift:37), (scale:1880874624, shift:38), (scale:1576878592, shift:38), (scale:1967843072, shift:38), (scale:1340814848, shift:37), (scale:1297278464, shift:37), (scale:1349762944, shift:37), (scale:2047192576, shift:38), (scale:2040242432, shift:38), (scale:2015957760, shift:38), (scale:1827989504, shift:38), (scale:2056193920, shift:38)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 3 functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource
    Input 02 Int32 scale: [(scale:1721265280, shift:42), (scale:1705873280, shift:42), (scale:1700739840, shift:41), (scale:1222033024, shift:41), (scale:1743036032, shift:42), (scale:1887440000, shift:41), (scale:1560642304, shift:42), (scale:1483463040, shift:42), (scale:1630881920, shift:41), (scale:1745499392, shift:42), (scale:1959808000, shift:42), (scale:1971976064, shift:42), (scale:1864557568, shift:42), (scale:1803948800, shift:42), (scale:1167735296, shift:41), (scale:1143759488, shift:41), (scale:2049310592, shift:42), (scale:2085203584, shift:42), (scale:1742892032, shift:42), (scale:1424364672, shift:42), (scale:1236216704, shift:42), (scale:1219735296, shift:40), (scale:1875328896, shift:42), (scale:1761993216, shift:42), (scale:2053159296, shift:42), (scale:1236754688, shift:41), (scale:2053340416, shift:42), (scale:1532088192, shift:42), (scale:1859256320, shift:42), (scale:1111258880, shift:41), (scale:1434529920, shift:42), (scale:1731576448, shift:42), (scale:1092279424, shift:40), (scale:1831145472, shift:42), (scale:1721814784, shift:42), (scale:1474785280, shift:41), (scale:1289754240, shift:42), (scale:1428930048, shift:42), (scale:2061566080, shift:42), (scale:1330009728, shift:42), (scale:1152016384, shift:41), (scale:1367601024, shift:41), (scale:2131806848, shift:42), (scale:1102972544, shift:42), (scale:1647052288, shift:42), (scale:1208999680, shift:41), (scale:1426039296, shift:41), (scale:1692974848, shift:42), (scale:1871054464, shift:42), (scale:1551278464, shift:42), (scale:1482981888, shift:41), (scale:1738455808, shift:41), (scale:1084811520, shift:41), (scale:1806412928, shift:42), (scale:1514451712, shift:42), (scale:1889938432, shift:42), (scale:1287733504, shift:41), (scale:1245920640, shift:41), (scale:1296327296, shift:41), (scale:1966146560, shift:42), (scale:1959471488, shift:42), (scale:1936148224, shift:42), (scale:1755621504, shift:42), (scale:1974791552, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource
    Output 00 Int8 scale: [(scale:1078209024, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
7 Relu functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1078209024, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
    Output 00 Int8 scale: [(scale:1078209024, shift:34)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
8 Conv2D functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
    Input 00 Int8 scale: [(scale:1078209024, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
    Input 01 Int8 scale: [(scale:1612059136, shift:39), (scale:1775348480, shift:39), (scale:1644174208, shift:39), (scale:1761611136, shift:39), (scale:1954601984, shift:39), (scale:1292690944, shift:38), (scale:1128286592, shift:38), (scale:1686442880, shift:39), (scale:1895414912, shift:39), (scale:1503374720, shift:39), (scale:1264453248, shift:38), (scale:1539396992, shift:39), (scale:1422953856, shift:39), (scale:2026836224, shift:39), (scale:1614476672, shift:38), (scale:1475159552, shift:39), (scale:1108204544, shift:38), (scale:1272150016, shift:39), (scale:2097000960, shift:39), (scale:1201109120, shift:39), (scale:1217869696, shift:38), (scale:1302342400, shift:39), (scale:1457591040, shift:39), (scale:1382811776, shift:38), (scale:2041387008, shift:39), (scale:1850732928, shift:39), (scale:1673627776, shift:39), (scale:1730418048, shift:39), (scale:1566262144, shift:39), (scale:1545316608, shift:39), (scale:1586464256, shift:39), (scale:1925055872, shift:39), (scale:1139282432, shift:38), (scale:1972102272, shift:39), (scale:1941824000, shift:39), (scale:1075758592, shift:38), (scale:1547401984, shift:39), (scale:1668819200, shift:39), (scale:1792876032, shift:39), (scale:1926764416, shift:39), (scale:1719825408, shift:39), (scale:2022496000, shift:39), (scale:2003473920, shift:39), (scale:1557260928, shift:39), (scale:2140785664, shift:39), (scale:1805093376, shift:39), (scale:1751383808, shift:39), (scale:1919804800, shift:39), (scale:1348167552, shift:39), (scale:1570661376, shift:39), (scale:1651373440, shift:39), (scale:1701611904, shift:39), (scale:1920178944, shift:39), (scale:1074890112, shift:38), (scale:1531035008, shift:39), (scale:1860359168, shift:39), (scale:1651859840, shift:39), (scale:1482249856, shift:39), (scale:1822327552, shift:39), (scale:2091655936, shift:39), (scale:1734109440, shift:39), (scale:1922042880, shift:39), (scale:1608719744, shift:39), (scale:1604003584, shift:39)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/conv2d_2/Conv2D
    Input 02 Int32 scale: [(scale:1618765952, shift:43), (scale:1782734592, shift:43), (scale:1651014656, shift:43), (scale:1768940160, shift:43), (scale:1962733952, shift:43), (scale:1298069120, shift:42), (scale:1132980736, shift:42), (scale:1693459200, shift:43), (scale:1903300608, shift:43), (scale:1509629312, shift:43), (scale:1269713920, shift:42), (scale:1545801472, shift:43), (scale:1428873856, shift:43), (scale:2035268736, shift:43), (scale:1621193600, shift:42), (scale:1481296768, shift:43), (scale:1112815104, shift:42), (scale:1277442688, shift:43), (scale:2105725312, shift:43), (scale:1206106240, shift:43), (scale:1222936576, shift:42), (scale:1307760640, shift:43), (scale:1463655168, shift:43), (scale:1388564864, shift:42), (scale:2049880064, shift:43), (scale:1858432768, shift:43), (scale:1680590720, shift:43), (scale:1737617280, shift:43), (scale:1572778368, shift:43), (scale:1551745792, shift:43), (scale:1593064576, shift:43), (scale:1933064832, shift:43), (scale:1144022272, shift:42), (scale:1980307072, shift:43), (scale:1949902720, shift:43), (scale:1080234240, shift:42), (scale:1553839744, shift:43), (scale:1675762176, shift:43), (scale:1800335104, shift:43), (scale:1934780544, shift:43), (scale:1726980608, shift:43), (scale:2030910464, shift:43), (scale:2011809152, shift:43), (scale:1563739776, shift:43), (scale:1074846080, shift:42), (scale:1812603264, shift:43), (scale:1758670336, shift:43), (scale:1927792000, shift:43), (scale:1353776512, shift:43), (scale:1577195904, shift:43), (scale:1658243840, shift:43), (scale:1708691328, shift:43), (scale:1928167680, shift:43), (scale:1079362048, shift:42), (scale:1537404672, shift:43), (scale:1868099072, shift:43), (scale:1658732288, shift:43), (scale:1488416640, shift:43), (scale:1829909120, shift:43), (scale:2100358016, shift:43), (scale:1741324032, shift:43), (scale:1930039296, shift:43), (scale:1615412608, shift:43), (scale:1610676864, shift:43)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D
    Output 00 Int8 scale: [(scale:1285115648, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
9 Relu functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
    Input 00 Int8 scale: [(scale:1285115648, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
    Output 00 Int8 scale: [(scale:1285115648, shift:35)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
10 DepthwiseConv2D functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1285115648, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
    Input 01 Int8 scale: [(scale:1443064832, shift:37), (scale:1626474368, shift:38), (scale:1108856064, shift:37), (scale:1742836864, shift:38), (scale:1459007360, shift:38), (scale:1451106048, shift:37), (scale:1124030336, shift:38), (scale:2024264832, shift:38), (scale:1164180352, shift:38), (scale:1202871936, shift:37), (scale:1335792000, shift:37), (scale:2052092800, shift:38), (scale:1648422784, shift:38), (scale:1825270272, shift:38), (scale:2051987840, shift:38), (scale:2055072128, shift:38), (scale:1264699136, shift:37), (scale:1197251456, shift:37), (scale:2038382080, shift:38), (scale:1341286272, shift:38), (scale:1672669312, shift:38), (scale:2069471744, shift:38), (scale:1159708800, shift:38), (scale:1285290240, shift:37), (scale:1156410496, shift:38), (scale:1311717504, shift:38), (scale:1907664640, shift:38), (scale:1966439680, shift:38), (scale:1596604928, shift:37), (scale:2138117248, shift:38), (scale:1280972544, shift:38), (scale:2083718272, shift:38), (scale:2140180480, shift:38), (scale:1398972032, shift:38), (scale:1729058176, shift:38), (scale:1231629440, shift:38), (scale:1232161152, shift:37), (scale:1298262784, shift:37), (scale:1675111552, shift:38), (scale:2049285120, shift:39), (scale:1503264128, shift:38), (scale:1371875456, shift:38), (scale:1575143168, shift:38), (scale:1098279680, shift:38), (scale:1433077376, shift:38), (scale:1883795072, shift:38), (scale:1696941184, shift:38), (scale:1170690176, shift:37), (scale:1684608384, shift:38), (scale:1374521728, shift:37), (scale:1736215040, shift:38), (scale:1719291136, shift:37), (scale:1302240384, shift:38), (scale:1617303296, shift:38), (scale:1243250816, shift:37), (scale:1997172736, shift:38), (scale:2072570240, shift:38), (scale:2034194176, shift:38), (scale:1328418944, shift:38), (scale:2034920448, shift:38), (scale:1127586304, shift:37), (scale:1889290880, shift:38), (scale:1501662208, shift:37), (scale:2107579136, shift:38)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 3 functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource
    Input 02 Int32 scale: [(scale:1727142528, shift:42), (scale:1946657536, shift:43), (scale:1327142400, shift:42), (scale:2085926912, shift:43), (scale:1746223488, shift:43), (scale:1736766720, shift:42), (scale:1345303808, shift:43), (scale:1211377920, shift:42), (scale:1393357696, shift:43), (scale:1439665920, shift:42), (scale:1598752256, shift:42), (scale:1228030976, shift:42), (scale:1972926720, shift:43), (scale:1092293888, shift:42), (scale:1227968256, shift:42), (scale:1229813888, shift:42), (scale:1513664256, shift:42), (scale:1432939008, shift:42), (scale:1219826176, shift:42), (scale:1605328128, shift:43), (scale:2001946368, shift:43), (scale:1238431104, shift:42), (scale:1388005888, shift:43), (scale:1538308864, shift:42), (scale:1384058240, shift:43), (scale:1569938560, shift:43), (scale:1141601152, shift:42), (scale:1176773760, shift:42), (scale:1910908160, shift:42), (scale:1279510528, shift:42), (scale:1533141248, shift:43), (scale:1246956672, shift:42), (scale:1280745216, shift:42), (scale:1674369792, shift:43), (scale:2069435776, shift:43), (scale:1474084608, shift:43), (scale:1474721024, shift:42), (scale:1553835136, shift:42), (scale:2004869376, shift:43), (scale:1226350848, shift:43), (scale:1799192576, shift:43), (scale:1641939072, shift:43), (scale:1885221504, shift:43), (scale:1314483968, shift:43), (scale:1715188992, shift:43), (scale:1127316864, shift:42), (scale:2030996352, shift:43), (scale:1401148928, shift:42), (scale:2016235648, shift:43), (scale:1645106304, shift:42), (scale:2078001536, shift:43), (scale:2057746048, shift:42), (scale:1558595840, shift:43), (scale:1935681152, shift:43), (scale:1487993728, shift:42), (scale:1195165312, shift:42), (scale:1240285312, shift:42), (scale:1217319936, shift:42), (scale:1589927808, shift:43), (scale:1217754624, shift:42), (scale:1349559808, shift:42), (scale:1130605696, shift:42), (scale:1797275264, shift:42), (scale:1261235584, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource
    Output 00 Int8 scale: [(scale:1577148544, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
11 Relu functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1577148544, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
    Output 00 Int8 scale: [(scale:1577148544, shift:35)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
12 Conv2D functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
    Input 00 Int8 scale: [(scale:1577148544, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
    Input 01 Int8 scale: [(scale:1863724800, shift:39), (scale:2109638656, shift:40), (scale:1961520512, shift:39), (scale:1195189760, shift:38), (scale:1224187648, shift:38), (scale:1673181696, shift:39), (scale:2047420160, shift:39), (scale:1879607424, shift:39), (scale:1687176832, shift:39), (scale:1303134976, shift:39), (scale:1803716352, shift:39), (scale:1946363264, shift:39), (scale:2055114112, shift:39), (scale:1833580672, shift:39), (scale:1628952192, shift:39), (scale:1837843712, shift:39), (scale:1468153216, shift:39), (scale:1354978560, shift:39), (scale:1218520576, shift:39), (scale:1522567424, shift:39), (scale:1594123648, shift:39), (scale:2067559680, shift:39), (scale:1099234176, shift:38), (scale:1278900480, shift:39), (scale:2117757568, shift:39), (scale:1937855616, shift:40), (scale:1528192384, shift:39), (scale:1541464832, shift:39), (scale:2048757120, shift:39), (scale:1107013248, shift:38), (scale:1494630144, shift:39), (scale:1153654912, shift:38), (scale:1581562368, shift:39), (scale:1610798592, shift:39), (scale:1462448000, shift:39), (scale:1332861952, shift:39), (scale:1681374336, shift:39), (scale:1530865920, shift:39), (scale:1903420800, shift:39), (scale:1855637248, shift:39), (scale:1698240384, shift:39), (scale:1760665728, shift:39), (scale:1704585856, shift:39), (scale:1782982016, shift:39), (scale:1218571776, shift:38), (scale:1990299136, shift:39), (scale:1376934784, shift:39), (scale:2090388352, shift:39), (scale:1227487872, shift:39), (scale:2077491072, shift:39), (scale:1703966080, shift:39), (scale:1544664192, shift:39), (scale:1706559360, shift:39), (scale:1946924800, shift:39), (scale:1942351744, shift:39), (scale:1713386752, shift:39), (scale:1400965248, shift:39), (scale:1098118784, shift:38), (scale:1836725760, shift:39), (scale:1170026112, shift:38), (scale:1708500736, shift:39), (scale:1634204032, shift:39), (scale:1216194688, shift:39), (scale:1777225472, shift:39)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/conv2d_3/Conv2D
    Input 02 Int32 scale: [(scale:1368751232, shift:43), (scale:1549354496, shift:44), (scale:1440574080, shift:43), (scale:1755535360, shift:43), (scale:1798128512, shift:43), (scale:1228813056, shift:43), (scale:1503660160, shift:43), (scale:1380415744, shift:43), (scale:1239091328, shift:43), (scale:1914088960, shift:44), (scale:1324679936, shift:43), (scale:1429442304, shift:43), (scale:1509310848, shift:43), (scale:1346612864, shift:43), (scale:1196330240, shift:43), (scale:1349743744, shift:43), (scale:1078236672, shift:43), (scale:1990238592, shift:44), (scale:1789804544, shift:44), (scale:1118199424, shift:43), (scale:1170751488, shift:43), (scale:1518451072, shift:43), (scale:1614592640, shift:43), (scale:1878492544, shift:44), (scale:1555317248, shift:43), (scale:1423194112, shift:44), (scale:1122330496, shift:43), (scale:1132077952, shift:43), (scale:1504642048, shift:43), (scale:1626018688, shift:43), (scale:1097681792, shift:43), (scale:1694527616, shift:43), (scale:1161526272, shift:43), (scale:1182997888, shift:43), (scale:1074046720, shift:43), (scale:1957752960, shift:44), (scale:1234829952, shift:43), (scale:1124294016, shift:43), (scale:1397904640, shift:43), (scale:1362811520, shift:43), (scale:1247216640, shift:43), (scale:1293062912, shift:43), (scale:1251876864, shift:43), (scale:1309452288, shift:43), (scale:1789879680, shift:43), (scale:1461709568, shift:43), (scale:2022488704, shift:44), (scale:1535216768, shift:43), (scale:1802976000, shift:44), (scale:1525744768, shift:43), (scale:1251421696, shift:43), (scale:1134427648, shift:43), (scale:1253326208, shift:43), (scale:1429854720, shift:43), (scale:1426496128, shift:43), (scale:1258340352, shift:43), (scale:2057785472, shift:44), (scale:1612954240, shift:43), (scale:1348922624, shift:43), (scale:1718574208, shift:43), (scale:1254752000, shift:43), (scale:1200187264, shift:43), (scale:1786388224, shift:44), (scale:1305224576, shift:43)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D
    Output 00 Int8 scale: [(scale:1132866816, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
13 Relu functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
    Input 00 Int8 scale: [(scale:1132866816, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
    Output 00 Int8 scale: [(scale:1132866816, shift:35)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
14 DepthwiseConv2D functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1132866816, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
    Input 01 Int8 scale: [(scale:1769574528, shift:38), (scale:1436196608, shift:39), (scale:1332834944, shift:38), (scale:1882794880, shift:39), (scale:1135717888, shift:38), (scale:1140824448, shift:37), (scale:1855011072, shift:38), (scale:1521033088, shift:38), (scale:1664806784, shift:37), (scale:1240847744, shift:38), (scale:1423400320, shift:37), (scale:1118663936, shift:38), (scale:1524085376, shift:38), (scale:1225579008, shift:38), (scale:1079566208, shift:37), (scale:1432325888, shift:38), (scale:1504566272, shift:38), (scale:1597768960, shift:38), (scale:1453890944, shift:38), (scale:1279862528, shift:37), (scale:1646897408, shift:38), (scale:1187813376, shift:38), (scale:1901231616, shift:39), (scale:1535823488, shift:38), (scale:2004544512, shift:38), (scale:1255474688, shift:38), (scale:1848587392, shift:38), (scale:1125385472, shift:38), (scale:1181533824, shift:37), (scale:1731459456, shift:38), (scale:1243043200, shift:37), (scale:1215114752, shift:38), (scale:1898641792, shift:38), (scale:1976091264, shift:38), (scale:1287099136, shift:37), (scale:1961423616, shift:38), (scale:1667680000, shift:38), (scale:1447564544, shift:38), (scale:1338771968, shift:37), (scale:1458316800, shift:38), (scale:1691923328, shift:38), (scale:1093794688, shift:37), (scale:1339741568, shift:38), (scale:1621158656, shift:38), (scale:1262748160, shift:38), (scale:1245180544, shift:38), (scale:1669311872, shift:37), (scale:1121074048, shift:37), (scale:1222070784, shift:37), (scale:1197417984, shift:38), (scale:1975216768, shift:37), (scale:1576311296, shift:38), (scale:1419405312, shift:38), (scale:1565064832, shift:37), (scale:1182171392, shift:37), (scale:1713001472, shift:37), (scale:1074690304, shift:37), (scale:1725377024, shift:38), (scale:1729641472, shift:38), (scale:1532081664, shift:38), (scale:2083963392, shift:38), (scale:1782348288, shift:38), (scale:1676304512, shift:37), (scale:1076491648, shift:37)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 3 functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource
    Input 02 Int32 scale: [(scale:1867015168, shift:43), (scale:1515280000, shift:44), (scale:1406226816, shift:43), (scale:1986469888, shift:44), (scale:1198255616, shift:43), (scale:1203643264, shift:42), (scale:1957156224, shift:43), (scale:1604787968, shift:43), (scale:1756478464, shift:42), (scale:1309174272, shift:43), (scale:1501779072, shift:42), (scale:1180262528, shift:43), (scale:1608008320, shift:43), (scale:1293064832, shift:43), (scale:1139011968, shift:42), (scale:1511196160, shift:43), (scale:1587414400, shift:43), (scale:1685749248, shift:43), (scale:1533948672, shift:43), (scale:1350337408, shift:42), (scale:1737582848, shift:43), (scale:1253219712, shift:43), (scale:2005921920, shift:44), (scale:1620392704, shift:43), (scale:2114923648, shift:43), (scale:1324606720, shift:43), (scale:1950378880, shift:43), (scale:1187354240, shift:43), (scale:1246594304, shift:42), (scale:1826801280, shift:43), (scale:1311490688, shift:42), (scale:1282024320, shift:43), (scale:2003189376, shift:43), (scale:2084903680, shift:43), (scale:1357972480, shift:42), (scale:2069428352, shift:43), (scale:1759509888, shift:43), (scale:1527273856, shift:43), (scale:1412490752, shift:42), (scale:1538618240, shift:43), (scale:1785088128, shift:43), (scale:1154023936, shift:42), (scale:1413513728, shift:43), (scale:1710426880, shift:43), (scale:1332280704, shift:43), (scale:1313745664, shift:43), (scale:1761231616, shift:42), (scale:1182805376, shift:42), (scale:1289363456, shift:42), (scale:1263353088, shift:43), (scale:2083980928, shift:42), (scale:1663110016, shift:43), (scale:1497564032, shift:43), (scale:1651244288, shift:42), (scale:1247266944, shift:42), (scale:1807326976, shift:42), (scale:1133867520, shift:42), (scale:1820384000, shift:43), (scale:1824883200, shift:43), (scale:1616444928, shift:43), (scale:1099357824, shift:42), (scale:1880492288, shift:43), (scale:1768609280, shift:42), (scale:1135768064, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource
    Output 00 Int8 scale: [(scale:1609549056, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
15 Relu functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1609549056, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
    Output 00 Int8 scale: [(scale:1609549056, shift:35)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
16 Conv2D functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
    Input 00 Int8 scale: [(scale:1609549056, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
    Input 01 Int8 scale: [(scale:1103490560, shift:37), (scale:1089363840, shift:37), (scale:1941939968, shift:38), (scale:1134922112, shift:37), (scale:1322422528, shift:37), (scale:1349955072, shift:37), (scale:2142559232, shift:38), (scale:1213446272, shift:37), (scale:1076710272, shift:37), (scale:1197436800, shift:37), (scale:2025992576, shift:38), (scale:1132253696, shift:37), (scale:1151798656, shift:37), (scale:1741811840, shift:38), (scale:1472237696, shift:37), (scale:1945139584, shift:38), (scale:2004086912, shift:38), (scale:1158968064, shift:37), (scale:1331554304, shift:37), (scale:2059459712, shift:38), (scale:1826549760, shift:38), (scale:1309050496, shift:37), (scale:1278068608, shift:37), (scale:1465158784, shift:37), (scale:1969339520, shift:38), (scale:1781134208, shift:38), (scale:1081625472, shift:37), (scale:1401820288, shift:38), (scale:1138978432, shift:37), (scale:1437350400, shift:37), (scale:1752152832, shift:38), (scale:2023836032, shift:38), (scale:1261702272, shift:37), (scale:2069750144, shift:38), (scale:1704135424, shift:38), (scale:1183723520, shift:37), (scale:1783816064, shift:37), (scale:1640697856, shift:38), (scale:2132520064, shift:38), (scale:1130913408, shift:37), (scale:2000672128, shift:38), (scale:2056496896, shift:38), (scale:1687575424, shift:38), (scale:1778191872, shift:38), (scale:1227293824, shift:37), (scale:1932541952, shift:38), (scale:2127057408, shift:38), (scale:1173656704, shift:37), (scale:1674942464, shift:38), (scale:1131779456, shift:37), (scale:1077545856, shift:37), (scale:1163039104, shift:37), (scale:1117279872, shift:37), (scale:1211461888, shift:37), (scale:1098282496, shift:37), (scale:2108566528, shift:38), (scale:1250008960, shift:37), (scale:1251099520, shift:37), (scale:1328415616, shift:37), (scale:2087376384, shift:38), (scale:1938866688, shift:38), (scale:1269583104, shift:37), (scale:1581113216, shift:38), (scale:1269816064, shift:37)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/conv2d_4/Conv2D
    Input 02 Int32 scale: [(scale:1654142720, shift:42), (scale:1632966656, shift:42), (scale:1455493120, shift:42), (scale:1701258880, shift:42), (scale:1982323712, shift:42), (scale:2023595264, shift:42), (scale:1605858176, shift:42), (scale:1818967296, shift:42), (scale:1613998848, shift:42), (scale:1794968960, shift:42), (scale:1518490880, shift:42), (scale:1697258880, shift:42), (scale:1726556928, shift:42), (scale:1305496192, shift:42), (scale:1103449088, shift:41), (scale:1457891200, shift:42), (scale:1502072576, shift:42), (scale:1737303936, shift:42), (scale:1996012416, shift:42), (scale:1543574656, shift:42), (scale:1369007616, shift:42), (scale:1962278912, shift:42), (scale:1915836800, shift:42), (scale:1098143360, shift:41), (scale:1476029184, shift:42), (scale:1334968448, shift:42), (scale:1621366656, shift:42), (scale:2101341696, shift:43), (scale:1707339392, shift:42), (scale:1077300864, shift:41), (scale:1313246720, shift:42), (scale:1516874624, shift:42), (scale:1891303552, shift:42), (scale:1551287424, shift:42), (scale:1277257472, shift:42), (scale:1774412672, shift:42), (scale:1336978560, shift:41), (scale:1229710720, shift:42), (scale:1598333824, shift:42), (scale:1695249792, shift:42), (scale:1499513088, shift:42), (scale:1541354112, shift:42), (scale:1264845696, shift:42), (scale:1332763136, shift:42), (scale:1839724928, shift:42), (scale:1448449280, shift:42), (scale:1594239488, shift:42), (scale:1759322368, shift:42), (scale:1255377280, shift:42), (scale:1696547968, shift:42), (scale:1615251328, shift:42), (scale:1743406464, shift:42), (scale:1674813056, shift:42), (scale:1815992704, shift:42), (scale:1646335744, shift:42), (scale:1580380544, shift:42), (scale:1873775104, shift:42), (scale:1875409920, shift:42), (scale:1991307520, shift:42), (scale:1564498432, shift:42), (scale:1453189632, shift:42), (scale:1903116928, shift:42), (scale:1185051776, shift:42), (scale:1903466240, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D
    Output 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
17 Relu functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
    Input 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
    Output 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
18 AvgPool functional_1/average_pooling2d/AvgPool
    Input 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
    Output 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/average_pooling2d/AvgPool
19 FullyConnected functional_1/dense/BiasAdd
    Input 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/average_pooling2d/AvgPool
    Input 01 Int8 scale: [(scale:1152529408, shift:37)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/MatMul
    Input 02 Int32 scale: [(scale:1479592576, shift:41)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/ReadVariableOp/resource
    Output 00 Int8 scale: [(scale:1242899200, shift:33)], zero_point: [14], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd
20 MaxPool functional_1/dense/BiasAdd/maxpool
    Input 00 Int8 scale: [(scale:1242899200, shift:33)], zero_point: [14], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd
    Output 00 Int8 scale: [], zero_point: [14], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/maxpool
21 Sub functional_1/dense/BiasAdd/Sub
    Input 00 Int8 scale: [(scale:1242899200, shift:33)], zero_point: [14], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd
    Input 01 Int8 scale: [], zero_point: [14], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/maxpool
    Output 00 Int8 scale: [(scale:1, shift:0)], zero_point: [127], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub
22 LUT functional_1/dense/BiasAdd/Sub/lut
    Input 00 Int8 scale: [(scale:1, shift:0)], zero_point: [127], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 exp_lut
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [127], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut
23 Asr functional_1/dense/BiasAdd/Sub/lut/Asr
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 right_shift12
    Output 00 Int32 scale: [], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr
24 ReduceSum functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr
    Output 00 Int32 scale: [], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
25 CLZ functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
    Output 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
26 Sub headroom_offset/Sub
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 headroom_offset
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
    Output 00 Int32 scale: [], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 headroom_offset/Sub
27 Sub functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ/Sub
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 one_const
    Output 00 Int32 scale: [], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ/Sub
28 SHL functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ/Sub
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [-9223372036854775808], quantMax: [9223372036854775807], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
29 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 neg_32_over_17
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul
30 Add functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
    Input 00 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 const_48_over_17
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
31 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
32 Sub F2_one/Sub
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one
    Input 01 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
33 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
34 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul
    Input 00 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 four
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul
35 Add functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
36 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
37 Sub F2_one/Sub
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one
    Input 01 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
38 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
39 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul
    Input 00 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 four
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul
40 Add functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
41 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
42 Sub F2_one/Sub
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one
    Input 01 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
43 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
44 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul
    Input 00 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 four
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul
45 Add functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add
46 Mul functional_1/dense/BiasAdd/Sub/lut/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Mul
47 Asr Identity
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Mul
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 headroom_offset/Sub
    Output 00 Int8 scale: [(scale:1073741824, shift:38)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 Identity

Schedule: 'graph_MIN_BUFFERED'
	0: Operation Conv2D  - OFM 1, 25, 5, 64
		Kernel: size=4,10 stride=2,2, dilation=1,1 padding=[t:4,l:1,b:5,r:1,n:0,f:0]
		Time index = 0
		Operator Config = OFM Block=[1, 10, 6, 32], IFM Block=[1, 26, 14, 16], OFM UBlock=[2, 2, 8] Traversal=PartKernel, AccType=Acc32
		IFM Stripe   = [1, 49, 10, 1]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 25, 5, 64]
		Assigned Cascade = 0
		Encoded Weights = 4960 bytes
		Weight buffer = 4960 bytes
		Depth slices = [0, 16, 64]
		sub-operations: [ Relu ]
		Estimated Perf: Macs=320000 Cycles=13031
		Memory Used: 12960 bytes
	1: Operation DepthwiseConv2D  - OFM 1, 25, 5, 64
		Kernel: size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0]
		Time index = 2
		Operator Config = OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
		IFM Stripe   = [1, 25, 5, 64]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 25, 5, 64]
		Assigned Cascade = 0
		Encoded Weights = 1312 bytes
		Weight buffer = 0 bytes
		Depth slices = [0, 64]
		sub-operations: [ Relu ]
		Estimated Perf: Macs=72000 Cycles=5134
		Memory Used: 16000 bytes
	2: Operation Conv2D  - OFM 1, 25, 5, 64
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 4
		Operator Config = OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 25, 5, 64]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 25, 5, 64]
		Assigned Cascade = 0
		Encoded Weights = 4752 bytes
		Weight buffer = 4752 bytes
		Depth slices = [0, 64]
		sub-operations: [ Relu ]
		Estimated Perf: Macs=512000 Cycles=3566
		Memory Used: 20752 bytes
	3: Operation DepthwiseConv2D  - OFM 1, 25, 5, 64
		Kernel: size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0]
		Time index = 6
		Operator Config = OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
		IFM Stripe   = [1, 25, 5, 64]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 25, 5, 64]
		Assigned Cascade = 0
		Encoded Weights = 1296 bytes
		Weight buffer = 0 bytes
		Depth slices = [0, 64]
		sub-operations: [ Relu ]
		Estimated Perf: Macs=72000 Cycles=5134
		Memory Used: 16000 bytes
	4: Operation Conv2D  - OFM 1, 25, 5, 64
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 8
		Operator Config = OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 25, 5, 64]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 25, 5, 64]
		Assigned Cascade = 0
		Encoded Weights = 4752 bytes
		Weight buffer = 4752 bytes
		Depth slices = [0, 64]
		sub-operations: [ Relu ]
		Estimated Perf: Macs=512000 Cycles=3566
		Memory Used: 20752 bytes
	5: Operation DepthwiseConv2D  - OFM 1, 25, 5, 64
		Kernel: size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0]
		Time index = 10
		Operator Config = OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
		IFM Stripe   = [1, 25, 5, 64]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 25, 5, 64]
		Assigned Cascade = 0
		Encoded Weights = 1296 bytes
		Weight buffer = 0 bytes
		Depth slices = [0, 64]
		sub-operations: [ Relu ]
		Estimated Perf: Macs=72000 Cycles=5134
		Memory Used: 16000 bytes
	6: Operation Conv2D  - OFM 1, 25, 5, 64
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 12
		Operator Config = OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 25, 5, 64]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 25, 5, 64]
		Assigned Cascade = 0
		Encoded Weights = 4752 bytes
		Weight buffer = 4752 bytes
		Depth slices = [0, 64]
		sub-operations: [ Relu ]
		Estimated Perf: Macs=512000 Cycles=3566
		Memory Used: 20752 bytes
	7: Operation DepthwiseConv2D  - OFM 1, 25, 5, 64
		Kernel: size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0]
		Time index = 14
		Operator Config = OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
		IFM Stripe   = [1, 25, 5, 64]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 25, 5, 64]
		Assigned Cascade = 0
		Encoded Weights = 1296 bytes
		Weight buffer = 0 bytes
		Depth slices = [0, 64]
		sub-operations: [ Relu ]
		Estimated Perf: Macs=72000 Cycles=5134
		Memory Used: 16000 bytes
	8: Operation Conv2D  - OFM 1, 25, 5, 64
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 16
		Operator Config = OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 25, 5, 64]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 25, 5, 64]
		Assigned Cascade = 0
		Encoded Weights = 4720 bytes
		Weight buffer = 4720 bytes
		Depth slices = [0, 64]
		sub-operations: [ Relu ]
		Estimated Perf: Macs=512000 Cycles=3566
		Memory Used: 20720 bytes
	9: Operation AvgPool  - OFM 1, 1, 1, 64
		Kernel: size=5,25 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 18
		Operator Config = OFM Block=[1, 2, 64], IFM Block=[1, 8, 6, 64], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 25, 5, 64]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 1, 1, 64]
		Assigned Cascade = 0
		sub-operations: -
		Estimated Perf: Macs=8000 Cycles=2767
		Memory Used: 8064 bytes
	10: Operation FullyConnected  - OFM 1, 1, 1, 12
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 20
		Operator Config = OFM Block=[1, 1, 4, 16], IFM Block=[1, 1, 4, 64], OFM UBlock=[1, 4, 8] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 64]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 1, 1, 12]
		Assigned Cascade = 0
		Encoded Weights = 1072 bytes
		Weight buffer = 0 bytes
		Depth slices = [0, 12]
		sub-operations: -
		Estimated Perf: Macs=768 Cycles=532
		Memory Used: 80 bytes
	11: Operation MaxPool  - OFM 1, 1, 1, 1
		Kernel: size=12,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 22
		Operator Config = OFM Block=[1, 2, 16], IFM Block=[1, 2, 10, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 12, 1]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: -
		Estimated Perf: Macs=12 Cycles=404
		Memory Used: 32 bytes
	12: Operation Sub  - OFM 1, 1, 1, 12
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 24
		Operator Config = OFM Block=[1, 128, 16], IFM Block=[1, 128, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 12]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 12]
		Assigned Cascade = 0
		sub-operations: [ LUT ]
		Estimated Perf: Macs=0 Cycles=4
		Memory Used: 96 bytes
	13: Operation Asr  - OFM 1, 1, 1, 12
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 26
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 12]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 12]
		Assigned Cascade = 0
		sub-operations: -
		Estimated Perf: Macs=0 Cycles=5
		Memory Used: 112 bytes
	14: Operation ReduceSum  - OFM 1, 1, 1, 1
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 28
		Operator Config = OFM Block=[1, 4, 16], IFM Block=[1, 1, 4, 32], OFM UBlock=[1, 4, 8] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 12]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: -
		Estimated Perf: Macs=12 Cycles=442
		Memory Used: 176 bytes
	15: Operation CLZ  - OFM 1, 1, 1, 1
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 30
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 1]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: -
		Estimated Perf: Macs=0 Cycles=6
		Memory Used: 192 bytes
	16: Operation Sub  - OFM 1, 1, 1, 1
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 32
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 1]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: -
		Estimated Perf: Macs=0 Cycles=6
		Memory Used: 256 bytes
	17: Operation Sub  - OFM 1, 1, 1, 1
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 34
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 1]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: [ SHL ]
		Estimated Perf: Macs=0 Cycles=6
		Memory Used: 320 bytes
	18: Operation Mul  - OFM 1, 1, 1, 1
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 36
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 1]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: [ Add ]
		Estimated Perf: Macs=0 Cycles=6
		Memory Used: 256 bytes
	19: Operation Mul  - OFM 1, 1, 1, 1
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 38
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 1]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: [ Sub Mul Mul ]
		Estimated Perf: Macs=0 Cycles=6
		Memory Used: 320 bytes
	20: Operation Add  - OFM 1, 1, 1, 1
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 40
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 1]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: -
		Estimated Perf: Macs=0 Cycles=6
		Memory Used: 320 bytes
	21: Operation Mul  - OFM 1, 1, 1, 1
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 42
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 1]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: [ Sub Mul Mul ]
		Estimated Perf: Macs=0 Cycles=6
		Memory Used: 320 bytes
	22: Operation Add  - OFM 1, 1, 1, 1
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 44
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 1]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: -
		Estimated Perf: Macs=0 Cycles=6
		Memory Used: 320 bytes
	23: Operation Mul  - OFM 1, 1, 1, 1
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 46
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 1]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: [ Sub Mul Mul ]
		Estimated Perf: Macs=0 Cycles=6
		Memory Used: 320 bytes
	24: Operation Add  - OFM 1, 1, 1, 1
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 48
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 1]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: -
		Estimated Perf: Macs=0 Cycles=6
		Memory Used: 256 bytes
	25: Operation Mul  - OFM 1, 1, 1, 12
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 50
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 12]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 12]
		Assigned Cascade = 0
		sub-operations: [ Asr ]
		Estimated Perf: Macs=0 Cycles=6
		Memory Used: 192 bytes
	Cascades:
################################################################################
Allocation, memory Dram, usage mask: FeatureMap
Start Time - End Time  : Start Addr -   End Addr: Tensor Size: Memory Usage : Name
         0 -          1:        0x0 -      0x1f0:         496:          496 : input_1
        50 -         53:        0x0 -       0x10:          16:           16 : Identity
Allocation Peak Tensor Size: 496 bytes == 0.484375 KiB
################################################################################
Allocation, memory Sram, usage mask: Staging
Start Time - End Time  : Start Addr -   End Addr: Tensor Size: Memory Usage : Name
         0 -          1:     0x1f40 -     0x32a0:        4960:        12960 : functional_1/conv2d/Conv2D
         0 -          3:        0x0 -     0x1f40:        8000:        20752 : functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
         2 -          5:     0x1f40 -     0x3e80:        8000:        20752 : functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
         3 -          5:     0x3e80 -     0x5110:        4752:        20752 : functional_1/conv2d_1/Conv2D
         4 -          7:        0x0 -     0x1f40:        8000:        20752 : functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
         6 -          9:     0x1f40 -     0x3e80:        8000:        20752 : functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
         7 -          9:     0x3e80 -     0x5110:        4752:        20752 : functional_1/conv2d_2/Conv2D
         8 -         11:        0x0 -     0x1f40:        8000:        20752 : functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
        10 -         13:     0x1f40 -     0x3e80:        8000:        20752 : functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
        11 -         13:     0x3e80 -     0x5110:        4752:        20752 : functional_1/conv2d_3/Conv2D
        12 -         15:        0x0 -     0x1f40:        8000:        20752 : functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
        14 -         17:     0x1f40 -     0x3e80:        8000:        20720 : functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
        15 -         17:     0x3e80 -     0x50f0:        4720:        20720 : functional_1/conv2d_4/Conv2D
        16 -         19:        0x0 -     0x1f40:        8000:        20720 : functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
        18 -         21:     0x1f40 -     0x1f80:          64:         8064 : functional_1/average_pooling2d/AvgPool
        20 -         25:       0x40 -       0x50:          16:           96 : functional_1/dense/BiasAdd
        22 -         25:       0x50 -       0x60:          16:           96 : functional_1/dense/BiasAdd/maxpool
        24 -         51:        0x0 -       0x40:          64:          320 : functional_1/dense/BiasAdd/Sub/lut
        26 -         29:       0x40 -       0x70:          48:          176 : functional_1/dense/BiasAdd/Sub/lut/Asr
        28 -         35:       0xc0 -      0x100:          64:          320 : functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
        30 -         35:      0x100 -      0x140:          64:          320 : functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
        32 -         51:       0x40 -       0x80:          64:          320 : headroom_offset/Sub
        34 -         47:       0x80 -       0xc0:          64:          320 : functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
        36 -         41:      0x100 -      0x140:          64:          320 : functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
        38 -         45:       0xc0 -      0x100:          64:          320 : functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
        38 -         45:       0xc0 -      0x100:          64:          320 : functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul
        42 -         49:      0x100 -      0x140:          64:          320 : functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
        42 -         49:      0x100 -      0x140:          64:          320 : functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul
        46 -         51:       0xc0 -      0x100:          64:          320 : functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add
        46 -         51:       0xc0 -      0x100:          64:          320 : functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul
Allocation Peak Tensor Size: 20752 bytes == 20.265625 KiB
################################################################################
Tensor Allocation for read-only NPU tensors:
Start Time - End Time  : Start Addr -   End Addr: Tensor Size: Memory Usage : Name
         0 -          1:        0x0 -     0x1360:        4960:         4960 : functional_1/conv2d/Conv2D
         2 -          3:     0x1360 -     0x1880:        1312:         1312 : functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource
         4 -          5:     0x1880 -     0x2b10:        4752:         4752 : functional_1/conv2d_1/Conv2D
         6 -          7:     0x2b10 -     0x3020:        1296:         1296 : functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource
         8 -          9:     0x3020 -     0x42b0:        4752:         4752 : functional_1/conv2d_2/Conv2D
        10 -         11:     0x42b0 -     0x47c0:        1296:         1296 : functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource
        12 -         13:     0x47c0 -     0x5a50:        4752:         4752 : functional_1/conv2d_3/Conv2D
        14 -         15:     0x5a50 -     0x5f60:        1296:         1296 : functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource
        16 -         17:     0x5f60 -     0x71d0:        4720:         4720 : functional_1/conv2d_4/Conv2D
        20 -         21:     0x71d0 -     0x7600:        1072:         1072 : functional_1/dense/MatMul
        24 -         25:     0x7600 -     0x7a00:        1024:         1024 : exp_lut
        26 -         27:     0x7a00 -     0x7a10:          16:           16 : right_shift12
        32 -         33:     0x7a10 -     0x7a20:          16:           16 : headroom_offset
        34 -         35:     0x7a20 -     0x7a30:          16:           16 : one_const
        36 -         37:     0x7a30 -     0x7a40:          16:           32 : neg_32_over_17
        36 -         37:     0x7a40 -     0x7a50:          16:           32 : const_48_over_17
        38 -         47:     0x7a50 -     0x7a60:          16:           32 : F2_one
        38 -         47:     0x7a60 -     0x7a70:          16:           32 : four
Allocation Peak Tensor Size: 31344 bytes == 30.609375 KiB
High level NPU operations:
0 Conv2D , subOps: Relu, size=4,10 stride=2,2, dilation=1,1 padding=[t:4,l:1,b:5,r:1,n:0,f:0] OFM Block=[1, 10, 6, 32], IFM Block=[1, 26, 14, 16], OFM UBlock=[2, 2, 8] Traversal=PartKernel, AccType=Acc32
  IFM: input_1, [1, 49, 10, 1], format: 1, Dram:FeatureMap, address: 0x0
  OFM: functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1, [1, 25, 5, 64], format: 2, Sram:Staging, address: 0x0
  Weights: functional_1/conv2d/Conv2D, 2 ranges, buffering: 2, Sram:Staging, address: 0x1f40, format: Default|Sparse2_4
1 DepthwiseConv2D , subOps: Relu, size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0] OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
  IFM: functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1, [1, 25, 5, 64], format: 2, Sram:Staging, address: 0x0
  OFM: functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1, [1, 25, 5, 64], format: 2, Sram:Staging, address: 0x1f40
  Weights: functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource, 1 ranges, buffering: 0, Dram:ReadOnly, address: 0x1360, format: Default
2 Conv2D , subOps: Relu, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1, [1, 25, 5, 64], format: 2, Sram:Staging, address: 0x1f40
  OFM: functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1, [1, 25, 5, 64], format: 2, Sram:Staging, address: 0x0
  Weights: functional_1/conv2d_1/Conv2D, 1 ranges, buffering: 1, Sram:Staging, address: 0x3e80, format: Default
3 DepthwiseConv2D , subOps: Relu, size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0] OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
  IFM: functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1, [1, 25, 5, 64], format: 2, Sram:Staging, address: 0x0
  OFM: functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1, [1, 25, 5, 64], format: 2, Sram:Staging, address: 0x1f40
  Weights: functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource, 1 ranges, buffering: 0, Dram:ReadOnly, address: 0x2b10, format: Default
4 Conv2D , subOps: Relu, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1, [1, 25, 5, 64], format: 2, Sram:Staging, address: 0x1f40
  OFM: functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1, [1, 25, 5, 64], format: 2, Sram:Staging, address: 0x0
  Weights: functional_1/conv2d_2/Conv2D, 1 ranges, buffering: 1, Sram:Staging, address: 0x3e80, format: Default
5 DepthwiseConv2D , subOps: Relu, size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0] OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
  IFM: functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1, [1, 25, 5, 64], format: 2, Sram:Staging, address: 0x0
  OFM: functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1, [1, 25, 5, 64], format: 2, Sram:Staging, address: 0x1f40
  Weights: functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource, 1 ranges, buffering: 0, Dram:ReadOnly, address: 0x42b0, format: Default
6 Conv2D , subOps: Relu, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1, [1, 25, 5, 64], format: 2, Sram:Staging, address: 0x1f40
  OFM: functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1, [1, 25, 5, 64], format: 2, Sram:Staging, address: 0x0
  Weights: functional_1/conv2d_3/Conv2D, 1 ranges, buffering: 1, Sram:Staging, address: 0x3e80, format: Default
7 DepthwiseConv2D , subOps: Relu, size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0] OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
  IFM: functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1, [1, 25, 5, 64], format: 2, Sram:Staging, address: 0x0
  OFM: functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1, [1, 25, 5, 64], format: 2, Sram:Staging, address: 0x1f40
  Weights: functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource, 1 ranges, buffering: 0, Dram:ReadOnly, address: 0x5a50, format: Default
8 Conv2D , subOps: Relu, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1, [1, 25, 5, 64], format: 2, Sram:Staging, address: 0x1f40
  OFM: functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1, [1, 25, 5, 64], format: 2, Sram:Staging, address: 0x0
  Weights: functional_1/conv2d_4/Conv2D, 1 ranges, buffering: 1, Sram:Staging, address: 0x3e80, format: Default
9 AvgPool , subOps: -, size=5,25 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 2, 64], IFM Block=[1, 8, 6, 64], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1, [1, 25, 5, 64], format: 2, Sram:Staging, address: 0x0
  OFM: functional_1/average_pooling2d/AvgPool, [1, 1, 1, 64], format: 2, Sram:Staging, address: 0x1f40
10 FullyConnected , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 1, 4, 16], IFM Block=[1, 1, 4, 64], OFM UBlock=[1, 4, 8] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/average_pooling2d/AvgPool, [1, 1, 1, 64], format: 2, Sram:Staging, address: 0x1f40
  OFM: functional_1/dense/BiasAdd, [1, 1, 1, 12], format: 1, Sram:Staging, address: 0x40
  Weights: functional_1/dense/MatMul, 1 ranges, buffering: 0, Dram:ReadOnly, address: 0x71d0, format: Default
11 MaxPool , subOps: -, size=12,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 2, 16], IFM Block=[1, 2, 10, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd, [1, 1, 12, 1], format: 1, Sram:Staging, address: 0x40
  OFM: functional_1/dense/BiasAdd/maxpool, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0x50
12 Sub , subOps: LUT, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 128, 16], IFM Block=[1, 128, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd, [1, 1, 1, 12], format: 1, Sram:Staging, address: 0x40
  IFM2: functional_1/dense/BiasAdd/maxpool, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0x50
  OFM: functional_1/dense/BiasAdd/Sub/lut, [1, 1, 1, 12], format: 2, Sram:Staging, address: 0x0
13 Asr , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut, [1, 1, 1, 12], format: 2, Sram:Staging, address: 0x0
  IFM2: right_shift12, [1, 1, 1, 1], format: 1, Dram:ReadOnly, address: 0x7a00
  OFM: functional_1/dense/BiasAdd/Sub/lut/Asr, [1, 1, 1, 12], format: 1, Sram:Staging, address: 0x40
14 ReduceSum , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 4, 16], IFM Block=[1, 1, 4, 32], OFM UBlock=[1, 4, 8] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut/Asr, [1, 1, 1, 12], format: 1, Sram:Staging, address: 0x40
  OFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0xc0
15 CLZ , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0xc0
  OFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0x100
16 Sub , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: headroom_offset, [1, 1, 1, 1], format: 1, Dram:ReadOnly, address: 0x7a10
  IFM2: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0x100
  OFM: headroom_offset/Sub, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0x40
17 Sub , subOps: SHL, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0x100
  IFM2: one_const, [1, 1, 1, 1], format: 1, Dram:ReadOnly, address: 0x7a20
  OFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ/Sub, [1, 1, 1, 1], format: 2, Dram:FeatureMap, address: 0x-1
18 Mul , subOps: Add, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0x80
  IFM2: neg_32_over_17, [1, 1, 1, 1], format: 1, Dram:ReadOnly, address: 0x7a30
  OFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul, [1, 1, 1, 1], format: 2, Dram:FeatureMap, address: 0x-1
19 Mul , subOps: Sub Mul Mul, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0x100
  IFM2: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0x80
  OFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul, [1, 1, 1, 1], format: 2, Dram:FeatureMap, address: 0x-1
20 Add , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0x100
  IFM2: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0xc0
  OFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0xc0
21 Mul , subOps: Sub Mul Mul, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0xc0
  IFM2: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0x80
  OFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul, [1, 1, 1, 1], format: 2, Dram:FeatureMap, address: 0x-1
22 Add , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0xc0
  IFM2: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0x100
  OFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0x100
23 Mul , subOps: Sub Mul Mul, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0x100
  IFM2: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0x80
  OFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul, [1, 1, 1, 1], format: 2, Dram:FeatureMap, address: 0x-1
24 Add , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0x100
  IFM2: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0xc0
  OFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0xc0
25 Mul , subOps: Asr, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut, [1, 1, 1, 12], format: 2, Sram:Staging, address: 0x0
  IFM2: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add, [1, 1, 1, 1], format: 2, Sram:Staging, address: 0xc0
  OFM: functional_1/dense/BiasAdd/Sub/lut/Mul, [1, 1, 1, 12], format: 2, Dram:FeatureMap, address: 0x-1
High level command stream:
0 DMA src: Dram:ReadOnly, address: 0x0, dest: Sram:Staging, address: 0x1f40, sizes: (N/A), length: 1248
1 Conv2D OFM area [0, 0, 0, 0 - 1, 25, 5, 16], IFM [0, 0, 0, 0 - 1, 49, 10, 1], Weight depth: 0, padding: [top:4,left:1,bottom:5,right:1], buffered
2 DMA src: Dram:ReadOnly, address: 0x4e0, dest: Sram:Staging, address: 0x2420, sizes: (N/A), length: 3712
3 Conv2D OFM area [0, 0, 0, 16 - 1, 25, 5, 64], IFM [0, 0, 0, 0 - 1, 49, 10, 1], Weight depth: 16, padding: [top:4,left:1,bottom:5,right:1], buffered
4 DepthwiseConv2D OFM area [0, 0, 0, 0 - 1, 25, 5, 64], IFM [0, 0, 0, 0 - 1, 25, 5, 64], padding: [top:1,left:1,bottom:1,right:1]
5 DMA src: Dram:ReadOnly, address: 0x1880, dest: Sram:Staging, address: 0x3e80, sizes: (N/A), length: 4752
6 Conv2D OFM area [0, 0, 0, 0 - 1, 25, 5, 64], IFM [0, 0, 0, 0 - 1, 25, 5, 64], Weight depth: 0
7 DepthwiseConv2D OFM area [0, 0, 0, 0 - 1, 25, 5, 64], IFM [0, 0, 0, 0 - 1, 25, 5, 64], padding: [top:1,left:1,bottom:1,right:1]
8 DMA src: Dram:ReadOnly, address: 0x3020, dest: Sram:Staging, address: 0x3e80, sizes: (N/A), length: 4752
9 Conv2D OFM area [0, 0, 0, 0 - 1, 25, 5, 64], IFM [0, 0, 0, 0 - 1, 25, 5, 64], Weight depth: 0
10 DepthwiseConv2D OFM area [0, 0, 0, 0 - 1, 25, 5, 64], IFM [0, 0, 0, 0 - 1, 25, 5, 64], padding: [top:1,left:1,bottom:1,right:1]
11 DMA src: Dram:ReadOnly, address: 0x47c0, dest: Sram:Staging, address: 0x3e80, sizes: (N/A), length: 4752
12 Conv2D OFM area [0, 0, 0, 0 - 1, 25, 5, 64], IFM [0, 0, 0, 0 - 1, 25, 5, 64], Weight depth: 0
13 DepthwiseConv2D OFM area [0, 0, 0, 0 - 1, 25, 5, 64], IFM [0, 0, 0, 0 - 1, 25, 5, 64], padding: [top:1,left:1,bottom:1,right:1]
14 DMA src: Dram:ReadOnly, address: 0x5f60, dest: Sram:Staging, address: 0x3e80, sizes: (N/A), length: 4720
15 Conv2D OFM area [0, 0, 0, 0 - 1, 25, 5, 64], IFM [0, 0, 0, 0 - 1, 25, 5, 64], Weight depth: 0
16 AvgPool OFM area [0, 0, 0, 0 - 1, 1, 1, 64], IFM [0, 0, 0, 0 - 1, 25, 5, 64]
17 FullyConnected OFM area [0, 0, 0, 0 - 1, 1, 1, 12], IFM [0, 0, 0, 0 - 1, 1, 1, 64]
18 MaxPool OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 12, 1]
19 Sub OFM area [0, 0, 0, 0 - 1, 1, 1, 12], IFM [0, 0, 0, 0 - 1, 1, 1, 12], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
20 Asr OFM area [0, 0, 0, 0 - 1, 1, 1, 12], IFM [0, 0, 0, 0 - 1, 1, 1, 12], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
21 ReduceSum OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 1, 12]
22 CLZ OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 1, 1]
23 Sub OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 1, 1], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
24 Sub OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 1, 1], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
25 Mul OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 1, 1], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
26 Mul OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 1, 1], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
27 Add OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 1, 1], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
28 Mul OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 1, 1], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
29 Add OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 1, 1], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
30 Mul OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 1, 1], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
31 Add OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 1, 1], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
32 Mul OFM area [0, 0, 0, 0 - 1, 1, 1, 12], IFM [0, 0, 0, 0 - 1, 1, 1, 12], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
Register command stream: 1277 words
  Offset: Payload Param Code - Command                        Param, Fields
// DMA src: Dram:ReadOnly, address: 0x0, dest: Sram:Staging, address: 0x1f40, sizes: (N/A), length: 1248
0x000000:          0000 0130 - NPU_SET_DMA0_SRC_REGION            0, region = 0, region_mode = DMA_REGION_MODE_EXTERNAL, stride_mode = DMA_STRIDE_MODE_D1, idx_mode = DMA_IDX_MODE_DISABLED
0x000004: 00000000 0000 4030 - NPU_SET_DMA0_SRC                   0, addr = 0x0
0x00000c:          0002 0131 - NPU_SET_DMA0_DST_REGION            2, region = 2, region_mode = DMA_REGION_MODE_EXTERNAL, idx_mode = DMA_IDX_MODE_DISABLED
0x000010: 00001f40 0000 4031 - NPU_SET_DMA0_DST                   0, addr = 0x1f40
0x000018: 000004e0 0000 4032 - NPU_SET_DMA0_LEN                   0, addr = 0x4e0
0x000020:          0000 0010 - NPU_OP_DMA_START                   0
// Conv2D , subOps: Relu, size=4,10 stride=2,2, dilation=1,1 padding=[t:4,l:1,b:5,r:1,n:0,f:0] OFM Block=[1, 10, 6, 32], IFM Block=[1, 26, 14, 16], OFM UBlock=[2, 2, 8] Traversal=PartKernel, AccType=Acc32
0x000024: 51088c32 0025 4024 - NPU_SET_OFM_SCALE                 37, shift = 37, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1359514674
0x00002c:          0001 0105 - NPU_SET_IFM_PRECISION              1, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B8, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000030:          0001 010f - NPU_SET_IFM_REGION                 1, region = 1
0x000034: 00000000 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x0
0x00003c: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x000044: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x00004c: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x000054:          0030 010b - NPU_SET_IFM_HEIGHT0_M1            48, height_m1 = 48
0x000058:          0030 010c - NPU_SET_IFM_HEIGHT1_M1            48, height_m1 = 48
0x00005c:          0009 010a - NPU_SET_IFM_WIDTH0_M1              9, width_m1 = 9
0x000060:          0000 0104 - NPU_SET_IFM_DEPTH_M1               0, depth_m1 = 0
0x000064: 0000000a 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0xa
0x00006c: 00000001 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x1
0x000074: 00000001 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x1
0x00007c:          0053 0109 - NPU_SET_IFM_ZERO_POINT            83, zero_point = 83
0x000080:          0000 0107 - NPU_SET_IFM_UPSCALE                0, mode = IFM_UPSCALE_MODE_NONE
0x000084:          0004 0100 - NPU_SET_IFM_PAD_TOP                4, pad = 4
0x000088:          0001 0101 - NPU_SET_IFM_PAD_LEFT               1, pad = 1
0x00008c:          0005 0103 - NPU_SET_IFM_PAD_BOTTOM             5, pad = 5
0x000090:          0001 0102 - NPU_SET_IFM_PAD_RIGHT              1, pad = 1
0x000094:          0041 0114 - NPU_SET_OFM_PRECISION             65, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B8, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_PER_CHANNEL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000098:          0002 011f - NPU_SET_OFM_REGION                 2, region = 2
0x00009c: 00000000 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x0
0x0000a4: 00000000 0000 4011 - NPU_SET_OFM_BASE1                  0, addr = 0x0
0x0000ac: 00000000 0000 4012 - NPU_SET_OFM_BASE2                  0, addr = 0x0
0x0000b4: 00000000 0000 4013 - NPU_SET_OFM_BASE3                  0, addr = 0x0
0x0000bc:          0018 0112 - NPU_SET_OFM_HEIGHT_M1             24, height_m1 = 24
0x0000c0:          0004 0111 - NPU_SET_OFM_WIDTH_M1               4, width_m1 = 4
0x0000c4:          000f 0113 - NPU_SET_OFM_DEPTH_M1              15, depth_m1 = 15
0x0000c8:          0018 011b - NPU_SET_OFM_HEIGHT0_M1            24, height_m1 = 24
0x0000cc:          0018 011c - NPU_SET_OFM_HEIGHT1_M1            24, height_m1 = 24
0x0000d0:          0004 011a - NPU_SET_OFM_WIDTH0_M1              4, width_m1 = 4
0x0000d4: 00000140 0000 4015 - NPU_SET_OFM_STRIDE_Y               0, addr = 0x140
0x0000dc: 00000010 0000 4014 - NPU_SET_OFM_STRIDE_X               0, addr = 0x10
0x0000e4: 00000050 0000 4016 - NPU_SET_OFM_STRIDE_C               0, addr = 0x50
0x0000ec:          ff80 0118 - NPU_SET_OFM_ZERO_POINT         65408, zero_point = 65408
0x0000f0:          0009 0121 - NPU_SET_KERNEL_HEIGHT_M1           9, height_m1 = 9
0x0000f4:          0003 0120 - NPU_SET_KERNEL_WIDTH_M1            3, width_m1 = 3
0x0000f8:          0007 0122 - NPU_SET_KERNEL_STRIDE              7, stride_x_lsb = 1, stride_y_lsb = 1, weight_order = WEIGHT_ORDER_PART_KERNEL_FIRST, dilation_x = KERNEL_DILATION_NONE, dilation_y = KERNEL_DILATION_NONE, decomposition = KERNEL_DECOMPOSITION_D8X8, stride_x_msb = 0, stride_y_msb = 0
0x0000fc:          0010 012e - NPU_SET_WEIGHT_FORMAT             16, weight_format = WEIGHT_FORMAT_SWD, weight_sparsity = WEIGHT_SPARSITY_SPARSE_2_4
0x000100:          0002 0128 - NPU_SET_WEIGHT_REGION              2, region = 2
0x000104: 00001fe0 0000 4020 - NPU_SET_WEIGHT_BASE                0, addr = 0x1fe0
0x00010c: 00000440 0000 4021 - NPU_SET_WEIGHT_LENGTH              0, length = 1088
0x000114:          0002 0129 - NPU_SET_SCALE_REGION               2, region = 2
0x000118: 00001f40 0000 4022 - NPU_SET_SCALE_BASE                 0, addr = 0x1f40
0x000120: 000000a0 0000 4023 - NPU_SET_SCALE_LENGTH               0, length = 160
0x000128:          0000 0125 - NPU_SET_ACTIVATION                 0, activation_function = ACTIVATION_FUNCTION_LUT_NONE, table = 0, activation_clip_range = ACTIVATION_CLIP_RANGE_B16
0x00012c:          ff80 0126 - NPU_SET_ACTIVATION_MIN         65408, clip_boundary = 65408
0x000130:          007f 0127 - NPU_SET_ACTIVATION_MAX           127, clip_boundary = 127
0x000134:          0009 0116 - NPU_SET_OFM_BLK_HEIGHT_M1          9, height_m1 = 9
0x000138:          0005 0115 - NPU_SET_OFM_BLK_WIDTH_M1           5, width_m1 = 5
0x00013c:          001f 0117 - NPU_SET_OFM_BLK_DEPTH_M1          31, depth_m1 = 31
0x000140:          0300 0124 - NPU_SET_ACC_FORMAT               768, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U2X2
0x000144:          0000 012f - NPU_SET_BLOCKDEP                   0, blockdep = 0
0x000148:          0000 0011 - NPU_OP_DMA_WAIT                    0, k = 0
0x00014c:          0000 0002 - NPU_OP_CONV                        0, weights_ifm2 = 0
// DMA src: Dram:ReadOnly, address: 0x4e0, dest: Sram:Staging, address: 0x2420, sizes: (N/A), length: 3712
0x000150: 000004e0 0000 4030 - NPU_SET_DMA0_SRC                   0, addr = 0x4e0
0x000158: 00002420 0000 4031 - NPU_SET_DMA0_DST                   0, addr = 0x2420
0x000160: 00000e80 0000 4032 - NPU_SET_DMA0_LEN                   0, addr = 0xe80
0x000168:          0000 0010 - NPU_OP_DMA_START                   0
// Conv2D , subOps: Relu, size=4,10 stride=2,2, dilation=1,1 padding=[t:4,l:1,b:5,r:1,n:0,f:0] OFM Block=[1, 10, 6, 32], IFM Block=[1, 26, 14, 16], OFM UBlock=[2, 2, 8] Traversal=PartKernel, AccType=Acc32
0x00016c: 00000050 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x50
0x000174:          002f 0113 - NPU_SET_OFM_DEPTH_M1              47, depth_m1 = 47
0x000178: 00002600 0000 4020 - NPU_SET_WEIGHT_BASE                0, addr = 0x2600
0x000180: 00000ca0 0000 4021 - NPU_SET_WEIGHT_LENGTH              0, length = 3232
0x000188: 00002420 0000 4022 - NPU_SET_SCALE_BASE                 0, addr = 0x2420
0x000190: 000001e0 0000 4023 - NPU_SET_SCALE_LENGTH               0, length = 480
0x000198:          0007 012f - NPU_SET_BLOCKDEP                   7, blockdep = 7
0x00019c:          0000 0011 - NPU_OP_DMA_WAIT                    0, k = 0
0x0001a0:          0000 0002 - NPU_OP_CONV                        0, weights_ifm2 = 0
// DepthwiseConv2D , subOps: Relu, size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0] OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
0x0001a4: 42983810 0025 4024 - NPU_SET_OFM_SCALE                 37, shift = 37, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1117272080
0x0001ac:          0041 0105 - NPU_SET_IFM_PRECISION             65, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B8, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x0001b0:          0002 010f - NPU_SET_IFM_REGION                 2, region = 2
0x0001b4:          0018 010b - NPU_SET_IFM_HEIGHT0_M1            24, height_m1 = 24
0x0001b8:          0018 010c - NPU_SET_IFM_HEIGHT1_M1            24, height_m1 = 24
0x0001bc:          0004 010a - NPU_SET_IFM_WIDTH0_M1              4, width_m1 = 4
0x0001c0:          003f 0104 - NPU_SET_IFM_DEPTH_M1              63, depth_m1 = 63
0x0001c4: 00000140 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x140
0x0001cc: 00000010 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x10
0x0001d4: 00000050 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x50
0x0001dc:          ff80 0109 - NPU_SET_IFM_ZERO_POINT         65408, zero_point = 65408
0x0001e0:          0001 0100 - NPU_SET_IFM_PAD_TOP                1, pad = 1
0x0001e4:          0001 0103 - NPU_SET_IFM_PAD_BOTTOM             1, pad = 1
0x0001e8: 00001f40 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x1f40
0x0001f0:          003f 0113 - NPU_SET_OFM_DEPTH_M1              63, depth_m1 = 63
0x0001f4:          0002 0121 - NPU_SET_KERNEL_HEIGHT_M1           2, height_m1 = 2
0x0001f8:          0002 0120 - NPU_SET_KERNEL_WIDTH_M1            2, width_m1 = 2
0x0001fc:          0000 0122 - NPU_SET_KERNEL_STRIDE              0, stride_x_lsb = 0, stride_y_lsb = 0, weight_order = WEIGHT_ORDER_DEPTH_FIRST, dilation_x = KERNEL_DILATION_NONE, dilation_y = KERNEL_DILATION_NONE, decomposition = KERNEL_DECOMPOSITION_D8X8, stride_x_msb = 0, stride_y_msb = 0
0x000200:          0000 012e - NPU_SET_WEIGHT_FORMAT              0, weight_format = WEIGHT_FORMAT_SWD, weight_sparsity = WEIGHT_SPARSITY_NONE
0x000204:          0000 0128 - NPU_SET_WEIGHT_REGION              0, region = 0
0x000208: 000015e0 0000 4020 - NPU_SET_WEIGHT_BASE                0, addr = 0x15e0
0x000210: 000002a0 0000 4021 - NPU_SET_WEIGHT_LENGTH              0, length = 672
0x000218:          0000 0129 - NPU_SET_SCALE_REGION               0, region = 0
0x00021c: 00001360 0000 4022 - NPU_SET_SCALE_BASE                 0, addr = 0x1360
0x000224: 00000280 0000 4023 - NPU_SET_SCALE_LENGTH               0, length = 640
0x00022c:          0018 0116 - NPU_SET_OFM_BLK_HEIGHT_M1         24, height_m1 = 24
0x000230:          000f 0117 - NPU_SET_OFM_BLK_DEPTH_M1          15, depth_m1 = 15
0x000234:          0100 0124 - NPU_SET_ACC_FORMAT               256, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U1X2
0x000238:          0002 012f - NPU_SET_BLOCKDEP                   2, blockdep = 2
0x00023c:          0000 0003 - NPU_OP_DEPTHWISE                   0
// DMA src: Dram:ReadOnly, address: 0x1880, dest: Sram:Staging, address: 0x3e80, sizes: (N/A), length: 4752
0x000240: 00001880 0000 4030 - NPU_SET_DMA0_SRC                   0, addr = 0x1880
0x000248: 00003e80 0000 4031 - NPU_SET_DMA0_DST                   0, addr = 0x3e80
0x000250: 00001290 0000 4032 - NPU_SET_DMA0_LEN                   0, addr = 0x1290
0x000258:          0000 0010 - NPU_OP_DMA_START                   0
// Conv2D , subOps: Relu, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
0x00025c: 687cd140 0027 4024 - NPU_SET_OFM_SCALE                 39, shift = 39, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1753010496
0x000264: 00001f40 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x1f40
0x00026c:          0000 0100 - NPU_SET_IFM_PAD_TOP                0, pad = 0
0x000270:          0000 0101 - NPU_SET_IFM_PAD_LEFT               0, pad = 0
0x000274:          0000 0103 - NPU_SET_IFM_PAD_BOTTOM             0, pad = 0
0x000278:          0000 0102 - NPU_SET_IFM_PAD_RIGHT              0, pad = 0
0x00027c: 00000000 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x0
0x000284:          0000 0121 - NPU_SET_KERNEL_HEIGHT_M1           0, height_m1 = 0
0x000288:          0000 0120 - NPU_SET_KERNEL_WIDTH_M1            0, width_m1 = 0
0x00028c:          0002 0128 - NPU_SET_WEIGHT_REGION              2, region = 2
0x000290: 00004100 0000 4020 - NPU_SET_WEIGHT_BASE                0, addr = 0x4100
0x000298: 00001010 0000 4021 - NPU_SET_WEIGHT_LENGTH              0, length = 4112
0x0002a0:          0002 0129 - NPU_SET_SCALE_REGION               2, region = 2
0x0002a4: 00003e80 0000 4022 - NPU_SET_SCALE_BASE                 0, addr = 0x3e80
0x0002ac:          000f 0116 - NPU_SET_OFM_BLK_HEIGHT_M1         15, height_m1 = 15
0x0002b0:          0003 0115 - NPU_SET_OFM_BLK_WIDTH_M1           3, width_m1 = 3
0x0002b4:          001f 0117 - NPU_SET_OFM_BLK_DEPTH_M1          31, depth_m1 = 31
0x0002b8:          0300 0124 - NPU_SET_ACC_FORMAT               768, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U2X2
0x0002bc:          0000 012f - NPU_SET_BLOCKDEP                   0, blockdep = 0
0x0002c0:          0000 0011 - NPU_OP_DMA_WAIT                    0, k = 0
0x0002c4:          0000 0002 - NPU_OP_CONV                        0, weights_ifm2 = 0
// DepthwiseConv2D , subOps: Relu, size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0] OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
0x0002c8: 662b9af8 0026 4024 - NPU_SET_OFM_SCALE                 38, shift = 38, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1714133752
0x0002d0: 00000000 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x0
0x0002d8:          0001 0100 - NPU_SET_IFM_PAD_TOP                1, pad = 1
0x0002dc:          0001 0101 - NPU_SET_IFM_PAD_LEFT               1, pad = 1
0x0002e0:          0001 0103 - NPU_SET_IFM_PAD_BOTTOM             1, pad = 1
0x0002e4:          0001 0102 - NPU_SET_IFM_PAD_RIGHT              1, pad = 1
0x0002e8: 00001f40 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x1f40
0x0002f0:          0002 0121 - NPU_SET_KERNEL_HEIGHT_M1           2, height_m1 = 2
0x0002f4:          0002 0120 - NPU_SET_KERNEL_WIDTH_M1            2, width_m1 = 2
0x0002f8:          0000 0128 - NPU_SET_WEIGHT_REGION              0, region = 0
0x0002fc: 00002d90 0000 4020 - NPU_SET_WEIGHT_BASE                0, addr = 0x2d90
0x000304: 00000290 0000 4021 - NPU_SET_WEIGHT_LENGTH              0, length = 656
0x00030c:          0000 0129 - NPU_SET_SCALE_REGION               0, region = 0
0x000310: 00002b10 0000 4022 - NPU_SET_SCALE_BASE                 0, addr = 0x2b10
0x000318:          0018 0116 - NPU_SET_OFM_BLK_HEIGHT_M1         24, height_m1 = 24
0x00031c:          0005 0115 - NPU_SET_OFM_BLK_WIDTH_M1           5, width_m1 = 5
0x000320:          000f 0117 - NPU_SET_OFM_BLK_DEPTH_M1          15, depth_m1 = 15
0x000324:          0100 0124 - NPU_SET_ACC_FORMAT               256, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U1X2
0x000328:          0001 012f - NPU_SET_BLOCKDEP                   1, blockdep = 1
0x00032c:          0000 0003 - NPU_OP_DEPTHWISE                   0
// DMA src: Dram:ReadOnly, address: 0x3020, dest: Sram:Staging, address: 0x3e80, sizes: (N/A), length: 4752
0x000330: 00003020 0000 4030 - NPU_SET_DMA0_SRC                   0, addr = 0x3020
0x000338:          0001 0012 - NPU_OP_KERNEL_WAIT                 1, n = 1
0x00033c:          0000 0010 - NPU_OP_DMA_START                   0
// Conv2D , subOps: Relu, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
0x000340: 509db936 0026 4024 - NPU_SET_OFM_SCALE                 38, shift = 38, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1352513846
0x000348: 00001f40 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x1f40
0x000350:          0000 0100 - NPU_SET_IFM_PAD_TOP                0, pad = 0
0x000354:          0000 0101 - NPU_SET_IFM_PAD_LEFT               0, pad = 0
0x000358:          0000 0103 - NPU_SET_IFM_PAD_BOTTOM             0, pad = 0
0x00035c:          0000 0102 - NPU_SET_IFM_PAD_RIGHT              0, pad = 0
0x000360: 00000000 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x0
0x000368:          0000 0121 - NPU_SET_KERNEL_HEIGHT_M1           0, height_m1 = 0
0x00036c:          0000 0120 - NPU_SET_KERNEL_WIDTH_M1            0, width_m1 = 0
0x000370:          0002 0128 - NPU_SET_WEIGHT_REGION              2, region = 2
0x000374: 00004100 0000 4020 - NPU_SET_WEIGHT_BASE                0, addr = 0x4100
0x00037c: 00001010 0000 4021 - NPU_SET_WEIGHT_LENGTH              0, length = 4112
0x000384:          0002 0129 - NPU_SET_SCALE_REGION               2, region = 2
0x000388: 00003e80 0000 4022 - NPU_SET_SCALE_BASE                 0, addr = 0x3e80
0x000390:          000f 0116 - NPU_SET_OFM_BLK_HEIGHT_M1         15, height_m1 = 15
0x000394:          0003 0115 - NPU_SET_OFM_BLK_WIDTH_M1           3, width_m1 = 3
0x000398:          001f 0117 - NPU_SET_OFM_BLK_DEPTH_M1          31, depth_m1 = 31
0x00039c:          0300 0124 - NPU_SET_ACC_FORMAT               768, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U2X2
0x0003a0:          0000 012f - NPU_SET_BLOCKDEP                   0, blockdep = 0
0x0003a4:          0000 0011 - NPU_OP_DMA_WAIT                    0, k = 0
0x0003a8:          0000 0002 - NPU_OP_CONV                        0, weights_ifm2 = 0
// DepthwiseConv2D , subOps: Relu, size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0] OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
0x0003ac: 4616316a 0025 4024 - NPU_SET_OFM_SCALE                 37, shift = 37, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1175859562
0x0003b4: 00000000 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x0
0x0003bc:          0001 0100 - NPU_SET_IFM_PAD_TOP                1, pad = 1
0x0003c0:          0001 0101 - NPU_SET_IFM_PAD_LEFT               1, pad = 1
0x0003c4:          0001 0103 - NPU_SET_IFM_PAD_BOTTOM             1, pad = 1
0x0003c8:          0001 0102 - NPU_SET_IFM_PAD_RIGHT              1, pad = 1
0x0003cc: 00001f40 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x1f40
0x0003d4:          0002 0121 - NPU_SET_KERNEL_HEIGHT_M1           2, height_m1 = 2
0x0003d8:          0002 0120 - NPU_SET_KERNEL_WIDTH_M1            2, width_m1 = 2
0x0003dc:          0000 0128 - NPU_SET_WEIGHT_REGION              0, region = 0
0x0003e0: 00004530 0000 4020 - NPU_SET_WEIGHT_BASE                0, addr = 0x4530
0x0003e8: 00000290 0000 4021 - NPU_SET_WEIGHT_LENGTH              0, length = 656
0x0003f0:          0000 0129 - NPU_SET_SCALE_REGION               0, region = 0
0x0003f4: 000042b0 0000 4022 - NPU_SET_SCALE_BASE                 0, addr = 0x42b0
0x0003fc:          0018 0116 - NPU_SET_OFM_BLK_HEIGHT_M1         24, height_m1 = 24
0x000400:          0005 0115 - NPU_SET_OFM_BLK_WIDTH_M1           5, width_m1 = 5
0x000404:          000f 0117 - NPU_SET_OFM_BLK_DEPTH_M1          15, depth_m1 = 15
0x000408:          0100 0124 - NPU_SET_ACC_FORMAT               256, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U1X2
0x00040c:          0001 012f - NPU_SET_BLOCKDEP                   1, blockdep = 1
0x000410:          0000 0003 - NPU_OP_DEPTHWISE                   0
// DMA src: Dram:ReadOnly, address: 0x47c0, dest: Sram:Staging, address: 0x3e80, sizes: (N/A), length: 4752
0x000414: 000047c0 0000 4030 - NPU_SET_DMA0_SRC                   0, addr = 0x47c0
0x00041c:          0001 0012 - NPU_OP_KERNEL_WAIT                 1, n = 1
0x000420:          0000 0010 - NPU_OP_DMA_START                   0
// Conv2D , subOps: Relu, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
0x000424: 4d5375cd 0026 4024 - NPU_SET_OFM_SCALE                 38, shift = 38, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1297315277
0x00042c: 00001f40 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x1f40
0x000434:          0000 0100 - NPU_SET_IFM_PAD_TOP                0, pad = 0
0x000438:          0000 0101 - NPU_SET_IFM_PAD_LEFT               0, pad = 0
0x00043c:          0000 0103 - NPU_SET_IFM_PAD_BOTTOM             0, pad = 0
0x000440:          0000 0102 - NPU_SET_IFM_PAD_RIGHT              0, pad = 0
0x000444: 00000000 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x0
0x00044c:          0000 0121 - NPU_SET_KERNEL_HEIGHT_M1           0, height_m1 = 0
0x000450:          0000 0120 - NPU_SET_KERNEL_WIDTH_M1            0, width_m1 = 0
0x000454:          0002 0128 - NPU_SET_WEIGHT_REGION              2, region = 2
0x000458: 00004100 0000 4020 - NPU_SET_WEIGHT_BASE                0, addr = 0x4100
0x000460: 00001010 0000 4021 - NPU_SET_WEIGHT_LENGTH              0, length = 4112
0x000468:          0002 0129 - NPU_SET_SCALE_REGION               2, region = 2
0x00046c: 00003e80 0000 4022 - NPU_SET_SCALE_BASE                 0, addr = 0x3e80
0x000474:          000f 0116 - NPU_SET_OFM_BLK_HEIGHT_M1         15, height_m1 = 15
0x000478:          0003 0115 - NPU_SET_OFM_BLK_WIDTH_M1           3, width_m1 = 3
0x00047c:          001f 0117 - NPU_SET_OFM_BLK_DEPTH_M1          31, depth_m1 = 31
0x000480:          0300 0124 - NPU_SET_ACC_FORMAT               768, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U2X2
0x000484:          0000 012f - NPU_SET_BLOCKDEP                   0, blockdep = 0
0x000488:          0000 0011 - NPU_OP_DMA_WAIT                    0, k = 0
0x00048c:          0000 0002 - NPU_OP_CONV                        0, weights_ifm2 = 0
// DepthwiseConv2D , subOps: Relu, size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0] OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
0x000490: 4a3ccfbc 0026 4024 - NPU_SET_OFM_SCALE                 38, shift = 38, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1245499324
0x000498: 00000000 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x0
0x0004a0:          0001 0100 - NPU_SET_IFM_PAD_TOP                1, pad = 1
0x0004a4:          0001 0101 - NPU_SET_IFM_PAD_LEFT               1, pad = 1
0x0004a8:          0001 0103 - NPU_SET_IFM_PAD_BOTTOM             1, pad = 1
0x0004ac:          0001 0102 - NPU_SET_IFM_PAD_RIGHT              1, pad = 1
0x0004b0: 00001f40 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x1f40
0x0004b8:          0002 0121 - NPU_SET_KERNEL_HEIGHT_M1           2, height_m1 = 2
0x0004bc:          0002 0120 - NPU_SET_KERNEL_WIDTH_M1            2, width_m1 = 2
0x0004c0:          0000 0128 - NPU_SET_WEIGHT_REGION              0, region = 0
0x0004c4: 00005cd0 0000 4020 - NPU_SET_WEIGHT_BASE                0, addr = 0x5cd0
0x0004cc: 00000290 0000 4021 - NPU_SET_WEIGHT_LENGTH              0, length = 656
0x0004d4:          0000 0129 - NPU_SET_SCALE_REGION               0, region = 0
0x0004d8: 00005a50 0000 4022 - NPU_SET_SCALE_BASE                 0, addr = 0x5a50
0x0004e0:          0018 0116 - NPU_SET_OFM_BLK_HEIGHT_M1         24, height_m1 = 24
0x0004e4:          0005 0115 - NPU_SET_OFM_BLK_WIDTH_M1           5, width_m1 = 5
0x0004e8:          000f 0117 - NPU_SET_OFM_BLK_DEPTH_M1          15, depth_m1 = 15
0x0004ec:          0100 0124 - NPU_SET_ACC_FORMAT               256, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U1X2
0x0004f0:          0001 012f - NPU_SET_BLOCKDEP                   1, blockdep = 1
0x0004f4:          0000 0003 - NPU_OP_DEPTHWISE                   0
// DMA src: Dram:ReadOnly, address: 0x5f60, dest: Sram:Staging, address: 0x3e80, sizes: (N/A), length: 4720
0x0004f8: 00005f60 0000 4030 - NPU_SET_DMA0_SRC                   0, addr = 0x5f60
0x000500: 00001270 0000 4032 - NPU_SET_DMA0_LEN                   0, addr = 0x1270
0x000508:          0001 0012 - NPU_OP_KERNEL_WAIT                 1, n = 1
0x00050c:          0000 0010 - NPU_OP_DMA_START                   0
// Conv2D , subOps: Relu, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
0x000510: 4ccce0f6 0026 4024 - NPU_SET_OFM_SCALE                 38, shift = 38, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1288495350
0x000518: 00001f40 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x1f40
0x000520:          0000 0100 - NPU_SET_IFM_PAD_TOP                0, pad = 0
0x000524:          0000 0101 - NPU_SET_IFM_PAD_LEFT               0, pad = 0
0x000528:          0000 0103 - NPU_SET_IFM_PAD_BOTTOM             0, pad = 0
0x00052c:          0000 0102 - NPU_SET_IFM_PAD_RIGHT              0, pad = 0
0x000530: 00000000 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x0
0x000538:          0000 0121 - NPU_SET_KERNEL_HEIGHT_M1           0, height_m1 = 0
0x00053c:          0000 0120 - NPU_SET_KERNEL_WIDTH_M1            0, width_m1 = 0
0x000540:          0002 0128 - NPU_SET_WEIGHT_REGION              2, region = 2
0x000544: 00004100 0000 4020 - NPU_SET_WEIGHT_BASE                0, addr = 0x4100
0x00054c: 00000ff0 0000 4021 - NPU_SET_WEIGHT_LENGTH              0, length = 4080
0x000554:          0002 0129 - NPU_SET_SCALE_REGION               2, region = 2
0x000558: 00003e80 0000 4022 - NPU_SET_SCALE_BASE                 0, addr = 0x3e80
0x000560:          000f 0116 - NPU_SET_OFM_BLK_HEIGHT_M1         15, height_m1 = 15
0x000564:          0003 0115 - NPU_SET_OFM_BLK_WIDTH_M1           3, width_m1 = 3
0x000568:          001f 0117 - NPU_SET_OFM_BLK_DEPTH_M1          31, depth_m1 = 31
0x00056c:          0300 0124 - NPU_SET_ACC_FORMAT               768, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U2X2
0x000570:          0000 012f - NPU_SET_BLOCKDEP                   0, blockdep = 0
0x000574:          0000 0011 - NPU_OP_DMA_WAIT                    0, k = 0
0x000578:          0000 0002 - NPU_OP_CONV                        0, weights_ifm2 = 0
// AvgPool , subOps: -, size=5,25 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 2, 64], IFM Block=[1, 8, 6, 64], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x00057c: 00000000 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x0
0x000584:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000588:          0141 0114 - NPU_SET_OFM_PRECISION            321, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B8, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x00058c: 00001f40 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x1f40
0x000594:          0000 0112 - NPU_SET_OFM_HEIGHT_M1              0, height_m1 = 0
0x000598:          0000 0111 - NPU_SET_OFM_WIDTH_M1               0, width_m1 = 0
0x00059c:          0000 011b - NPU_SET_OFM_HEIGHT0_M1             0, height_m1 = 0
0x0005a0:          0000 011c - NPU_SET_OFM_HEIGHT1_M1             0, height_m1 = 0
0x0005a4:          0000 011a - NPU_SET_OFM_WIDTH0_M1              0, width_m1 = 0
0x0005a8: 00000040 0000 4015 - NPU_SET_OFM_STRIDE_Y               0, addr = 0x40
0x0005b0: 00000010 0000 4016 - NPU_SET_OFM_STRIDE_C               0, addr = 0x10
0x0005b8:          0000 0118 - NPU_SET_OFM_ZERO_POINT             0, zero_point = 0
0x0005bc:          0018 0121 - NPU_SET_KERNEL_HEIGHT_M1          24, height_m1 = 24
0x0005c0:          0004 0120 - NPU_SET_KERNEL_WIDTH_M1            4, width_m1 = 4
0x0005c4: 4189374c 2025 4024 - NPU_SET_OFM_SCALE               8229, shift = 37, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_NATURAL, scale = 1099511628
0x0005cc:          0000 0116 - NPU_SET_OFM_BLK_HEIGHT_M1          0, height_m1 = 0
0x0005d0:          0001 0115 - NPU_SET_OFM_BLK_WIDTH_M1           1, width_m1 = 1
0x0005d4:          003f 0117 - NPU_SET_OFM_BLK_DEPTH_M1          63, depth_m1 = 63
0x0005d8:          0100 0124 - NPU_SET_ACC_FORMAT               256, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U1X2
0x0005dc:          0003 0005 - NPU_OP_POOL                        3, pooling_mode = POOLING_MODE_SUM
// FullyConnected , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 1, 4, 16], IFM Block=[1, 1, 4, 64], OFM UBlock=[1, 4, 8] Traversal=DepthFirst, AccType=Acc32
0x0005e0: 4c301c95 0026 4024 - NPU_SET_OFM_SCALE                 38, shift = 38, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1278221461
0x0005e8: 00001f40 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x1f40
0x0005f0:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x0005f4:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x0005f8:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x0005fc: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x000604: 00000010 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x10
0x00060c:          ff80 0109 - NPU_SET_IFM_ZERO_POINT         65408, zero_point = 65408
0x000610:          0001 0114 - NPU_SET_OFM_PRECISION              1, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B8, activation_format = ACTIVATION_FORMAT_NHWC, scale_mode = OFM_SCALE_MODE_PER_CHANNEL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000614: 00000040 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x40
0x00061c:          000b 0113 - NPU_SET_OFM_DEPTH_M1              11, depth_m1 = 11
0x000620: 0000000c 0000 4015 - NPU_SET_OFM_STRIDE_Y               0, addr = 0xc
0x000628: 0000000c 0000 4014 - NPU_SET_OFM_STRIDE_X               0, addr = 0xc
0x000630: 00000001 0000 4016 - NPU_SET_OFM_STRIDE_C               0, addr = 0x1
0x000638:          000e 0118 - NPU_SET_OFM_ZERO_POINT            14, zero_point = 14
0x00063c:          0000 0121 - NPU_SET_KERNEL_HEIGHT_M1           0, height_m1 = 0
0x000640:          0000 0120 - NPU_SET_KERNEL_WIDTH_M1            0, width_m1 = 0
0x000644:          0000 0128 - NPU_SET_WEIGHT_REGION              0, region = 0
0x000648: 00007270 0000 4020 - NPU_SET_WEIGHT_BASE                0, addr = 0x7270
0x000650: 00000390 0000 4021 - NPU_SET_WEIGHT_LENGTH              0, length = 912
0x000658:          0000 0129 - NPU_SET_SCALE_REGION               0, region = 0
0x00065c: 000071d0 0000 4022 - NPU_SET_SCALE_BASE                 0, addr = 0x71d0
0x000664: 000000a0 0000 4023 - NPU_SET_SCALE_LENGTH               0, length = 160
0x00066c:          0003 0115 - NPU_SET_OFM_BLK_WIDTH_M1           3, width_m1 = 3
0x000670:          000f 0117 - NPU_SET_OFM_BLK_DEPTH_M1          15, depth_m1 = 15
0x000674:          0200 0124 - NPU_SET_ACC_FORMAT               512, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U1X4
0x000678:          0000 0002 - NPU_OP_CONV                        0, weights_ifm2 = 0
// MaxPool , subOps: -, size=12,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 2, 16], IFM Block=[1, 2, 10, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x00067c:          0001 0105 - NPU_SET_IFM_PRECISION              1, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B8, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000680: 00000040 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x40
0x000688:          000b 010a - NPU_SET_IFM_WIDTH0_M1             11, width_m1 = 11
0x00068c:          0000 0104 - NPU_SET_IFM_DEPTH_M1               0, depth_m1 = 0
0x000690: 0000000c 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0xc
0x000698: 00000001 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x1
0x0006a0: 00000001 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x1
0x0006a8:          000e 0109 - NPU_SET_IFM_ZERO_POINT            14, zero_point = 14
0x0006ac:          0141 0114 - NPU_SET_OFM_PRECISION            321, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B8, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x0006b0: 00000050 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x50
0x0006b8:          0000 0113 - NPU_SET_OFM_DEPTH_M1               0, depth_m1 = 0
0x0006bc: 00000010 0000 4015 - NPU_SET_OFM_STRIDE_Y               0, addr = 0x10
0x0006c4: 00000010 0000 4014 - NPU_SET_OFM_STRIDE_X               0, addr = 0x10
0x0006cc: 00000010 0000 4016 - NPU_SET_OFM_STRIDE_C               0, addr = 0x10
0x0006d4:          000b 0120 - NPU_SET_KERNEL_WIDTH_M1           11, width_m1 = 11
0x0006d8: 00000001 0000 4024 - NPU_SET_OFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1
0x0006e0:          0001 0115 - NPU_SET_OFM_BLK_WIDTH_M1           1, width_m1 = 1
0x0006e4:          0100 0124 - NPU_SET_ACC_FORMAT               256, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U1X2
0x0006e8:          0000 0005 - NPU_OP_POOL                        0, pooling_mode = POOLING_MODE_MAX
// DMA src: Dram:ReadOnly, address: 0x7600, dest: lutram:LUT, address: 0x0, sizes: (N/A), length: 1024
0x0006ec: 00007600 0000 4030 - NPU_SET_DMA0_SRC                   0, addr = 0x7600
0x0006f4:          0103 0131 - NPU_SET_DMA0_DST_REGION          259, region = 3, region_mode = DMA_REGION_MODE_INTERNAL, idx_mode = DMA_IDX_MODE_DISABLED
0x0006f8: 00000000 0000 4031 - NPU_SET_DMA0_DST                   0, addr = 0x0
0x000700: 00000400 0000 4032 - NPU_SET_DMA0_LEN                   0, addr = 0x400
0x000708:          0000 0010 - NPU_OP_DMA_START                   0
// Sub , subOps: LUT, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 128, 16], IFM Block=[1, 128, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x00070c: 00000001 0500 4025 - NPU_SET_IFM_SCALE               1280, shift = 0, dbl_rnd = 20, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000714: 00000001 0500 4026 - NPU_SET_IFM2_SCALE              1280, shift = 0, dbl_rnd = 20, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x00071c:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x000720:          000b 0104 - NPU_SET_IFM_DEPTH_M1              11, depth_m1 = 11
0x000724: 0000000c 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0xc
0x00072c:          0145 0114 - NPU_SET_OFM_PRECISION            325, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000730: 00000000 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x0
0x000738:          000b 0113 - NPU_SET_OFM_DEPTH_M1              11, depth_m1 = 11
0x00073c: 00000040 0000 4015 - NPU_SET_OFM_STRIDE_Y               0, addr = 0x40
0x000744: 00000040 0000 4014 - NPU_SET_OFM_STRIDE_X               0, addr = 0x40
0x00074c: 00000040 0000 4016 - NPU_SET_OFM_STRIDE_C               0, addr = 0x40
0x000754:          007f 0118 - NPU_SET_OFM_ZERO_POINT           127, zero_point = 127
0x000758:          0007 0125 - NPU_SET_ACTIVATION                 7, activation_function = ACTIVATION_FUNCTION_LUT_S8_S32, table = 0, activation_clip_range = ACTIVATION_CLIP_RANGE_B16
0x00075c:          0041 0185 - NPU_SET_IFM2_PRECISION            65, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B8, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000760:          0002 018f - NPU_SET_IFM2_REGION                2, region = 2
0x000764: 00000050 0000 4080 - NPU_SET_IFM2_BASE0                 0, addr = 0x50
0x00076c: 00000000 0000 4081 - NPU_SET_IFM2_BASE1                 0, addr = 0x0
0x000774: 00000000 0000 4082 - NPU_SET_IFM2_BASE2                 0, addr = 0x0
0x00077c: 00000000 0000 4083 - NPU_SET_IFM2_BASE3                 0, addr = 0x0
0x000784:          0000 018b - NPU_SET_IFM2_HEIGHT0_M1            0, height_m1 = 0
0x000788:          0000 018c - NPU_SET_IFM2_HEIGHT1_M1            0, height_m1 = 0
0x00078c:          0000 018a - NPU_SET_IFM2_WIDTH0_M1             0, width_m1 = 0
0x000790: 00000010 0000 4085 - NPU_SET_IFM2_STRIDE_Y              0, addr = 0x10
0x000798: 00000010 0000 4084 - NPU_SET_IFM2_STRIDE_X              0, addr = 0x10
0x0007a0: 00000010 0000 4086 - NPU_SET_IFM2_STRIDE_C              0, addr = 0x10
0x0007a8:          000e 0189 - NPU_SET_IFM2_ZERO_POINT           14, zero_point = 14
0x0007ac:          0000 0108 - NPU_SET_IFM_BROADCAST              0, broadcast_mode = BROADCAST_MODE_NONE
0x0007b0:          0004 0180 - NPU_SET_IFM2_BROADCAST             4, broadcast_mode = BROADCAST_MODE_C
0x0007b4:          007f 0115 - NPU_SET_OFM_BLK_WIDTH_M1         127, width_m1 = 127
0x0007b8:          0000 0011 - NPU_OP_DMA_WAIT                    0, k = 0
0x0007bc:          0002 0006 - NPU_OP_ELEMENTWISE                 2, elementwise_mode = ELEMENTWISE_MODE_SUB
// Asr , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x0007c0: 00000001 0000 4025 - NPU_SET_IFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x0007c8: 00000001 0000 4026 - NPU_SET_IFM2_SCALE                 0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x0007d0: 00000001 2000 4024 - NPU_SET_OFM_SCALE               8192, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_NATURAL, scale = 1
0x0007d8:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x0007dc: 00000000 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x0
0x0007e4: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x0007ec: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x0007f4: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x0007fc:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000800:          0105 0114 - NPU_SET_OFM_PRECISION            261, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000804: 00000040 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x40
0x00080c: 00000030 0000 4015 - NPU_SET_OFM_STRIDE_Y               0, addr = 0x30
0x000814: 00000030 0000 4014 - NPU_SET_OFM_STRIDE_X               0, addr = 0x30
0x00081c: 00000004 0000 4016 - NPU_SET_OFM_STRIDE_C               0, addr = 0x4
0x000824:          0000 0118 - NPU_SET_OFM_ZERO_POINT             0, zero_point = 0
0x000828:          1000 0125 - NPU_SET_ACTIVATION              4096, activation_function = ACTIVATION_FUNCTION_LUT_NONE, table = 0, activation_clip_range = ACTIVATION_CLIP_RANGE_NONE
0x00082c:          8000 0126 - NPU_SET_ACTIVATION_MIN         32768, clip_boundary = 32768
0x000830:          ffff 0127 - NPU_SET_ACTIVATION_MAX         65535, clip_boundary = 65535
0x000834:          c009 0185 - NPU_SET_IFM2_PRECISION         49161, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_NONE
0x000838: 0000000c 0000 4027 - NPU_SET_OP_SCALAR                  0, scalar = 12
0x000840:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000844:          0008 0180 - NPU_SET_IFM2_BROADCAST             8, broadcast_mode = BROADCAST_MODE_SCALAR
0x000848:          001f 0115 - NPU_SET_OFM_BLK_WIDTH_M1          31, width_m1 = 31
0x00084c:          0008 0006 - NPU_OP_ELEMENTWISE                 8, elementwise_mode = ELEMENTWISE_MODE_SHR
// ReduceSum , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 4, 16], IFM Block=[1, 1, 4, 32], OFM UBlock=[1, 4, 8] Traversal=DepthFirst, AccType=Acc32
0x000850:          0009 0105 - NPU_SET_IFM_PRECISION              9, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000854: 00000040 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x40
0x00085c: 00000030 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x30
0x000864: 00000030 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x30
0x00086c: 00000004 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x4
0x000874:          0145 0114 - NPU_SET_OFM_PRECISION            325, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000878: 000000c0 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0xc0
0x000880:          0000 0113 - NPU_SET_OFM_DEPTH_M1               0, depth_m1 = 0
0x000884: 00000040 0000 4015 - NPU_SET_OFM_STRIDE_Y               0, addr = 0x40
0x00088c: 00000040 0000 4014 - NPU_SET_OFM_STRIDE_X               0, addr = 0x40
0x000894: 00000040 0000 4016 - NPU_SET_OFM_STRIDE_C               0, addr = 0x40
0x00089c:          0000 0120 - NPU_SET_KERNEL_WIDTH_M1            0, width_m1 = 0
0x0008a0:          0003 0115 - NPU_SET_OFM_BLK_WIDTH_M1           3, width_m1 = 3
0x0008a4:          0200 0124 - NPU_SET_ACC_FORMAT               512, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U1X4
0x0008a8:          0002 0005 - NPU_OP_POOL                        2, pooling_mode = POOLING_MODE_REDUCE_SUM
// CLZ , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x0008ac: 00000001 0000 4024 - NPU_SET_OFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1
0x0008b4:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x0008b8: 000000c0 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0xc0
0x0008c0:          0000 0104 - NPU_SET_IFM_DEPTH_M1               0, depth_m1 = 0
0x0008c4: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x0008cc: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x0008d4: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x0008dc: 00000100 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x100
0x0008e4:          0000 0180 - NPU_SET_IFM2_BROADCAST             0, broadcast_mode = BROADCAST_MODE_NONE
0x0008e8:          001f 0115 - NPU_SET_OFM_BLK_WIDTH_M1          31, width_m1 = 31
0x0008ec:          0100 0124 - NPU_SET_ACC_FORMAT               256, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U1X2
0x0008f0:          0007 0006 - NPU_OP_ELEMENTWISE                 7, elementwise_mode = ELEMENTWISE_MODE_CLZ
// Sub , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x0008f4: 00000001 03c0 4025 - NPU_SET_IFM_SCALE                960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x0008fc: 00000001 03c0 4026 - NPU_SET_IFM2_SCALE               960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000904:          c009 0105 - NPU_SET_IFM_PRECISION          49161, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_NONE
0x000908: 00000023 0000 4027 - NPU_SET_OP_SCALAR                  0, scalar = 35
0x000910: 00000040 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x40
0x000918:          0049 0185 - NPU_SET_IFM2_PRECISION            73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x00091c: 00000100 0000 4080 - NPU_SET_IFM2_BASE0                 0, addr = 0x100
0x000924: 00000040 0000 4085 - NPU_SET_IFM2_STRIDE_Y              0, addr = 0x40
0x00092c: 00000040 0000 4084 - NPU_SET_IFM2_STRIDE_X              0, addr = 0x40
0x000934: 00000040 0000 4086 - NPU_SET_IFM2_STRIDE_C              0, addr = 0x40
0x00093c:          0008 0108 - NPU_SET_IFM_BROADCAST              8, broadcast_mode = BROADCAST_MODE_SCALAR
0x000940:          0002 0006 - NPU_OP_ELEMENTWISE                 2, elementwise_mode = ELEMENTWISE_MODE_SUB
// Sub , subOps: SHL, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000944:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000948:          0002 010f - NPU_SET_IFM_REGION                 2, region = 2
0x00094c: 00000100 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x100
0x000954: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x00095c: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x000964: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x00096c:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x000970:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x000974:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x000978: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x000980: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x000988: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x000990:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000994:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000998:          0000 011f - NPU_SET_OFM_REGION                 0, region = 0
0x00099c:          c009 0185 - NPU_SET_IFM2_PRECISION         49161, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_NONE
0x0009a0: 00000001 0000 4027 - NPU_SET_OP_SCALAR                  0, scalar = 1
0x0009a8:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x0009ac:          0000 0108 - NPU_SET_IFM_BROADCAST              0, broadcast_mode = BROADCAST_MODE_NONE
0x0009b0:          0008 0180 - NPU_SET_IFM2_BROADCAST             8, broadcast_mode = BROADCAST_MODE_SCALAR
0x0009b4:          0002 0006 - NPU_OP_ELEMENTWISE                 2, elementwise_mode = ELEMENTWISE_MODE_SUB
// SHL , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x0009b8: 00000001 0000 4025 - NPU_SET_IFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x0009c0: 00000001 0000 4026 - NPU_SET_IFM2_SCALE                 0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x0009c8:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x0009cc:          0002 010f - NPU_SET_IFM_REGION                 2, region = 2
0x0009d0: 000000c0 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0xc0
0x0009d8: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x0009e0: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x0009e8: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x0009f0:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x0009f4:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x0009f8:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x0009fc: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x000a04: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x000a0c: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x000a14:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000a18:          0145 0114 - NPU_SET_OFM_PRECISION            325, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000a1c:          0002 011f - NPU_SET_OFM_REGION                 2, region = 2
0x000a20: 00000080 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x80
0x000a28:          8049 0185 - NPU_SET_IFM2_PRECISION         32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000a2c:          0000 018f - NPU_SET_IFM2_REGION                0, region = 0
0x000a30:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000a34:          0000 0180 - NPU_SET_IFM2_BROADCAST             0, broadcast_mode = BROADCAST_MODE_NONE
0x000a38:          0009 0006 - NPU_OP_ELEMENTWISE                 9, elementwise_mode = ELEMENTWISE_MODE_SHL
// Mul , subOps: Add, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000a3c: 40000000 001f 4024 - NPU_SET_OFM_SCALE                 31, shift = 31, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1073741824
0x000a44:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000a48:          0002 010f - NPU_SET_IFM_REGION                 2, region = 2
0x000a4c: 00000080 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x80
0x000a54: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x000a5c: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x000a64: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x000a6c:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x000a70:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x000a74:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x000a78: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x000a80: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x000a88: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x000a90:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000a94:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000a98:          0000 011f - NPU_SET_OFM_REGION                 0, region = 0
0x000a9c:          c009 0185 - NPU_SET_IFM2_PRECISION         49161, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_NONE
0x000aa0: c3c3c3c4 0000 4027 - NPU_SET_OP_SCALAR                  0, scalar = 3284386755
0x000aa8:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000aac:          0008 0180 - NPU_SET_IFM2_BROADCAST             8, broadcast_mode = BROADCAST_MODE_SCALAR
0x000ab0:          0000 0006 - NPU_OP_ELEMENTWISE                 0, elementwise_mode = ELEMENTWISE_MODE_MUL
// Add , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000ab4: 00000001 03c0 4025 - NPU_SET_IFM_SCALE                960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000abc: 00000001 03c0 4026 - NPU_SET_IFM2_SCALE               960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000ac4: 00000001 0000 4024 - NPU_SET_OFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1
0x000acc:          8049 0105 - NPU_SET_IFM_PRECISION          32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000ad0:          0000 010f - NPU_SET_IFM_REGION                 0, region = 0
0x000ad4:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000ad8:          0145 0114 - NPU_SET_OFM_PRECISION            325, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000adc:          0002 011f - NPU_SET_OFM_REGION                 2, region = 2
0x000ae0: 00000100 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x100
0x000ae8:          c009 0185 - NPU_SET_IFM2_PRECISION         49161, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_NONE
0x000aec: 5a5a5a5a 0000 4027 - NPU_SET_OP_SCALAR                  0, scalar = 1515870810
0x000af4:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000af8:          0001 0006 - NPU_OP_ELEMENTWISE                 1, elementwise_mode = ELEMENTWISE_MODE_ADD
// Mul , subOps: Sub Mul Mul, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000afc: 00000001 0000 4025 - NPU_SET_IFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000b04: 00000001 0000 4026 - NPU_SET_IFM2_SCALE                 0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000b0c: 40000000 001f 4024 - NPU_SET_OFM_SCALE                 31, shift = 31, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1073741824
0x000b14:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000b18:          0002 010f - NPU_SET_IFM_REGION                 2, region = 2
0x000b1c: 00000100 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x100
0x000b24: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x000b2c: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x000b34: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x000b3c:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x000b40:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x000b44:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x000b48: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x000b50: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x000b58: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x000b60:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000b64:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000b68:          0000 011f - NPU_SET_OFM_REGION                 0, region = 0
0x000b6c:          0049 0185 - NPU_SET_IFM2_PRECISION            73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000b70:          0002 018f - NPU_SET_IFM2_REGION                2, region = 2
0x000b74: 00000080 0000 4080 - NPU_SET_IFM2_BASE0                 0, addr = 0x80
0x000b7c: 00000000 0000 4081 - NPU_SET_IFM2_BASE1                 0, addr = 0x0
0x000b84: 00000000 0000 4082 - NPU_SET_IFM2_BASE2                 0, addr = 0x0
0x000b8c: 00000000 0000 4083 - NPU_SET_IFM2_BASE3                 0, addr = 0x0
0x000b94:          0000 018b - NPU_SET_IFM2_HEIGHT0_M1            0, height_m1 = 0
0x000b98:          0000 018c - NPU_SET_IFM2_HEIGHT1_M1            0, height_m1 = 0
0x000b9c:          0000 018a - NPU_SET_IFM2_WIDTH0_M1             0, width_m1 = 0
0x000ba0: 00000040 0000 4085 - NPU_SET_IFM2_STRIDE_Y              0, addr = 0x40
0x000ba8: 00000040 0000 4084 - NPU_SET_IFM2_STRIDE_X              0, addr = 0x40
0x000bb0: 00000040 0000 4086 - NPU_SET_IFM2_STRIDE_C              0, addr = 0x40
0x000bb8:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000bbc:          0000 0180 - NPU_SET_IFM2_BROADCAST             0, broadcast_mode = BROADCAST_MODE_NONE
0x000bc0:          0000 0006 - NPU_OP_ELEMENTWISE                 0, elementwise_mode = ELEMENTWISE_MODE_MUL
// Sub , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000bc4: 00000001 03c0 4025 - NPU_SET_IFM_SCALE                960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000bcc: 00000001 03c0 4026 - NPU_SET_IFM2_SCALE               960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000bd4: 00000001 0000 4024 - NPU_SET_OFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1
0x000bdc:          c009 0105 - NPU_SET_IFM_PRECISION          49161, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_NONE
0x000be0: 20000000 0000 4027 - NPU_SET_OP_SCALAR                  0, scalar = 536870912
0x000be8:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000bec:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000bf0:          0001 011f - NPU_SET_OFM_REGION                 1, region = 1
0x000bf4:          8049 0185 - NPU_SET_IFM2_PRECISION         32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000bf8:          0000 018f - NPU_SET_IFM2_REGION                0, region = 0
0x000bfc:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000c00:          0008 0108 - NPU_SET_IFM_BROADCAST              8, broadcast_mode = BROADCAST_MODE_SCALAR
0x000c04:          0002 0006 - NPU_OP_ELEMENTWISE                 2, elementwise_mode = ELEMENTWISE_MODE_SUB
// Mul , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000c08: 00000001 0000 4025 - NPU_SET_IFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000c10: 00000001 0000 4026 - NPU_SET_IFM2_SCALE                 0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000c18: 40000000 001f 4024 - NPU_SET_OFM_SCALE                 31, shift = 31, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1073741824
0x000c20:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000c24:          0002 010f - NPU_SET_IFM_REGION                 2, region = 2
0x000c28: 00000100 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x100
0x000c30: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x000c38: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x000c40: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x000c48:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x000c4c:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x000c50:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x000c54: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x000c5c: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x000c64: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x000c6c:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000c70:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000c74:          0002 011f - NPU_SET_OFM_REGION                 2, region = 2
0x000c78:          8049 0185 - NPU_SET_IFM2_PRECISION         32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000c7c:          0001 018f - NPU_SET_IFM2_REGION                1, region = 1
0x000c80:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000c84:          0000 0108 - NPU_SET_IFM_BROADCAST              0, broadcast_mode = BROADCAST_MODE_NONE
0x000c88:          0000 0006 - NPU_OP_ELEMENTWISE                 0, elementwise_mode = ELEMENTWISE_MODE_MUL
// Mul , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000c8c: 00000001 0000 4024 - NPU_SET_OFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1
0x000c94:          8049 0105 - NPU_SET_IFM_PRECISION          32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000c98:          0002 010f - NPU_SET_IFM_REGION                 2, region = 2
0x000c9c:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000ca0:          0145 0114 - NPU_SET_OFM_PRECISION            325, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000ca4: 000000c0 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0xc0
0x000cac:          c009 0185 - NPU_SET_IFM2_PRECISION         49161, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_NONE
0x000cb0: 00000004 0000 4027 - NPU_SET_OP_SCALAR                  0, scalar = 4
0x000cb8:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000cbc:          0008 0180 - NPU_SET_IFM2_BROADCAST             8, broadcast_mode = BROADCAST_MODE_SCALAR
0x000cc0:          0000 0006 - NPU_OP_ELEMENTWISE                 0, elementwise_mode = ELEMENTWISE_MODE_MUL
// Add , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000cc4: 00000001 03c0 4025 - NPU_SET_IFM_SCALE                960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000ccc: 00000001 03c0 4026 - NPU_SET_IFM2_SCALE               960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000cd4:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000cd8:          0002 010f - NPU_SET_IFM_REGION                 2, region = 2
0x000cdc: 00000100 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x100
0x000ce4: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x000cec: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x000cf4: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x000cfc:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x000d00:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x000d04:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x000d08: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x000d10: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x000d18: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x000d20:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000d24:          0145 0114 - NPU_SET_OFM_PRECISION            325, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000d28:          0049 0185 - NPU_SET_IFM2_PRECISION            73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000d2c:          0002 018f - NPU_SET_IFM2_REGION                2, region = 2
0x000d30: 000000c0 0000 4080 - NPU_SET_IFM2_BASE0                 0, addr = 0xc0
0x000d38: 00000000 0000 4081 - NPU_SET_IFM2_BASE1                 0, addr = 0x0
0x000d40: 00000000 0000 4082 - NPU_SET_IFM2_BASE2                 0, addr = 0x0
0x000d48: 00000000 0000 4083 - NPU_SET_IFM2_BASE3                 0, addr = 0x0
0x000d50:          0000 018b - NPU_SET_IFM2_HEIGHT0_M1            0, height_m1 = 0
0x000d54:          0000 018c - NPU_SET_IFM2_HEIGHT1_M1            0, height_m1 = 0
0x000d58:          0000 018a - NPU_SET_IFM2_WIDTH0_M1             0, width_m1 = 0
0x000d5c: 00000040 0000 4085 - NPU_SET_IFM2_STRIDE_Y              0, addr = 0x40
0x000d64: 00000040 0000 4084 - NPU_SET_IFM2_STRIDE_X              0, addr = 0x40
0x000d6c: 00000040 0000 4086 - NPU_SET_IFM2_STRIDE_C              0, addr = 0x40
0x000d74:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000d78:          0000 0180 - NPU_SET_IFM2_BROADCAST             0, broadcast_mode = BROADCAST_MODE_NONE
0x000d7c:          0001 0006 - NPU_OP_ELEMENTWISE                 1, elementwise_mode = ELEMENTWISE_MODE_ADD
// Mul , subOps: Sub Mul Mul, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000d80: 00000001 0000 4025 - NPU_SET_IFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000d88: 00000001 0000 4026 - NPU_SET_IFM2_SCALE                 0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000d90: 40000000 001f 4024 - NPU_SET_OFM_SCALE                 31, shift = 31, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1073741824
0x000d98:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000d9c:          0002 010f - NPU_SET_IFM_REGION                 2, region = 2
0x000da0: 000000c0 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0xc0
0x000da8: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x000db0: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x000db8: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x000dc0:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x000dc4:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x000dc8:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x000dcc: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x000dd4: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x000ddc: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x000de4:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000de8:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000dec:          0000 011f - NPU_SET_OFM_REGION                 0, region = 0
0x000df0:          0049 0185 - NPU_SET_IFM2_PRECISION            73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000df4:          0002 018f - NPU_SET_IFM2_REGION                2, region = 2
0x000df8: 00000080 0000 4080 - NPU_SET_IFM2_BASE0                 0, addr = 0x80
0x000e00: 00000000 0000 4081 - NPU_SET_IFM2_BASE1                 0, addr = 0x0
0x000e08: 00000000 0000 4082 - NPU_SET_IFM2_BASE2                 0, addr = 0x0
0x000e10: 00000000 0000 4083 - NPU_SET_IFM2_BASE3                 0, addr = 0x0
0x000e18:          0000 018b - NPU_SET_IFM2_HEIGHT0_M1            0, height_m1 = 0
0x000e1c:          0000 018c - NPU_SET_IFM2_HEIGHT1_M1            0, height_m1 = 0
0x000e20:          0000 018a - NPU_SET_IFM2_WIDTH0_M1             0, width_m1 = 0
0x000e24: 00000040 0000 4085 - NPU_SET_IFM2_STRIDE_Y              0, addr = 0x40
0x000e2c: 00000040 0000 4084 - NPU_SET_IFM2_STRIDE_X              0, addr = 0x40
0x000e34: 00000040 0000 4086 - NPU_SET_IFM2_STRIDE_C              0, addr = 0x40
0x000e3c:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000e40:          0000 0006 - NPU_OP_ELEMENTWISE                 0, elementwise_mode = ELEMENTWISE_MODE_MUL
// Sub , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000e44: 00000001 03c0 4025 - NPU_SET_IFM_SCALE                960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000e4c: 00000001 03c0 4026 - NPU_SET_IFM2_SCALE               960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000e54: 00000001 0000 4024 - NPU_SET_OFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1
0x000e5c:          c009 0105 - NPU_SET_IFM_PRECISION          49161, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_NONE
0x000e60: 20000000 0000 4027 - NPU_SET_OP_SCALAR                  0, scalar = 536870912
0x000e68:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000e6c:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000e70:          0001 011f - NPU_SET_OFM_REGION                 1, region = 1
0x000e74:          8049 0185 - NPU_SET_IFM2_PRECISION         32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000e78:          0000 018f - NPU_SET_IFM2_REGION                0, region = 0
0x000e7c:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000e80:          0008 0108 - NPU_SET_IFM_BROADCAST              8, broadcast_mode = BROADCAST_MODE_SCALAR
0x000e84:          0002 0006 - NPU_OP_ELEMENTWISE                 2, elementwise_mode = ELEMENTWISE_MODE_SUB
// Mul , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000e88: 00000001 0000 4025 - NPU_SET_IFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000e90: 00000001 0000 4026 - NPU_SET_IFM2_SCALE                 0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000e98: 40000000 001f 4024 - NPU_SET_OFM_SCALE                 31, shift = 31, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1073741824
0x000ea0:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000ea4:          0002 010f - NPU_SET_IFM_REGION                 2, region = 2
0x000ea8: 000000c0 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0xc0
0x000eb0: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x000eb8: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x000ec0: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x000ec8:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x000ecc:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x000ed0:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x000ed4: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x000edc: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x000ee4: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x000eec:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000ef0:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000ef4:          0002 011f - NPU_SET_OFM_REGION                 2, region = 2
0x000ef8:          8049 0185 - NPU_SET_IFM2_PRECISION         32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000efc:          0001 018f - NPU_SET_IFM2_REGION                1, region = 1
0x000f00:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000f04:          0000 0108 - NPU_SET_IFM_BROADCAST              0, broadcast_mode = BROADCAST_MODE_NONE
0x000f08:          0000 0006 - NPU_OP_ELEMENTWISE                 0, elementwise_mode = ELEMENTWISE_MODE_MUL
// Mul , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000f0c: 00000001 0000 4024 - NPU_SET_OFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1
0x000f14:          8049 0105 - NPU_SET_IFM_PRECISION          32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000f18:          0002 010f - NPU_SET_IFM_REGION                 2, region = 2
0x000f1c:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000f20:          0145 0114 - NPU_SET_OFM_PRECISION            325, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000f24: 00000100 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x100
0x000f2c:          c009 0185 - NPU_SET_IFM2_PRECISION         49161, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_NONE
0x000f30: 00000004 0000 4027 - NPU_SET_OP_SCALAR                  0, scalar = 4
0x000f38:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000f3c:          0008 0180 - NPU_SET_IFM2_BROADCAST             8, broadcast_mode = BROADCAST_MODE_SCALAR
0x000f40:          0000 0006 - NPU_OP_ELEMENTWISE                 0, elementwise_mode = ELEMENTWISE_MODE_MUL
// Add , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000f44: 00000001 03c0 4025 - NPU_SET_IFM_SCALE                960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000f4c: 00000001 03c0 4026 - NPU_SET_IFM2_SCALE               960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000f54:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000f58:          0002 010f - NPU_SET_IFM_REGION                 2, region = 2
0x000f5c: 000000c0 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0xc0
0x000f64: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x000f6c: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x000f74: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x000f7c:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x000f80:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x000f84:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x000f88: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x000f90: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x000f98: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x000fa0:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000fa4:          0145 0114 - NPU_SET_OFM_PRECISION            325, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000fa8:          0049 0185 - NPU_SET_IFM2_PRECISION            73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000fac:          0002 018f - NPU_SET_IFM2_REGION                2, region = 2
0x000fb0: 00000100 0000 4080 - NPU_SET_IFM2_BASE0                 0, addr = 0x100
0x000fb8: 00000000 0000 4081 - NPU_SET_IFM2_BASE1                 0, addr = 0x0
0x000fc0: 00000000 0000 4082 - NPU_SET_IFM2_BASE2                 0, addr = 0x0
0x000fc8: 00000000 0000 4083 - NPU_SET_IFM2_BASE3                 0, addr = 0x0
0x000fd0:          0000 018b - NPU_SET_IFM2_HEIGHT0_M1            0, height_m1 = 0
0x000fd4:          0000 018c - NPU_SET_IFM2_HEIGHT1_M1            0, height_m1 = 0
0x000fd8:          0000 018a - NPU_SET_IFM2_WIDTH0_M1             0, width_m1 = 0
0x000fdc: 00000040 0000 4085 - NPU_SET_IFM2_STRIDE_Y              0, addr = 0x40
0x000fe4: 00000040 0000 4084 - NPU_SET_IFM2_STRIDE_X              0, addr = 0x40
0x000fec: 00000040 0000 4086 - NPU_SET_IFM2_STRIDE_C              0, addr = 0x40
0x000ff4:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000ff8:          0000 0180 - NPU_SET_IFM2_BROADCAST             0, broadcast_mode = BROADCAST_MODE_NONE
0x000ffc:          0001 0006 - NPU_OP_ELEMENTWISE                 1, elementwise_mode = ELEMENTWISE_MODE_ADD
// Mul , subOps: Sub Mul Mul, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x001000: 00000001 0000 4025 - NPU_SET_IFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x001008: 00000001 0000 4026 - NPU_SET_IFM2_SCALE                 0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x001010: 40000000 001f 4024 - NPU_SET_OFM_SCALE                 31, shift = 31, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1073741824
0x001018:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x00101c:          0002 010f - NPU_SET_IFM_REGION                 2, region = 2
0x001020: 00000100 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x100
0x001028: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x001030: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x001038: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x001040:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x001044:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x001048:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x00104c: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x001054: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x00105c: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x001064:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x001068:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x00106c:          0000 011f - NPU_SET_OFM_REGION                 0, region = 0
0x001070:          0049 0185 - NPU_SET_IFM2_PRECISION            73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x001074:          0002 018f - NPU_SET_IFM2_REGION                2, region = 2
0x001078: 00000080 0000 4080 - NPU_SET_IFM2_BASE0                 0, addr = 0x80
0x001080: 00000000 0000 4081 - NPU_SET_IFM2_BASE1                 0, addr = 0x0
0x001088: 00000000 0000 4082 - NPU_SET_IFM2_BASE2                 0, addr = 0x0
0x001090: 00000000 0000 4083 - NPU_SET_IFM2_BASE3                 0, addr = 0x0
0x001098:          0000 018b - NPU_SET_IFM2_HEIGHT0_M1            0, height_m1 = 0
0x00109c:          0000 018c - NPU_SET_IFM2_HEIGHT1_M1            0, height_m1 = 0
0x0010a0:          0000 018a - NPU_SET_IFM2_WIDTH0_M1             0, width_m1 = 0
0x0010a4: 00000040 0000 4085 - NPU_SET_IFM2_STRIDE_Y              0, addr = 0x40
0x0010ac: 00000040 0000 4084 - NPU_SET_IFM2_STRIDE_X              0, addr = 0x40
0x0010b4: 00000040 0000 4086 - NPU_SET_IFM2_STRIDE_C              0, addr = 0x40
0x0010bc:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x0010c0:          0000 0006 - NPU_OP_ELEMENTWISE                 0, elementwise_mode = ELEMENTWISE_MODE_MUL
// Sub , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x0010c4: 00000001 03c0 4025 - NPU_SET_IFM_SCALE                960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x0010cc: 00000001 03c0 4026 - NPU_SET_IFM2_SCALE               960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x0010d4: 00000001 0000 4024 - NPU_SET_OFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1
0x0010dc:          c009 0105 - NPU_SET_IFM_PRECISION          49161, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_NONE
0x0010e0: 20000000 0000 4027 - NPU_SET_OP_SCALAR                  0, scalar = 536870912
0x0010e8:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x0010ec:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x0010f0:          0001 011f - NPU_SET_OFM_REGION                 1, region = 1
0x0010f4:          8049 0185 - NPU_SET_IFM2_PRECISION         32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x0010f8:          0000 018f - NPU_SET_IFM2_REGION                0, region = 0
0x0010fc:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x001100:          0008 0108 - NPU_SET_IFM_BROADCAST              8, broadcast_mode = BROADCAST_MODE_SCALAR
0x001104:          0002 0006 - NPU_OP_ELEMENTWISE                 2, elementwise_mode = ELEMENTWISE_MODE_SUB
// Mul , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x001108: 00000001 0000 4025 - NPU_SET_IFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x001110: 00000001 0000 4026 - NPU_SET_IFM2_SCALE                 0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x001118: 40000000 001f 4024 - NPU_SET_OFM_SCALE                 31, shift = 31, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1073741824
0x001120:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x001124:          0002 010f - NPU_SET_IFM_REGION                 2, region = 2
0x001128: 00000100 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x100
0x001130: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x001138: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x001140: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x001148:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x00114c:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x001150:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x001154: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x00115c: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x001164: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x00116c:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x001170:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x001174:          0002 011f - NPU_SET_OFM_REGION                 2, region = 2
0x001178:          8049 0185 - NPU_SET_IFM2_PRECISION         32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x00117c:          0001 018f - NPU_SET_IFM2_REGION                1, region = 1
0x001180:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x001184:          0000 0108 - NPU_SET_IFM_BROADCAST              0, broadcast_mode = BROADCAST_MODE_NONE
0x001188:          0000 0006 - NPU_OP_ELEMENTWISE                 0, elementwise_mode = ELEMENTWISE_MODE_MUL
// Mul , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x00118c: 00000001 0000 4024 - NPU_SET_OFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1
0x001194:          8049 0105 - NPU_SET_IFM_PRECISION          32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x001198:          0002 010f - NPU_SET_IFM_REGION                 2, region = 2
0x00119c:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x0011a0:          0145 0114 - NPU_SET_OFM_PRECISION            325, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x0011a4: 000000c0 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0xc0
0x0011ac:          c009 0185 - NPU_SET_IFM2_PRECISION         49161, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_NONE
0x0011b0: 00000004 0000 4027 - NPU_SET_OP_SCALAR                  0, scalar = 4
0x0011b8:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x0011bc:          0008 0180 - NPU_SET_IFM2_BROADCAST             8, broadcast_mode = BROADCAST_MODE_SCALAR
0x0011c0:          0000 0006 - NPU_OP_ELEMENTWISE                 0, elementwise_mode = ELEMENTWISE_MODE_MUL
// Add , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x0011c4: 00000001 03c0 4025 - NPU_SET_IFM_SCALE                960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x0011cc: 00000001 03c0 4026 - NPU_SET_IFM2_SCALE               960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x0011d4:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x0011d8:          0002 010f - NPU_SET_IFM_REGION                 2, region = 2
0x0011dc: 00000100 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x100
0x0011e4: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x0011ec: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x0011f4: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x0011fc:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x001200:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x001204:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x001208: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x001210: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x001218: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x001220:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x001224:          0145 0114 - NPU_SET_OFM_PRECISION            325, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x001228:          0049 0185 - NPU_SET_IFM2_PRECISION            73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x00122c:          0002 018f - NPU_SET_IFM2_REGION                2, region = 2
0x001230: 000000c0 0000 4080 - NPU_SET_IFM2_BASE0                 0, addr = 0xc0
0x001238: 00000000 0000 4081 - NPU_SET_IFM2_BASE1                 0, addr = 0x0
0x001240: 00000000 0000 4082 - NPU_SET_IFM2_BASE2                 0, addr = 0x0
0x001248: 00000000 0000 4083 - NPU_SET_IFM2_BASE3                 0, addr = 0x0
0x001250:          0000 018b - NPU_SET_IFM2_HEIGHT0_M1            0, height_m1 = 0
0x001254:          0000 018c - NPU_SET_IFM2_HEIGHT1_M1            0, height_m1 = 0
0x001258:          0000 018a - NPU_SET_IFM2_WIDTH0_M1             0, width_m1 = 0
0x00125c: 00000040 0000 4085 - NPU_SET_IFM2_STRIDE_Y              0, addr = 0x40
0x001264: 00000040 0000 4084 - NPU_SET_IFM2_STRIDE_X              0, addr = 0x40
0x00126c: 00000040 0000 4086 - NPU_SET_IFM2_STRIDE_C              0, addr = 0x40
0x001274:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x001278:          0000 0180 - NPU_SET_IFM2_BROADCAST             0, broadcast_mode = BROADCAST_MODE_NONE
0x00127c:          0001 0006 - NPU_OP_ELEMENTWISE                 1, elementwise_mode = ELEMENTWISE_MODE_ADD
// Mul , subOps: Asr, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x001280: 00000001 0000 4025 - NPU_SET_IFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x001288: 00000001 0000 4026 - NPU_SET_IFM2_SCALE                 0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x001290: 40000000 001e 4024 - NPU_SET_OFM_SCALE                 30, shift = 30, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1073741824
0x001298:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x00129c:          0002 010f - NPU_SET_IFM_REGION                 2, region = 2
0x0012a0: 00000000 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x0
0x0012a8: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x0012b0: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x0012b8: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x0012c0:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x0012c4:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x0012c8:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x0012cc:          000b 0104 - NPU_SET_IFM_DEPTH_M1              11, depth_m1 = 11
0x0012d0: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x0012d8: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x0012e0: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x0012e8:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x0012ec:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x0012f0:          0000 011f - NPU_SET_OFM_REGION                 0, region = 0
0x0012f4:          000b 0113 - NPU_SET_OFM_DEPTH_M1              11, depth_m1 = 11
0x0012f8:          0049 0185 - NPU_SET_IFM2_PRECISION            73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x0012fc:          0002 018f - NPU_SET_IFM2_REGION                2, region = 2
0x001300: 000000c0 0000 4080 - NPU_SET_IFM2_BASE0                 0, addr = 0xc0
0x001308: 00000000 0000 4081 - NPU_SET_IFM2_BASE1                 0, addr = 0x0
0x001310: 00000000 0000 4082 - NPU_SET_IFM2_BASE2                 0, addr = 0x0
0x001318: 00000000 0000 4083 - NPU_SET_IFM2_BASE3                 0, addr = 0x0
0x001320:          0000 018b - NPU_SET_IFM2_HEIGHT0_M1            0, height_m1 = 0
0x001324:          0000 018c - NPU_SET_IFM2_HEIGHT1_M1            0, height_m1 = 0
0x001328:          0000 018a - NPU_SET_IFM2_WIDTH0_M1             0, width_m1 = 0
0x00132c: 00000040 0000 4085 - NPU_SET_IFM2_STRIDE_Y              0, addr = 0x40
0x001334: 00000040 0000 4084 - NPU_SET_IFM2_STRIDE_X              0, addr = 0x40
0x00133c: 00000040 0000 4086 - NPU_SET_IFM2_STRIDE_C              0, addr = 0x40
0x001344:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x001348:          0004 0180 - NPU_SET_IFM2_BROADCAST             4, broadcast_mode = BROADCAST_MODE_C
0x00134c:          0000 0006 - NPU_OP_ELEMENTWISE                 0, elementwise_mode = ELEMENTWISE_MODE_MUL
// Asr , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x001350: 00000001 2000 4024 - NPU_SET_OFM_SCALE               8192, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_NATURAL, scale = 1
0x001358:          8049 0105 - NPU_SET_IFM_PRECISION          32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x00135c:          0000 010f - NPU_SET_IFM_REGION                 0, region = 0
0x001360:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x001364:          0101 0114 - NPU_SET_OFM_PRECISION            257, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B8, activation_format = ACTIVATION_FORMAT_NHWC, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x001368:          0001 011f - NPU_SET_OFM_REGION                 1, region = 1
0x00136c: 00000000 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x0
0x001374: 0000000c 0000 4015 - NPU_SET_OFM_STRIDE_Y               0, addr = 0xc
0x00137c: 0000000c 0000 4014 - NPU_SET_OFM_STRIDE_X               0, addr = 0xc
0x001384: 00000001 0000 4016 - NPU_SET_OFM_STRIDE_C               0, addr = 0x1
0x00138c:          ff80 0118 - NPU_SET_OFM_ZERO_POINT         65408, zero_point = 65408
0x001390:          0000 0125 - NPU_SET_ACTIVATION                 0, activation_function = ACTIVATION_FUNCTION_LUT_NONE, table = 0, activation_clip_range = ACTIVATION_CLIP_RANGE_B16
0x001394:          ff80 0126 - NPU_SET_ACTIVATION_MIN         65408, clip_boundary = 65408
0x001398:          007f 0127 - NPU_SET_ACTIVATION_MAX           127, clip_boundary = 127
0x00139c:          0049 0185 - NPU_SET_IFM2_PRECISION            73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x0013a0:          0002 018f - NPU_SET_IFM2_REGION                2, region = 2
0x0013a4: 00000040 0000 4080 - NPU_SET_IFM2_BASE0                 0, addr = 0x40
0x0013ac: 00000000 0000 4081 - NPU_SET_IFM2_BASE1                 0, addr = 0x0
0x0013b4: 00000000 0000 4082 - NPU_SET_IFM2_BASE2                 0, addr = 0x0
0x0013bc: 00000000 0000 4083 - NPU_SET_IFM2_BASE3                 0, addr = 0x0
0x0013c4:          0000 018b - NPU_SET_IFM2_HEIGHT0_M1            0, height_m1 = 0
0x0013c8:          0000 018c - NPU_SET_IFM2_HEIGHT1_M1            0, height_m1 = 0
0x0013cc:          0000 018a - NPU_SET_IFM2_WIDTH0_M1             0, width_m1 = 0
0x0013d0: 00000040 0000 4085 - NPU_SET_IFM2_STRIDE_Y              0, addr = 0x40
0x0013d8: 00000040 0000 4084 - NPU_SET_IFM2_STRIDE_X              0, addr = 0x40
0x0013e0: 00000040 0000 4086 - NPU_SET_IFM2_STRIDE_C              0, addr = 0x40
0x0013e8:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x0013ec:          0008 0006 - NPU_OP_ELEMENTWISE                 8, elementwise_mode = ELEMENTWISE_MODE_SHR
0x0013f0:          ffff 0000 - NPU_OP_STOP                    65535, mask = 65535
Warning: No configuration file specified. Using a default of ['/Users/carlosmorales/dev/vela_example_generator/lib/python3.13/site-packages/ethosu/config_files/Arm/vela.ini']. Compilation may be invalid or non-optimal.
Warning: No system configuration specified. Using a default of Ethos_U85_SYS_DRAM_Mid. Compilation may be invalid or non-optimal.
Warning: No memory mode specified. Using a default of Dedicated_Sram_384KB. Compilation may be invalid or non-optimal.
Configuration files:
   original = None
   used = ['/Users/carlosmorales/dev/vela_example_generator/lib/python3.13/site-packages/ethosu/config_files/Arm/vela.ini']
System Configuration (Ethos_U85_SYS_DRAM_Mid):
   core_clock = 1000000000.0
   axi0_port = Sram
   axi1_port = Dram
   Sram_clock_scales = 1.0
   Sram_burst_length = 64
   Sram_read_latency = 32
   Sram_write_latency = 32
   Dram_clock_scales = 0.75
   Dram_burst_length = 128
   Dram_read_latency = 500
   Dram_write_latency = 250
   OnChipFlash_clock_scales = 1.0
   OnChipFlash_burst_length = 1
   OnChipFlash_read_latency = 0
   OnChipFlash_write_latency = 0
   OffChipFlash_clock_scales = 1.0
   OffChipFlash_burst_length = 1
   OffChipFlash_read_latency = 0
   OffChipFlash_write_latency = 0
Memory Mode (Dedicated_Sram_384KB):
   const_mem_area = Axi1
   arena_mem_area = Axi1
   cache_mem_area = Axi0
   arena_cache_size = 393216 from Configuration file
Architecture Settings:
   permanent_storage_mem_area = Dram
   feature_map_storage_mem_area = Dram
   fast_storage_mem_area = Sram

################################################################################
Performance for NPU Grap output/kws_ref_model_aligned
Original Operator    NNG Operator         Target Staging Usage  Peak% (Staging)  Op Cycles Network% (cycles)        NPU    SRAM AC    DRAM AC OnFlash AC OffFlash AC  MAC Count Network% (MAC)  Util% (MAC) Name                 
-------------------- -------------------- ------ ------------- ---------------- ---------- ----------------- ---------- ---------- ---------- ---------- ----------- ---------- -------------- ------------ -------------------- 
Conv2D               Conv2D               NPU            12960            62.45      12387             20.40      12387        790       7617          0           0     160000           6.39         5.05 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1 
Conv2D               Relu                 NPU            12960            62.45      19531             32.17       6632        390      19531          0           0       8000           0.32         0.16 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1 
DepthwiseConv2D      DepthwiseConv2D      NPU            16000            77.10       5000              8.24       5000        500       1562          0           0      72000           2.87         5.62 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1 
DepthwiseConv2D      Relu                 NPU            16000            77.10       7324             12.06       1338        390       7324          0           0       8000           0.32         0.43 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1 
Conv2D               Conv2D               NPU            20752           100.00       6249             10.29       4146       1788       6249          0           0     512000          20.44        32.01 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1 
Conv2D               Relu                 NPU            20752           100.00       6626             10.91       6626        390       2441          0           0       8000           0.32         0.47 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1 
DepthwiseConv2D      DepthwiseConv2D      NPU            16000            77.10       5000              8.24       5000        500       1562          0           0      72000           2.87         5.62 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1 
DepthwiseConv2D      Relu                 NPU            16000            77.10       7324             12.06       1338        390       7324          0           0       8000           0.32         0.43 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1 
Conv2D               Conv2D               NPU            20752           100.00       6249             10.29       4146       1788       6249          0           0     512000          20.44        32.01 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1 
Conv2D               Relu                 NPU            20752           100.00       6626             10.91       6626        390       2441          0           0       8000           0.32         0.47 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1 
DepthwiseConv2D      DepthwiseConv2D      NPU            16000            77.10       5000              8.24       5000        500       1562          0           0      72000           2.87         5.62 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1 
DepthwiseConv2D      Relu                 NPU            16000            77.10       7324             12.06       1338        390       7324          0           0       8000           0.32         0.43 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1 
Conv2D               Conv2D               NPU            20752           100.00       6249             10.29       4146       1788       6249          0           0     512000          20.44        32.01 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1 
Conv2D               Relu                 NPU            20752           100.00       6626             10.91       6626        390       2441          0           0       8000           0.32         0.47 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1 
DepthwiseConv2D      DepthwiseConv2D      NPU            16000            77.10       5000              8.24       5000        500       1562          0           0      72000           2.87         5.62 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1 
DepthwiseConv2D      Relu                 NPU            16000            77.10       7324             12.06       1338        390       7324          0           0       8000           0.32         0.43 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1 
Conv2D               Conv2D               NPU            20720            99.85       6249             10.29       4134       1784       6249          0           0     512000          20.44        32.01 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1 
Conv2D               Relu                 NPU            20720            99.85       6626             10.91       6626        390       2441          0           0       8000           0.32         0.47 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1 
AvgPool              AvgPool              NPU             8064            38.86       2541              4.19       2541        500          0          0           0       8000           0.32         1.23 functional_1/average_pooling2d/AvgPool 
FullyConnected       FullyConnected       NPU               80             0.39        390              0.64        325          3        390          0           0        768           0.03         0.77 functional_1/dense/BiasAdd 
Softmax              MaxPool              NPU               32             0.15         81              0.13         81          3          0          0           0         12           0.00         0.06 functional_1/dense/BiasAdd/maxpool 
Softmax              Sub                  NPU               96             0.46          4              0.01          4          2          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut 
Softmax              LUT                  NPU               96             0.46       1296              2.13       1296          0          4          0           0         12           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut 
Softmax              Asr                  NPU              112             0.54         12              0.02          3          0         12          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr 
Softmax              ReduceSum            NPU              176             0.85        178              0.29        178          0          0          0           0         12           0.00         0.03 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum 
Softmax              CLZ                  NPU              192             0.93          4              0.01          4          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ 
Softmax              Sub                  NPU              256             1.23          5              0.01          5          0          0          0           0          0           0.00         0.00 headroom_offset/Sub  
Softmax              Sub                  NPU              320             1.54          6              0.01          6          0          1          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ/Sub 
Softmax              SHL                  NPU              320             1.54          5              0.01          5          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL 
Softmax              Mul                  NPU              256             1.23          6              0.01          6          0          1          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul 
Softmax              Add                  NPU              256             1.23          6              0.01          5          0          6          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add 
Softmax              Mul                  NPU              320             1.54          4              0.01          4          0          1          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul 
Softmax              Sub                  NPU              320             1.54          6              0.01          6          0          1          0           0          0           0.00         0.00 F2_one/Sub           
Softmax              Mul                  NPU              320             1.54          6              0.01          6          0          1          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul 
Softmax              Mul                  NPU              320             1.54          6              0.01          5          0          6          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul 
Softmax              Add                  NPU              320             1.54          4              0.01          4          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add 
Softmax              Mul                  NPU              320             1.54          4              0.01          4          0          1          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul 
Softmax              Sub                  NPU              320             1.54          6              0.01          6          0          1          0           0          0           0.00         0.00 F2_one/Sub           
Softmax              Mul                  NPU              320             1.54          6              0.01          6          0          1          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul 
Softmax              Mul                  NPU              320             1.54          6              0.01          5          0          6          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul 
Softmax              Add                  NPU              320             1.54          4              0.01          4          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add 
Softmax              Mul                  NPU              320             1.54          4              0.01          4          0          1          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul 
Softmax              Sub                  NPU              320             1.54          6              0.01          6          0          1          0           0          0           0.00         0.00 F2_one/Sub           
Softmax              Mul                  NPU              320             1.54          6              0.01          6          0          1          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul 
Softmax              Mul                  NPU              320             1.54          6              0.01          5          0          6          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul 
Softmax              Add                  NPU              256             1.23          4              0.01          4          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add 
Softmax              Mul                  NPU              192             0.93          4              0.01          4          1          1          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Mul 
Softmax              Asr                  NPU              192             0.93          9              0.01          5          0          9          0           0          0           0.00         0.00 Identity             

Network summary for kws_ref_model_aligned
Accelerator configuration               Ethos_U85_256
System configuration             Ethos_U85_SYS_DRAM_Mid
Memory mode                      Dedicated_Sram_384KB
Accelerator clock                                1000 MHz
Design peak SRAM bandwidth                      29.80 GB/s
Design peak DRAM bandwidth                      11.18 GB/s

Total SRAM used                                 20.27 KiB
Total DRAM used                                 31.09 KiB

CPU operators = 0 (0.0%)
NPU operators = 38 (100.0%)

Average SRAM bandwidth                           5.67 GB/s
Input   SRAM bandwidth                           0.17 MB/batch
Weight  SRAM bandwidth                           0.10 MB/batch
Output  SRAM bandwidth                           0.07 MB/batch
Total   SRAM bandwidth                           0.34 MB/batch
Total   SRAM bandwidth            per input      0.34 MB/inference (batch size 1)

Average DRAM bandwidth                           0.87 GB/s
Input   DRAM bandwidth                           0.02 MB/batch
Weight  DRAM bandwidth                           0.03 MB/batch
Output  DRAM bandwidth                           0.00 MB/batch
Total   DRAM bandwidth                           0.05 MB/batch
Total   DRAM bandwidth            per input      0.05 MB/inference (batch size 1)

Original Weights Size                           21.50 KiB
NPU Encoded Weights Size                        23.72 KiB

Neural network macs                           2504792 MACs/batch

Info: The numbers below are internal compiler estimates.
For performance numbers the compiled network should be run on an FVP Model or FPGA.

Network Tops/s                                   0.08 Tops/s

NPU cycles                                      52206 cycles/batch
SRAM Access cycles                              13141 cycles/batch
DRAM Access cycles                              46700 cycles/batch
On-chip Flash Access cycles                         0 cycles/batch
Off-chip Flash Access cycles                        0 cycles/batch
Total cycles                                    60712 cycles/batch

Batch Inference time                 0.06 ms, 16471.21 inferences/s (batch size 1)

