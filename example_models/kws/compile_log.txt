Tensor 'input_1' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/average_pooling2d/AvgPool' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/flatten/Reshape' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'functional_1/dense/BiasAdd' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.
Tensor 'Identity' has a dynamic shape signature, which is not supported. Attempting to proceed with a fixed shape.

[ Before Graph Optimisation ]
0     Conv2D               functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
1     Relu                 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
2     DepthwiseConv2D      functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
3     Relu                 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
4     Conv2D               functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
5     Relu                 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
6     DepthwiseConv2D      functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
7     Relu                 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
8     Conv2D               functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
9     Relu                 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
10    DepthwiseConv2D      functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
11    Relu                 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
12    Conv2D               functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
13    Relu                 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
14    DepthwiseConv2D      functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
15    Relu                 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
16    Conv2D               functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
17    Relu                 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
18    AvgPool              functional_1/average_pooling2d/AvgPool
19    Reshape              functional_1/flatten/Reshape  
20    FullyConnected       functional_1/dense/BiasAdd    
21    Softmax              Identity                      


[ After Graph Optimization ]
0     Conv2D               functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
1     Relu                 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
2     DepthwiseConv2D      functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
3     Relu                 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
4     Conv2D               functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
5     Relu                 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
6     DepthwiseConv2D      functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
7     Relu                 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
8     Conv2D               functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
9     Relu                 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
10    DepthwiseConv2D      functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
11    Relu                 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
12    Conv2D               functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
13    Relu                 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
14    DepthwiseConv2D      functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
15    Relu                 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
16    Conv2D               functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
17    Relu                 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
18    AvgPool              functional_1/average_pooling2d/AvgPool
19    FullyConnected       functional_1/dense/BiasAdd    
20    MaxPool              functional_1/dense/BiasAdd/maxpool
21    Sub                  functional_1/dense/BiasAdd/Sub
22    LUT                  functional_1/dense/BiasAdd/Sub/lut
23    Asr                  functional_1/dense/BiasAdd/Sub/lut/Asr
24    ReduceSum            functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
25    CLZ                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
26    Sub                  headroom_offset/Sub           
27    Sub                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ/Sub
28    SHL                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
29    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul
30    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
31    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
32    Sub                  F2_one/Sub                    
33    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
34    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul
35    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
36    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
37    Sub                  F2_one/Sub                    
38    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
39    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul
40    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
41    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
42    Sub                  F2_one/Sub                    
43    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
44    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul
45    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add
46    Mul                  functional_1/dense/BiasAdd/Sub/lut/Mul
47    Asr                  Identity                      


[ Graph With Tensor Quantization ]
0 Conv2D functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
    Input 00 Int8 scale: [(scale:1255639936, shift:31)], zero_point: [83], quantMin: [], quantMax: [], dimension: 0 input_1
    Input 01 Int8 scale: [(scale:1464379008, shift:40), (scale:1627438592, shift:41), (scale:2075258880, shift:42), (scale:1168237824, shift:41), (scale:1974605056, shift:42), (scale:1721740160, shift:41), (scale:1753228160, shift:40), (scale:1488934784, shift:41), (scale:1158502912, shift:41), (scale:1188821888, shift:42), (scale:2093692416, shift:41), (scale:1192383104, shift:41), (scale:1241635712, shift:40), (scale:1341249536, shift:41), (scale:1510890880, shift:41), (scale:1695192704, shift:42), (scale:1737978496, shift:40), (scale:1398920704, shift:42), (scale:1746344320, shift:42), (scale:1183181312, shift:41), (scale:1977891584, shift:42), (scale:2113310208, shift:41), (scale:1867738624, shift:42), (scale:2071492864, shift:40), (scale:1785629696, shift:42), (scale:1601047552, shift:41), (scale:2084708864, shift:42), (scale:1776369664, shift:41), (scale:1110910976, shift:40), (scale:1188599936, shift:40), (scale:1304962560, shift:41), (scale:2105906560, shift:41), (scale:1524456576, shift:41), (scale:1199206144, shift:41), (scale:1698997888, shift:41), (scale:1483576448, shift:41), (scale:1413839616, shift:40), (scale:1961673344, shift:42), (scale:1395400576, shift:42), (scale:1804189824, shift:42), (scale:1684543488, shift:42), (scale:1297103488, shift:41), (scale:1180393728, shift:41), (scale:1112020992, shift:39), (scale:1304851456, shift:40), (scale:1339063296, shift:40), (scale:1462929152, shift:41), (scale:1156472320, shift:41), (scale:1637322240, shift:41), (scale:1713849088, shift:40), (scale:1621298432, shift:41), (scale:1104686080, shift:40), (scale:1114051584, shift:40), (scale:1806657408, shift:42), (scale:1706757760, shift:41), (scale:1979592448, shift:40), (scale:1814144384, shift:42), (scale:1384162944, shift:41), (scale:1765874944, shift:41), (scale:1857623040, shift:42), (scale:1349751680, shift:41), (scale:1080475776, shift:41), (scale:2000449024, shift:41), (scale:1812903424, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/conv2d/Conv2D
    Input 02 Int32 scale: [(scale:1712453376, shift:41), (scale:1903136128, shift:42), (scale:1213409920, shift:42), (scale:1366144128, shift:42), (scale:1154557312, shift:42), (scale:2013412992, shift:42), (scale:2050235264, shift:41), (scale:1741169024, shift:42), (scale:1354760064, shift:42), (scale:1390215296, shift:43), (scale:1224188032, shift:41), (scale:1394379776, shift:42), (scale:1451976064, shift:41), (scale:1568465024, shift:42), (scale:1766844544, shift:42), (scale:1982368256, shift:43), (scale:2032402176, shift:41), (scale:1635906048, shift:43), (scale:2042185216, shift:43), (scale:1383619072, shift:42), (scale:1156478976, shift:42), (scale:1235658624, shift:41), (scale:1092072192, shift:42), (scale:1211207936, shift:40), (scale:2088125696, shift:43), (scale:1872274304, shift:42), (scale:1218935296, shift:42), (scale:2077297024, shift:42), (scale:1299105792, shift:41), (scale:1389955712, shift:41), (scale:1526030848, shift:42), (scale:1231329664, shift:41), (scale:1782708352, shift:42), (scale:1402358656, shift:42), (scale:1986818048, shift:42), (scale:1734902912, shift:42), (scale:1653352320, shift:41), (scale:1146996096, shift:42), (scale:1631789568, shift:43), (scale:2109830016, shift:43), (scale:1969915008, shift:43), (scale:1516840320, shift:42), (scale:1380359296, shift:42), (scale:1300403840, shift:40), (scale:1525900928, shift:41), (scale:1565908352, shift:41), (scale:1710757888, shift:42), (scale:1352385408, shift:42), (scale:1914694144, shift:42), (scale:2004185088, shift:41), (scale:1895955840, shift:42), (scale:1291826304, shift:41), (scale:1302778368, shift:41), (scale:2112715648, shift:43), (scale:1995892480, shift:42), (scale:1157473408, shift:40), (scale:2121470976, shift:43), (scale:1618648192, shift:42), (scale:2065024384, shift:42), (scale:1086157568, shift:42), (scale:1578407424, shift:42), (scale:1263514624, shift:42), (scale:1169668352, shift:41), (scale:2120019840, shift:43)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D
    Output 00 Int8 scale: [(scale:1352492032, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
1 Relu functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
    Input 00 Int8 scale: [(scale:1352492032, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
    Output 00 Int8 scale: [(scale:1352492032, shift:34)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
2 DepthwiseConv2D functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1352492032, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
    Input 01 Int8 scale: [(scale:1175311872, shift:37), (scale:1421834240, shift:38), (scale:1271638528, shift:37), (scale:1767601536, shift:37), (scale:1557757056, shift:37), (scale:1964024960, shift:37), (scale:1340253440, shift:37), (scale:1632174336, shift:38), (scale:1362240512, shift:37), (scale:1455178240, shift:38), (scale:1301060352, shift:37), (scale:1534470784, shift:37), (scale:1505380864, shift:37), (scale:1607027712, shift:37), (scale:2074724736, shift:38), (scale:1142046336, shift:37), (scale:1205169408, shift:37), (scale:1980826496, shift:37), (scale:1788229376, shift:37), (scale:1879952768, shift:37), (scale:2140038912, shift:37), (scale:1967693440, shift:38), (scale:1371067008, shift:36), (scale:1222602752, shift:37), (scale:2044833408, shift:37), (scale:1474644096, shift:38), (scale:1265859456, shift:37), (scale:1932803968, shift:37), (scale:1682347648, shift:37), (scale:1849218560, shift:37), (scale:1137651584, shift:37), (scale:1620537088, shift:38), (scale:1330349056, shift:37), (scale:1458722176, shift:37), (scale:1262768512, shift:37), (scale:1439908864, shift:37), (scale:1143717888, shift:37), (scale:1255351168, shift:38), (scale:1737809280, shift:37), (scale:1521102720, shift:37), (scale:1310250368, shift:36), (scale:1701335296, shift:37), (scale:1126833920, shift:36), (scale:1467101824, shift:37), (scale:1102162304, shift:37), (scale:1211554304, shift:37), (scale:2127924352, shift:38), (scale:1508294144, shift:38), (scale:1134804864, shift:36), (scale:1403477120, shift:37), (scale:1413260928, shift:37), (scale:1539753600, shift:36), (scale:1543505408, shift:37), (scale:2064233344, shift:38), (scale:1818934528, shift:38), (scale:1809568256, shift:38), (scale:1679345920, shift:37), (scale:2092672000, shift:38), (scale:1182935296, shift:36), (scale:1790981376, shift:37), (scale:1380477440, shift:37), (scale:1797254400, shift:38), (scale:1616903808, shift:37), (scale:1895568512, shift:37)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 3 functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource
    Input 02 Int32 scale: [(scale:1480430336, shift:41), (scale:1790951424, shift:42), (scale:1601763968, shift:41), (scale:1113241088, shift:40), (scale:1962160640, shift:41), (scale:1236949120, shift:40), (scale:1688191744, shift:41), (scale:2055897216, shift:42), (scale:1715886848, shift:41), (scale:1832951808, shift:42), (scale:1638823936, shift:41), (scale:1932829184, shift:41), (scale:1896187264, shift:41), (scale:2024222336, shift:41), (scale:1306668288, shift:41), (scale:1438528768, shift:41), (scale:1518039040, shift:41), (scale:1247530880, shift:40), (scale:1126232576, shift:40), (scale:1184000256, shift:40), (scale:1347803264, shift:40), (scale:1239259648, shift:41), (scale:1727004672, shift:40), (scale:1539998208, shift:41), (scale:1287842560, shift:40), (scale:1857471104, shift:42), (scale:1594484608, shift:41), (scale:1217286144, shift:40), (scale:2119095808, shift:41), (scale:1164643712, shift:40), (scale:1432993152, shift:41), (scale:2041238784, shift:42), (scale:1675716096, shift:41), (scale:1837415680, shift:41), (scale:1590591232, shift:41), (scale:1813718400, shift:41), (scale:1440634368, shift:41), (scale:1581248256, shift:42), (scale:1094477824, shift:40), (scale:1915990656, shift:41), (scale:1650399744, shift:40), (scale:2143012736, shift:41), (scale:1419367168, shift:40), (scale:1847970816, shift:41), (scale:1388290688, shift:41), (scale:1526081536, shift:41), (scale:1340173568, shift:41), (scale:1899856896, shift:42), (scale:1429407488, shift:40), (scale:1767828736, shift:41), (scale:1780152448, shift:41), (scale:1939483392, shift:40), (scale:1944209280, shift:41), (scale:1300060672, shift:41), (scale:1145570688, shift:41), (scale:1139671808, shift:41), (scale:2115314816, shift:41), (scale:1317971456, shift:41), (scale:1490032768, shift:40), (scale:1127965824, shift:40), (scale:1738858112, shift:41), (scale:1131916544, shift:41), (scale:2036662272, shift:41), (scale:1193835136, shift:40)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource
    Output 00 Int8 scale: [(scale:1422750976, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
3 Relu functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1422750976, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
    Output 00 Int8 scale: [(scale:1422750976, shift:34)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
4 Conv2D functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
    Input 00 Int8 scale: [(scale:1422750976, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
    Input 01 Int8 scale: [(scale:1270611200, shift:39), (scale:2030643712, shift:39), (scale:1644547200, shift:39), (scale:1274715008, shift:39), (scale:2034716288, shift:39), (scale:1319735296, shift:39), (scale:1097028992, shift:39), (scale:1806930304, shift:39), (scale:1675453184, shift:39), (scale:2144237824, shift:39), (scale:1841686400, shift:39), (scale:1626432000, shift:39), (scale:1143902976, shift:38), (scale:1698825600, shift:39), (scale:1795597696, shift:39), (scale:1543490048, shift:39), (scale:1347438720, shift:39), (scale:1668319104, shift:39), (scale:2038381824, shift:39), (scale:1589206784, shift:39), (scale:1710085504, shift:39), (scale:1645939584, shift:39), (scale:1300315648, shift:38), (scale:1830330496, shift:39), (scale:1526757248, shift:39), (scale:1863892992, shift:39), (scale:1325160448, shift:39), (scale:1427883392, shift:39), (scale:1518774144, shift:39), (scale:1850537472, shift:39), (scale:2038893184, shift:39), (scale:2012493696, shift:39), (scale:1608130816, shift:39), (scale:1479658112, shift:39), (scale:1104901376, shift:38), (scale:1808917120, shift:39), (scale:1817939712, shift:39), (scale:2125389056, shift:39), (scale:2083040256, shift:39), (scale:1571339776, shift:39), (scale:1132971264, shift:38), (scale:2043926656, shift:39), (scale:1689693696, shift:39), (scale:1087454464, shift:38), (scale:1903368448, shift:39), (scale:1731485568, shift:39), (scale:1077008384, shift:39), (scale:1954194944, shift:39), (scale:1262896768, shift:39), (scale:1708360064, shift:39), (scale:1683638400, shift:39), (scale:1548113408, shift:39), (scale:1464501632, shift:39), (scale:2042817536, shift:39), (scale:2064977792, shift:39), (scale:1936098048, shift:39), (scale:1109349504, shift:39), (scale:1603760256, shift:39), (scale:1557180928, shift:39), (scale:1261184000, shift:39), (scale:1872705280, shift:39), (scale:1398821760, shift:39), (scale:1747156736, shift:39), (scale:1785712640, shift:39)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/conv2d_1/Conv2D
    Input 02 Int32 scale: [(scale:1683610752, shift:43), (scale:1345342208, shift:42), (scale:1089545472, shift:42), (scale:1689048448, shift:43), (scale:1348040320, shift:42), (scale:1748702208, shift:43), (scale:1453607424, shift:43), (scale:1197127552, shift:42), (scale:1110021376, shift:42), (scale:1420600576, shift:42), (scale:1220154112, shift:42), (scale:1077543808, shift:42), (scale:1515717376, shift:42), (scale:1125506048, shift:42), (scale:1189619456, shift:42), (scale:2045186176, shift:43), (scale:1785410304, shift:43), (scale:1105294848, shift:42), (scale:1350468864, shift:42), (scale:2105762688, shift:43), (scale:1132965888, shift:42), (scale:1090467968, shift:42), (scale:1722970368, shift:42), (scale:1212630656, shift:42), (scale:2023014528, shift:43), (scale:1234866432, shift:42), (scale:1755890688, shift:43), (scale:1892002816, shift:43), (scale:2012436608, shift:43), (scale:1226018176, shift:42), (scale:1350807680, shift:42), (scale:1333317376, shift:42), (scale:2130837760, shift:43), (scale:1960606336, shift:43), (scale:1464038656, shift:42), (scale:1198443904, shift:42), (scale:1204421504, shift:42), (scale:1408112896, shift:42), (scale:1380055936, shift:42), (scale:2082088192, shift:43), (scale:1501232384, shift:42), (scale:1354142336, shift:42), (scale:1119456000, shift:42), (scale:1440920832, shift:42), (scale:1261019776, shift:42), (scale:1147143936, shift:42), (scale:1427079296, shift:43), (scale:1294693376, shift:42), (scale:1673388800, shift:43), (scale:1131822848, shift:42), (scale:1115444224, shift:42), (scale:2051312384, shift:43), (scale:1940523392, shift:43), (scale:1353407616, shift:42), (scale:1368089216, shift:42), (scale:1282703744, shift:42), (scale:1469932544, shift:43), (scale:2125046656, shift:43), (scale:2063327232, shift:43), (scale:1671119360, shift:43), (scale:1240704768, shift:42), (scale:1853494912, shift:43), (scale:1157526400, shift:42), (scale:1183070464, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D
    Output 00 Int8 scale: [(scale:2062467200, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
5 Relu functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
    Input 00 Int8 scale: [(scale:2062467200, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
    Output 00 Int8 scale: [(scale:2062467200, shift:35)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
6 DepthwiseConv2D functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:2062467200, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
    Input 01 Int8 scale: [(scale:1792217088, shift:38), (scale:1776190720, shift:38), (scale:1770845568, shift:37), (scale:1272406144, shift:37), (scale:1814885248, shift:38), (scale:1965241728, shift:37), (scale:1624973184, shift:38), (scale:1544612480, shift:38), (scale:1698108160, shift:37), (scale:1817450240, shift:38), (scale:2040592768, shift:38), (scale:2053262464, shift:38), (scale:1941416064, shift:38), (scale:1878308864, shift:38), (scale:1215870208, shift:37), (scale:1190906112, shift:37), (scale:2133784704, shift:38), (scale:1085578624, shift:37), (scale:1814735360, shift:38), (scale:1483078016, shift:38), (scale:1287174528, shift:38), (scale:1270013696, shift:36), (scale:1952631296, shift:38), (scale:1834623872, shift:38), (scale:2137792128, shift:38), (scale:1287734656, shift:37), (scale:2137980672, shift:38), (scale:1595241984, shift:38), (scale:1935896320, shift:38), (scale:1157065856, shift:37), (scale:1493662336, shift:38), (scale:1802953344, shift:38), (scale:1137304064, shift:36), (scale:1906626688, shift:38), (scale:1792789248, shift:38), (scale:1535577088, shift:37), (scale:1342918912, shift:38), (scale:1487831552, shift:38), (scale:2146545408, shift:38), (scale:1384833664, shift:38), (scale:1199503360, shift:37), (scale:1423974528, shift:37), (scale:1109840768, shift:37), (scale:1148437888, shift:38), (scale:1714945024, shift:38), (scale:1258835584, shift:37), (scale:1484821760, shift:37), (scale:1762760576, shift:38), (scale:1948180736, shift:38), (scale:1615223296, shift:38), (scale:1544111488, shift:37), (scale:1810116224, shift:37), (scale:1129528320, shift:37), (scale:1880874624, shift:38), (scale:1576878592, shift:38), (scale:1967843072, shift:38), (scale:1340814848, shift:37), (scale:1297278464, shift:37), (scale:1349762944, shift:37), (scale:2047192576, shift:38), (scale:2040242432, shift:38), (scale:2015957760, shift:38), (scale:1827989504, shift:38), (scale:2056193920, shift:38)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 3 functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource
    Input 02 Int32 scale: [(scale:1721265280, shift:42), (scale:1705873280, shift:42), (scale:1700739840, shift:41), (scale:1222033024, shift:41), (scale:1743036032, shift:42), (scale:1887440000, shift:41), (scale:1560642304, shift:42), (scale:1483463040, shift:42), (scale:1630881920, shift:41), (scale:1745499392, shift:42), (scale:1959808000, shift:42), (scale:1971976064, shift:42), (scale:1864557568, shift:42), (scale:1803948800, shift:42), (scale:1167735296, shift:41), (scale:1143759488, shift:41), (scale:2049310592, shift:42), (scale:2085203584, shift:42), (scale:1742892032, shift:42), (scale:1424364672, shift:42), (scale:1236216704, shift:42), (scale:1219735296, shift:40), (scale:1875328896, shift:42), (scale:1761993216, shift:42), (scale:2053159296, shift:42), (scale:1236754688, shift:41), (scale:2053340416, shift:42), (scale:1532088192, shift:42), (scale:1859256320, shift:42), (scale:1111258880, shift:41), (scale:1434529920, shift:42), (scale:1731576448, shift:42), (scale:1092279424, shift:40), (scale:1831145472, shift:42), (scale:1721814784, shift:42), (scale:1474785280, shift:41), (scale:1289754240, shift:42), (scale:1428930048, shift:42), (scale:2061566080, shift:42), (scale:1330009728, shift:42), (scale:1152016384, shift:41), (scale:1367601024, shift:41), (scale:2131806848, shift:42), (scale:1102972544, shift:42), (scale:1647052288, shift:42), (scale:1208999680, shift:41), (scale:1426039296, shift:41), (scale:1692974848, shift:42), (scale:1871054464, shift:42), (scale:1551278464, shift:42), (scale:1482981888, shift:41), (scale:1738455808, shift:41), (scale:1084811520, shift:41), (scale:1806412928, shift:42), (scale:1514451712, shift:42), (scale:1889938432, shift:42), (scale:1287733504, shift:41), (scale:1245920640, shift:41), (scale:1296327296, shift:41), (scale:1966146560, shift:42), (scale:1959471488, shift:42), (scale:1936148224, shift:42), (scale:1755621504, shift:42), (scale:1974791552, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource
    Output 00 Int8 scale: [(scale:1078209024, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
7 Relu functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1078209024, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
    Output 00 Int8 scale: [(scale:1078209024, shift:34)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
8 Conv2D functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
    Input 00 Int8 scale: [(scale:1078209024, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
    Input 01 Int8 scale: [(scale:1612059136, shift:39), (scale:1775348480, shift:39), (scale:1644174208, shift:39), (scale:1761611136, shift:39), (scale:1954601984, shift:39), (scale:1292690944, shift:38), (scale:1128286592, shift:38), (scale:1686442880, shift:39), (scale:1895414912, shift:39), (scale:1503374720, shift:39), (scale:1264453248, shift:38), (scale:1539396992, shift:39), (scale:1422953856, shift:39), (scale:2026836224, shift:39), (scale:1614476672, shift:38), (scale:1475159552, shift:39), (scale:1108204544, shift:38), (scale:1272150016, shift:39), (scale:2097000960, shift:39), (scale:1201109120, shift:39), (scale:1217869696, shift:38), (scale:1302342400, shift:39), (scale:1457591040, shift:39), (scale:1382811776, shift:38), (scale:2041387008, shift:39), (scale:1850732928, shift:39), (scale:1673627776, shift:39), (scale:1730418048, shift:39), (scale:1566262144, shift:39), (scale:1545316608, shift:39), (scale:1586464256, shift:39), (scale:1925055872, shift:39), (scale:1139282432, shift:38), (scale:1972102272, shift:39), (scale:1941824000, shift:39), (scale:1075758592, shift:38), (scale:1547401984, shift:39), (scale:1668819200, shift:39), (scale:1792876032, shift:39), (scale:1926764416, shift:39), (scale:1719825408, shift:39), (scale:2022496000, shift:39), (scale:2003473920, shift:39), (scale:1557260928, shift:39), (scale:2140785664, shift:39), (scale:1805093376, shift:39), (scale:1751383808, shift:39), (scale:1919804800, shift:39), (scale:1348167552, shift:39), (scale:1570661376, shift:39), (scale:1651373440, shift:39), (scale:1701611904, shift:39), (scale:1920178944, shift:39), (scale:1074890112, shift:38), (scale:1531035008, shift:39), (scale:1860359168, shift:39), (scale:1651859840, shift:39), (scale:1482249856, shift:39), (scale:1822327552, shift:39), (scale:2091655936, shift:39), (scale:1734109440, shift:39), (scale:1922042880, shift:39), (scale:1608719744, shift:39), (scale:1604003584, shift:39)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/conv2d_2/Conv2D
    Input 02 Int32 scale: [(scale:1618765952, shift:43), (scale:1782734592, shift:43), (scale:1651014656, shift:43), (scale:1768940160, shift:43), (scale:1962733952, shift:43), (scale:1298069120, shift:42), (scale:1132980736, shift:42), (scale:1693459200, shift:43), (scale:1903300608, shift:43), (scale:1509629312, shift:43), (scale:1269713920, shift:42), (scale:1545801472, shift:43), (scale:1428873856, shift:43), (scale:2035268736, shift:43), (scale:1621193600, shift:42), (scale:1481296768, shift:43), (scale:1112815104, shift:42), (scale:1277442688, shift:43), (scale:2105725312, shift:43), (scale:1206106240, shift:43), (scale:1222936576, shift:42), (scale:1307760640, shift:43), (scale:1463655168, shift:43), (scale:1388564864, shift:42), (scale:2049880064, shift:43), (scale:1858432768, shift:43), (scale:1680590720, shift:43), (scale:1737617280, shift:43), (scale:1572778368, shift:43), (scale:1551745792, shift:43), (scale:1593064576, shift:43), (scale:1933064832, shift:43), (scale:1144022272, shift:42), (scale:1980307072, shift:43), (scale:1949902720, shift:43), (scale:1080234240, shift:42), (scale:1553839744, shift:43), (scale:1675762176, shift:43), (scale:1800335104, shift:43), (scale:1934780544, shift:43), (scale:1726980608, shift:43), (scale:2030910464, shift:43), (scale:2011809152, shift:43), (scale:1563739776, shift:43), (scale:1074846080, shift:42), (scale:1812603264, shift:43), (scale:1758670336, shift:43), (scale:1927792000, shift:43), (scale:1353776512, shift:43), (scale:1577195904, shift:43), (scale:1658243840, shift:43), (scale:1708691328, shift:43), (scale:1928167680, shift:43), (scale:1079362048, shift:42), (scale:1537404672, shift:43), (scale:1868099072, shift:43), (scale:1658732288, shift:43), (scale:1488416640, shift:43), (scale:1829909120, shift:43), (scale:2100358016, shift:43), (scale:1741324032, shift:43), (scale:1930039296, shift:43), (scale:1615412608, shift:43), (scale:1610676864, shift:43)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D
    Output 00 Int8 scale: [(scale:1285115648, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
9 Relu functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
    Input 00 Int8 scale: [(scale:1285115648, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
    Output 00 Int8 scale: [(scale:1285115648, shift:35)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
10 DepthwiseConv2D functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1285115648, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
    Input 01 Int8 scale: [(scale:1443064832, shift:37), (scale:1626474368, shift:38), (scale:1108856064, shift:37), (scale:1742836864, shift:38), (scale:1459007360, shift:38), (scale:1451106048, shift:37), (scale:1124030336, shift:38), (scale:2024264832, shift:38), (scale:1164180352, shift:38), (scale:1202871936, shift:37), (scale:1335792000, shift:37), (scale:2052092800, shift:38), (scale:1648422784, shift:38), (scale:1825270272, shift:38), (scale:2051987840, shift:38), (scale:2055072128, shift:38), (scale:1264699136, shift:37), (scale:1197251456, shift:37), (scale:2038382080, shift:38), (scale:1341286272, shift:38), (scale:1672669312, shift:38), (scale:2069471744, shift:38), (scale:1159708800, shift:38), (scale:1285290240, shift:37), (scale:1156410496, shift:38), (scale:1311717504, shift:38), (scale:1907664640, shift:38), (scale:1966439680, shift:38), (scale:1596604928, shift:37), (scale:2138117248, shift:38), (scale:1280972544, shift:38), (scale:2083718272, shift:38), (scale:2140180480, shift:38), (scale:1398972032, shift:38), (scale:1729058176, shift:38), (scale:1231629440, shift:38), (scale:1232161152, shift:37), (scale:1298262784, shift:37), (scale:1675111552, shift:38), (scale:2049285120, shift:39), (scale:1503264128, shift:38), (scale:1371875456, shift:38), (scale:1575143168, shift:38), (scale:1098279680, shift:38), (scale:1433077376, shift:38), (scale:1883795072, shift:38), (scale:1696941184, shift:38), (scale:1170690176, shift:37), (scale:1684608384, shift:38), (scale:1374521728, shift:37), (scale:1736215040, shift:38), (scale:1719291136, shift:37), (scale:1302240384, shift:38), (scale:1617303296, shift:38), (scale:1243250816, shift:37), (scale:1997172736, shift:38), (scale:2072570240, shift:38), (scale:2034194176, shift:38), (scale:1328418944, shift:38), (scale:2034920448, shift:38), (scale:1127586304, shift:37), (scale:1889290880, shift:38), (scale:1501662208, shift:37), (scale:2107579136, shift:38)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 3 functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource
    Input 02 Int32 scale: [(scale:1727142528, shift:42), (scale:1946657536, shift:43), (scale:1327142400, shift:42), (scale:2085926912, shift:43), (scale:1746223488, shift:43), (scale:1736766720, shift:42), (scale:1345303808, shift:43), (scale:1211377920, shift:42), (scale:1393357696, shift:43), (scale:1439665920, shift:42), (scale:1598752256, shift:42), (scale:1228030976, shift:42), (scale:1972926720, shift:43), (scale:1092293888, shift:42), (scale:1227968256, shift:42), (scale:1229813888, shift:42), (scale:1513664256, shift:42), (scale:1432939008, shift:42), (scale:1219826176, shift:42), (scale:1605328128, shift:43), (scale:2001946368, shift:43), (scale:1238431104, shift:42), (scale:1388005888, shift:43), (scale:1538308864, shift:42), (scale:1384058240, shift:43), (scale:1569938560, shift:43), (scale:1141601152, shift:42), (scale:1176773760, shift:42), (scale:1910908160, shift:42), (scale:1279510528, shift:42), (scale:1533141248, shift:43), (scale:1246956672, shift:42), (scale:1280745216, shift:42), (scale:1674369792, shift:43), (scale:2069435776, shift:43), (scale:1474084608, shift:43), (scale:1474721024, shift:42), (scale:1553835136, shift:42), (scale:2004869376, shift:43), (scale:1226350848, shift:43), (scale:1799192576, shift:43), (scale:1641939072, shift:43), (scale:1885221504, shift:43), (scale:1314483968, shift:43), (scale:1715188992, shift:43), (scale:1127316864, shift:42), (scale:2030996352, shift:43), (scale:1401148928, shift:42), (scale:2016235648, shift:43), (scale:1645106304, shift:42), (scale:2078001536, shift:43), (scale:2057746048, shift:42), (scale:1558595840, shift:43), (scale:1935681152, shift:43), (scale:1487993728, shift:42), (scale:1195165312, shift:42), (scale:1240285312, shift:42), (scale:1217319936, shift:42), (scale:1589927808, shift:43), (scale:1217754624, shift:42), (scale:1349559808, shift:42), (scale:1130605696, shift:42), (scale:1797275264, shift:42), (scale:1261235584, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource
    Output 00 Int8 scale: [(scale:1577148544, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
11 Relu functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1577148544, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
    Output 00 Int8 scale: [(scale:1577148544, shift:35)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
12 Conv2D functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
    Input 00 Int8 scale: [(scale:1577148544, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
    Input 01 Int8 scale: [(scale:1863724800, shift:39), (scale:2109638656, shift:40), (scale:1961520512, shift:39), (scale:1195189760, shift:38), (scale:1224187648, shift:38), (scale:1673181696, shift:39), (scale:2047420160, shift:39), (scale:1879607424, shift:39), (scale:1687176832, shift:39), (scale:1303134976, shift:39), (scale:1803716352, shift:39), (scale:1946363264, shift:39), (scale:2055114112, shift:39), (scale:1833580672, shift:39), (scale:1628952192, shift:39), (scale:1837843712, shift:39), (scale:1468153216, shift:39), (scale:1354978560, shift:39), (scale:1218520576, shift:39), (scale:1522567424, shift:39), (scale:1594123648, shift:39), (scale:2067559680, shift:39), (scale:1099234176, shift:38), (scale:1278900480, shift:39), (scale:2117757568, shift:39), (scale:1937855616, shift:40), (scale:1528192384, shift:39), (scale:1541464832, shift:39), (scale:2048757120, shift:39), (scale:1107013248, shift:38), (scale:1494630144, shift:39), (scale:1153654912, shift:38), (scale:1581562368, shift:39), (scale:1610798592, shift:39), (scale:1462448000, shift:39), (scale:1332861952, shift:39), (scale:1681374336, shift:39), (scale:1530865920, shift:39), (scale:1903420800, shift:39), (scale:1855637248, shift:39), (scale:1698240384, shift:39), (scale:1760665728, shift:39), (scale:1704585856, shift:39), (scale:1782982016, shift:39), (scale:1218571776, shift:38), (scale:1990299136, shift:39), (scale:1376934784, shift:39), (scale:2090388352, shift:39), (scale:1227487872, shift:39), (scale:2077491072, shift:39), (scale:1703966080, shift:39), (scale:1544664192, shift:39), (scale:1706559360, shift:39), (scale:1946924800, shift:39), (scale:1942351744, shift:39), (scale:1713386752, shift:39), (scale:1400965248, shift:39), (scale:1098118784, shift:38), (scale:1836725760, shift:39), (scale:1170026112, shift:38), (scale:1708500736, shift:39), (scale:1634204032, shift:39), (scale:1216194688, shift:39), (scale:1777225472, shift:39)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/conv2d_3/Conv2D
    Input 02 Int32 scale: [(scale:1368751232, shift:43), (scale:1549354496, shift:44), (scale:1440574080, shift:43), (scale:1755535360, shift:43), (scale:1798128512, shift:43), (scale:1228813056, shift:43), (scale:1503660160, shift:43), (scale:1380415744, shift:43), (scale:1239091328, shift:43), (scale:1914088960, shift:44), (scale:1324679936, shift:43), (scale:1429442304, shift:43), (scale:1509310848, shift:43), (scale:1346612864, shift:43), (scale:1196330240, shift:43), (scale:1349743744, shift:43), (scale:1078236672, shift:43), (scale:1990238592, shift:44), (scale:1789804544, shift:44), (scale:1118199424, shift:43), (scale:1170751488, shift:43), (scale:1518451072, shift:43), (scale:1614592640, shift:43), (scale:1878492544, shift:44), (scale:1555317248, shift:43), (scale:1423194112, shift:44), (scale:1122330496, shift:43), (scale:1132077952, shift:43), (scale:1504642048, shift:43), (scale:1626018688, shift:43), (scale:1097681792, shift:43), (scale:1694527616, shift:43), (scale:1161526272, shift:43), (scale:1182997888, shift:43), (scale:1074046720, shift:43), (scale:1957752960, shift:44), (scale:1234829952, shift:43), (scale:1124294016, shift:43), (scale:1397904640, shift:43), (scale:1362811520, shift:43), (scale:1247216640, shift:43), (scale:1293062912, shift:43), (scale:1251876864, shift:43), (scale:1309452288, shift:43), (scale:1789879680, shift:43), (scale:1461709568, shift:43), (scale:2022488704, shift:44), (scale:1535216768, shift:43), (scale:1802976000, shift:44), (scale:1525744768, shift:43), (scale:1251421696, shift:43), (scale:1134427648, shift:43), (scale:1253326208, shift:43), (scale:1429854720, shift:43), (scale:1426496128, shift:43), (scale:1258340352, shift:43), (scale:2057785472, shift:44), (scale:1612954240, shift:43), (scale:1348922624, shift:43), (scale:1718574208, shift:43), (scale:1254752000, shift:43), (scale:1200187264, shift:43), (scale:1786388224, shift:44), (scale:1305224576, shift:43)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D
    Output 00 Int8 scale: [(scale:1132866816, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
13 Relu functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
    Input 00 Int8 scale: [(scale:1132866816, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
    Output 00 Int8 scale: [(scale:1132866816, shift:35)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
14 DepthwiseConv2D functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1132866816, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
    Input 01 Int8 scale: [(scale:1769574528, shift:38), (scale:1436196608, shift:39), (scale:1332834944, shift:38), (scale:1882794880, shift:39), (scale:1135717888, shift:38), (scale:1140824448, shift:37), (scale:1855011072, shift:38), (scale:1521033088, shift:38), (scale:1664806784, shift:37), (scale:1240847744, shift:38), (scale:1423400320, shift:37), (scale:1118663936, shift:38), (scale:1524085376, shift:38), (scale:1225579008, shift:38), (scale:1079566208, shift:37), (scale:1432325888, shift:38), (scale:1504566272, shift:38), (scale:1597768960, shift:38), (scale:1453890944, shift:38), (scale:1279862528, shift:37), (scale:1646897408, shift:38), (scale:1187813376, shift:38), (scale:1901231616, shift:39), (scale:1535823488, shift:38), (scale:2004544512, shift:38), (scale:1255474688, shift:38), (scale:1848587392, shift:38), (scale:1125385472, shift:38), (scale:1181533824, shift:37), (scale:1731459456, shift:38), (scale:1243043200, shift:37), (scale:1215114752, shift:38), (scale:1898641792, shift:38), (scale:1976091264, shift:38), (scale:1287099136, shift:37), (scale:1961423616, shift:38), (scale:1667680000, shift:38), (scale:1447564544, shift:38), (scale:1338771968, shift:37), (scale:1458316800, shift:38), (scale:1691923328, shift:38), (scale:1093794688, shift:37), (scale:1339741568, shift:38), (scale:1621158656, shift:38), (scale:1262748160, shift:38), (scale:1245180544, shift:38), (scale:1669311872, shift:37), (scale:1121074048, shift:37), (scale:1222070784, shift:37), (scale:1197417984, shift:38), (scale:1975216768, shift:37), (scale:1576311296, shift:38), (scale:1419405312, shift:38), (scale:1565064832, shift:37), (scale:1182171392, shift:37), (scale:1713001472, shift:37), (scale:1074690304, shift:37), (scale:1725377024, shift:38), (scale:1729641472, shift:38), (scale:1532081664, shift:38), (scale:2083963392, shift:38), (scale:1782348288, shift:38), (scale:1676304512, shift:37), (scale:1076491648, shift:37)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 3 functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource
    Input 02 Int32 scale: [(scale:1867015168, shift:43), (scale:1515280000, shift:44), (scale:1406226816, shift:43), (scale:1986469888, shift:44), (scale:1198255616, shift:43), (scale:1203643264, shift:42), (scale:1957156224, shift:43), (scale:1604787968, shift:43), (scale:1756478464, shift:42), (scale:1309174272, shift:43), (scale:1501779072, shift:42), (scale:1180262528, shift:43), (scale:1608008320, shift:43), (scale:1293064832, shift:43), (scale:1139011968, shift:42), (scale:1511196160, shift:43), (scale:1587414400, shift:43), (scale:1685749248, shift:43), (scale:1533948672, shift:43), (scale:1350337408, shift:42), (scale:1737582848, shift:43), (scale:1253219712, shift:43), (scale:2005921920, shift:44), (scale:1620392704, shift:43), (scale:2114923648, shift:43), (scale:1324606720, shift:43), (scale:1950378880, shift:43), (scale:1187354240, shift:43), (scale:1246594304, shift:42), (scale:1826801280, shift:43), (scale:1311490688, shift:42), (scale:1282024320, shift:43), (scale:2003189376, shift:43), (scale:2084903680, shift:43), (scale:1357972480, shift:42), (scale:2069428352, shift:43), (scale:1759509888, shift:43), (scale:1527273856, shift:43), (scale:1412490752, shift:42), (scale:1538618240, shift:43), (scale:1785088128, shift:43), (scale:1154023936, shift:42), (scale:1413513728, shift:43), (scale:1710426880, shift:43), (scale:1332280704, shift:43), (scale:1313745664, shift:43), (scale:1761231616, shift:42), (scale:1182805376, shift:42), (scale:1289363456, shift:42), (scale:1263353088, shift:43), (scale:2083980928, shift:42), (scale:1663110016, shift:43), (scale:1497564032, shift:43), (scale:1651244288, shift:42), (scale:1247266944, shift:42), (scale:1807326976, shift:42), (scale:1133867520, shift:42), (scale:1820384000, shift:43), (scale:1824883200, shift:43), (scale:1616444928, shift:43), (scale:1099357824, shift:42), (scale:1880492288, shift:43), (scale:1768609280, shift:42), (scale:1135768064, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource
    Output 00 Int8 scale: [(scale:1609549056, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
15 Relu functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1609549056, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
    Output 00 Int8 scale: [(scale:1609549056, shift:35)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
16 Conv2D functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
    Input 00 Int8 scale: [(scale:1609549056, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
    Input 01 Int8 scale: [(scale:1103490560, shift:37), (scale:1089363840, shift:37), (scale:1941939968, shift:38), (scale:1134922112, shift:37), (scale:1322422528, shift:37), (scale:1349955072, shift:37), (scale:2142559232, shift:38), (scale:1213446272, shift:37), (scale:1076710272, shift:37), (scale:1197436800, shift:37), (scale:2025992576, shift:38), (scale:1132253696, shift:37), (scale:1151798656, shift:37), (scale:1741811840, shift:38), (scale:1472237696, shift:37), (scale:1945139584, shift:38), (scale:2004086912, shift:38), (scale:1158968064, shift:37), (scale:1331554304, shift:37), (scale:2059459712, shift:38), (scale:1826549760, shift:38), (scale:1309050496, shift:37), (scale:1278068608, shift:37), (scale:1465158784, shift:37), (scale:1969339520, shift:38), (scale:1781134208, shift:38), (scale:1081625472, shift:37), (scale:1401820288, shift:38), (scale:1138978432, shift:37), (scale:1437350400, shift:37), (scale:1752152832, shift:38), (scale:2023836032, shift:38), (scale:1261702272, shift:37), (scale:2069750144, shift:38), (scale:1704135424, shift:38), (scale:1183723520, shift:37), (scale:1783816064, shift:37), (scale:1640697856, shift:38), (scale:2132520064, shift:38), (scale:1130913408, shift:37), (scale:2000672128, shift:38), (scale:2056496896, shift:38), (scale:1687575424, shift:38), (scale:1778191872, shift:38), (scale:1227293824, shift:37), (scale:1932541952, shift:38), (scale:2127057408, shift:38), (scale:1173656704, shift:37), (scale:1674942464, shift:38), (scale:1131779456, shift:37), (scale:1077545856, shift:37), (scale:1163039104, shift:37), (scale:1117279872, shift:37), (scale:1211461888, shift:37), (scale:1098282496, shift:37), (scale:2108566528, shift:38), (scale:1250008960, shift:37), (scale:1251099520, shift:37), (scale:1328415616, shift:37), (scale:2087376384, shift:38), (scale:1938866688, shift:38), (scale:1269583104, shift:37), (scale:1581113216, shift:38), (scale:1269816064, shift:37)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/conv2d_4/Conv2D
    Input 02 Int32 scale: [(scale:1654142720, shift:42), (scale:1632966656, shift:42), (scale:1455493120, shift:42), (scale:1701258880, shift:42), (scale:1982323712, shift:42), (scale:2023595264, shift:42), (scale:1605858176, shift:42), (scale:1818967296, shift:42), (scale:1613998848, shift:42), (scale:1794968960, shift:42), (scale:1518490880, shift:42), (scale:1697258880, shift:42), (scale:1726556928, shift:42), (scale:1305496192, shift:42), (scale:1103449088, shift:41), (scale:1457891200, shift:42), (scale:1502072576, shift:42), (scale:1737303936, shift:42), (scale:1996012416, shift:42), (scale:1543574656, shift:42), (scale:1369007616, shift:42), (scale:1962278912, shift:42), (scale:1915836800, shift:42), (scale:1098143360, shift:41), (scale:1476029184, shift:42), (scale:1334968448, shift:42), (scale:1621366656, shift:42), (scale:2101341696, shift:43), (scale:1707339392, shift:42), (scale:1077300864, shift:41), (scale:1313246720, shift:42), (scale:1516874624, shift:42), (scale:1891303552, shift:42), (scale:1551287424, shift:42), (scale:1277257472, shift:42), (scale:1774412672, shift:42), (scale:1336978560, shift:41), (scale:1229710720, shift:42), (scale:1598333824, shift:42), (scale:1695249792, shift:42), (scale:1499513088, shift:42), (scale:1541354112, shift:42), (scale:1264845696, shift:42), (scale:1332763136, shift:42), (scale:1839724928, shift:42), (scale:1448449280, shift:42), (scale:1594239488, shift:42), (scale:1759322368, shift:42), (scale:1255377280, shift:42), (scale:1696547968, shift:42), (scale:1615251328, shift:42), (scale:1743406464, shift:42), (scale:1674813056, shift:42), (scale:1815992704, shift:42), (scale:1646335744, shift:42), (scale:1580380544, shift:42), (scale:1873775104, shift:42), (scale:1875409920, shift:42), (scale:1991307520, shift:42), (scale:1564498432, shift:42), (scale:1453189632, shift:42), (scale:1903116928, shift:42), (scale:1185051776, shift:42), (scale:1903466240, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D
    Output 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
17 Relu functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
    Input 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
    Output 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
18 AvgPool functional_1/average_pooling2d/AvgPool
    Input 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
    Output 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/average_pooling2d/AvgPool
19 FullyConnected functional_1/dense/BiasAdd
    Input 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/average_pooling2d/AvgPool
    Input 01 Int8 scale: [(scale:1152529408, shift:37)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/MatMul
    Input 02 Int32 scale: [(scale:1479592576, shift:41)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/ReadVariableOp/resource
    Output 00 Int8 scale: [(scale:1242899200, shift:33)], zero_point: [14], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd
20 MaxPool functional_1/dense/BiasAdd/maxpool
    Input 00 Int8 scale: [(scale:1242899200, shift:33)], zero_point: [14], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd
    Output 00 Int8 scale: [], zero_point: [14], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/maxpool
21 Sub functional_1/dense/BiasAdd/Sub
    Input 00 Int8 scale: [(scale:1242899200, shift:33)], zero_point: [14], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd
    Input 01 Int8 scale: [], zero_point: [14], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/maxpool
    Output 00 Int8 scale: [(scale:1, shift:0)], zero_point: [127], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub
22 LUT functional_1/dense/BiasAdd/Sub/lut
    Input 00 Int8 scale: [(scale:1, shift:0)], zero_point: [127], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 exp_lut
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [127], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut
23 Asr functional_1/dense/BiasAdd/Sub/lut/Asr
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 right_shift12
    Output 00 Int32 scale: [], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr
24 ReduceSum functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr
    Output 00 Int32 scale: [], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
25 CLZ functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
    Output 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
26 Sub headroom_offset/Sub
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 headroom_offset
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
    Output 00 Int32 scale: [], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 headroom_offset/Sub
27 Sub functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ/Sub
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 one_const
    Output 00 Int32 scale: [], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ/Sub
28 SHL functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ/Sub
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
29 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 neg_32_over_17
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul
30 Add functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
    Input 00 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 const_48_over_17
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
31 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
32 Sub F2_one/Sub
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one
    Input 01 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
33 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
34 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul
    Input 00 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 four
    Output 00 Int32 scale: [], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul
35 Add functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
36 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
37 Sub F2_one/Sub
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one
    Input 01 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
38 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
39 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul
    Input 00 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 four
    Output 00 Int32 scale: [], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul
40 Add functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
41 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
42 Sub F2_one/Sub
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one
    Input 01 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
43 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
44 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul
    Input 00 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 four
    Output 00 Int32 scale: [], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul
45 Add functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add
46 Mul functional_1/dense/BiasAdd/Sub/lut/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Mul
47 Asr Identity
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Mul
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 headroom_offset/Sub
    Output 00 Int8 scale: [(scale:1073741824, shift:38)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 Identity


[ Before Graph Optimisation ]
0     Conv2D               functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
1     Relu                 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
2     DepthwiseConv2D      functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
3     Relu                 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
4     Conv2D               functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
5     Relu                 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
6     DepthwiseConv2D      functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
7     Relu                 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
8     Conv2D               functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
9     Relu                 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
10    DepthwiseConv2D      functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
11    Relu                 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
12    Conv2D               functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
13    Relu                 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
14    DepthwiseConv2D      functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
15    Relu                 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
16    Conv2D               functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
17    Relu                 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
18    AvgPool              functional_1/average_pooling2d/AvgPool
19    FullyConnected       functional_1/dense/BiasAdd    
20    MaxPool              functional_1/dense/BiasAdd/maxpool
21    Sub                  functional_1/dense/BiasAdd/Sub
22    LUT                  functional_1/dense/BiasAdd/Sub/lut
23    Asr                  functional_1/dense/BiasAdd/Sub/lut/Asr
24    ReduceSum            functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
25    CLZ                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
26    Sub                  headroom_offset/Sub           
27    Sub                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ/Sub
28    SHL                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
29    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul
30    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
31    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
32    Sub                  F2_one/Sub                    
33    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
34    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul
35    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
36    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
37    Sub                  F2_one/Sub                    
38    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
39    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul
40    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
41    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
42    Sub                  F2_one/Sub                    
43    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
44    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul
45    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add
46    Mul                  functional_1/dense/BiasAdd/Sub/lut/Mul
47    Asr                  Identity                      


[ After Graph Optimization ]
0     Conv2D               functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
1     Relu                 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
2     DepthwiseConv2D      functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
3     Relu                 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
4     Conv2D               functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
5     Relu                 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
6     DepthwiseConv2D      functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
7     Relu                 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
8     Conv2D               functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
9     Relu                 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
10    DepthwiseConv2D      functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
11    Relu                 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
12    Conv2D               functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
13    Relu                 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
14    DepthwiseConv2D      functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
15    Relu                 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
16    Conv2D               functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
17    Relu                 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
18    AvgPool              functional_1/average_pooling2d/AvgPool
19    FullyConnected       functional_1/dense/BiasAdd    
20    MaxPool              functional_1/dense/BiasAdd/maxpool
21    Sub                  functional_1/dense/BiasAdd/Sub
22    LUT                  functional_1/dense/BiasAdd/Sub/lut
23    Asr                  functional_1/dense/BiasAdd/Sub/lut/Asr
24    ReduceSum            functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
25    CLZ                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
26    Sub                  headroom_offset/Sub           
27    Sub                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ/Sub
28    SHL                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
29    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul
30    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
31    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
32    Sub                  F2_one/Sub                    
33    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
34    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul
35    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
36    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
37    Sub                  F2_one/Sub                    
38    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
39    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul
40    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
41    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
42    Sub                  F2_one/Sub                    
43    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
44    Mul                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul
45    Add                  functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add
46    Mul                  functional_1/dense/BiasAdd/Sub/lut/Mul
47    Asr                  Identity                      


[ Graph With Tensor Quantization ]
0 Conv2D functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
    Input 00 Int8 scale: [(scale:1255639936, shift:31)], zero_point: [83], quantMin: [], quantMax: [], dimension: 0 input_1
    Input 01 Int8 scale: [(scale:1464379008, shift:40), (scale:1627438592, shift:41), (scale:2075258880, shift:42), (scale:1168237824, shift:41), (scale:1974605056, shift:42), (scale:1721740160, shift:41), (scale:1753228160, shift:40), (scale:1488934784, shift:41), (scale:1158502912, shift:41), (scale:1188821888, shift:42), (scale:2093692416, shift:41), (scale:1192383104, shift:41), (scale:1241635712, shift:40), (scale:1341249536, shift:41), (scale:1510890880, shift:41), (scale:1695192704, shift:42), (scale:1737978496, shift:40), (scale:1398920704, shift:42), (scale:1746344320, shift:42), (scale:1183181312, shift:41), (scale:1977891584, shift:42), (scale:2113310208, shift:41), (scale:1867738624, shift:42), (scale:2071492864, shift:40), (scale:1785629696, shift:42), (scale:1601047552, shift:41), (scale:2084708864, shift:42), (scale:1776369664, shift:41), (scale:1110910976, shift:40), (scale:1188599936, shift:40), (scale:1304962560, shift:41), (scale:2105906560, shift:41), (scale:1524456576, shift:41), (scale:1199206144, shift:41), (scale:1698997888, shift:41), (scale:1483576448, shift:41), (scale:1413839616, shift:40), (scale:1961673344, shift:42), (scale:1395400576, shift:42), (scale:1804189824, shift:42), (scale:1684543488, shift:42), (scale:1297103488, shift:41), (scale:1180393728, shift:41), (scale:1112020992, shift:39), (scale:1304851456, shift:40), (scale:1339063296, shift:40), (scale:1462929152, shift:41), (scale:1156472320, shift:41), (scale:1637322240, shift:41), (scale:1713849088, shift:40), (scale:1621298432, shift:41), (scale:1104686080, shift:40), (scale:1114051584, shift:40), (scale:1806657408, shift:42), (scale:1706757760, shift:41), (scale:1979592448, shift:40), (scale:1814144384, shift:42), (scale:1384162944, shift:41), (scale:1765874944, shift:41), (scale:1857623040, shift:42), (scale:1349751680, shift:41), (scale:1080475776, shift:41), (scale:2000449024, shift:41), (scale:1812903424, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/conv2d/Conv2D
    Input 02 Int32 scale: [(scale:1712453376, shift:41), (scale:1903136128, shift:42), (scale:1213409920, shift:42), (scale:1366144128, shift:42), (scale:1154557312, shift:42), (scale:2013412992, shift:42), (scale:2050235264, shift:41), (scale:1741169024, shift:42), (scale:1354760064, shift:42), (scale:1390215296, shift:43), (scale:1224188032, shift:41), (scale:1394379776, shift:42), (scale:1451976064, shift:41), (scale:1568465024, shift:42), (scale:1766844544, shift:42), (scale:1982368256, shift:43), (scale:2032402176, shift:41), (scale:1635906048, shift:43), (scale:2042185216, shift:43), (scale:1383619072, shift:42), (scale:1156478976, shift:42), (scale:1235658624, shift:41), (scale:1092072192, shift:42), (scale:1211207936, shift:40), (scale:2088125696, shift:43), (scale:1872274304, shift:42), (scale:1218935296, shift:42), (scale:2077297024, shift:42), (scale:1299105792, shift:41), (scale:1389955712, shift:41), (scale:1526030848, shift:42), (scale:1231329664, shift:41), (scale:1782708352, shift:42), (scale:1402358656, shift:42), (scale:1986818048, shift:42), (scale:1734902912, shift:42), (scale:1653352320, shift:41), (scale:1146996096, shift:42), (scale:1631789568, shift:43), (scale:2109830016, shift:43), (scale:1969915008, shift:43), (scale:1516840320, shift:42), (scale:1380359296, shift:42), (scale:1300403840, shift:40), (scale:1525900928, shift:41), (scale:1565908352, shift:41), (scale:1710757888, shift:42), (scale:1352385408, shift:42), (scale:1914694144, shift:42), (scale:2004185088, shift:41), (scale:1895955840, shift:42), (scale:1291826304, shift:41), (scale:1302778368, shift:41), (scale:2112715648, shift:43), (scale:1995892480, shift:42), (scale:1157473408, shift:40), (scale:2121470976, shift:43), (scale:1618648192, shift:42), (scale:2065024384, shift:42), (scale:1086157568, shift:42), (scale:1578407424, shift:42), (scale:1263514624, shift:42), (scale:1169668352, shift:41), (scale:2120019840, shift:43)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D
    Output 00 Int8 scale: [(scale:1352492032, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
1 Relu functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
    Input 00 Int8 scale: [(scale:1352492032, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
    Output 00 Int8 scale: [(scale:1352492032, shift:34)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
2 DepthwiseConv2D functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1352492032, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
    Input 01 Int8 scale: [(scale:1175311872, shift:37), (scale:1421834240, shift:38), (scale:1271638528, shift:37), (scale:1767601536, shift:37), (scale:1557757056, shift:37), (scale:1964024960, shift:37), (scale:1340253440, shift:37), (scale:1632174336, shift:38), (scale:1362240512, shift:37), (scale:1455178240, shift:38), (scale:1301060352, shift:37), (scale:1534470784, shift:37), (scale:1505380864, shift:37), (scale:1607027712, shift:37), (scale:2074724736, shift:38), (scale:1142046336, shift:37), (scale:1205169408, shift:37), (scale:1980826496, shift:37), (scale:1788229376, shift:37), (scale:1879952768, shift:37), (scale:2140038912, shift:37), (scale:1967693440, shift:38), (scale:1371067008, shift:36), (scale:1222602752, shift:37), (scale:2044833408, shift:37), (scale:1474644096, shift:38), (scale:1265859456, shift:37), (scale:1932803968, shift:37), (scale:1682347648, shift:37), (scale:1849218560, shift:37), (scale:1137651584, shift:37), (scale:1620537088, shift:38), (scale:1330349056, shift:37), (scale:1458722176, shift:37), (scale:1262768512, shift:37), (scale:1439908864, shift:37), (scale:1143717888, shift:37), (scale:1255351168, shift:38), (scale:1737809280, shift:37), (scale:1521102720, shift:37), (scale:1310250368, shift:36), (scale:1701335296, shift:37), (scale:1126833920, shift:36), (scale:1467101824, shift:37), (scale:1102162304, shift:37), (scale:1211554304, shift:37), (scale:2127924352, shift:38), (scale:1508294144, shift:38), (scale:1134804864, shift:36), (scale:1403477120, shift:37), (scale:1413260928, shift:37), (scale:1539753600, shift:36), (scale:1543505408, shift:37), (scale:2064233344, shift:38), (scale:1818934528, shift:38), (scale:1809568256, shift:38), (scale:1679345920, shift:37), (scale:2092672000, shift:38), (scale:1182935296, shift:36), (scale:1790981376, shift:37), (scale:1380477440, shift:37), (scale:1797254400, shift:38), (scale:1616903808, shift:37), (scale:1895568512, shift:37)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 3 functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource
    Input 02 Int32 scale: [(scale:1480430336, shift:41), (scale:1790951424, shift:42), (scale:1601763968, shift:41), (scale:1113241088, shift:40), (scale:1962160640, shift:41), (scale:1236949120, shift:40), (scale:1688191744, shift:41), (scale:2055897216, shift:42), (scale:1715886848, shift:41), (scale:1832951808, shift:42), (scale:1638823936, shift:41), (scale:1932829184, shift:41), (scale:1896187264, shift:41), (scale:2024222336, shift:41), (scale:1306668288, shift:41), (scale:1438528768, shift:41), (scale:1518039040, shift:41), (scale:1247530880, shift:40), (scale:1126232576, shift:40), (scale:1184000256, shift:40), (scale:1347803264, shift:40), (scale:1239259648, shift:41), (scale:1727004672, shift:40), (scale:1539998208, shift:41), (scale:1287842560, shift:40), (scale:1857471104, shift:42), (scale:1594484608, shift:41), (scale:1217286144, shift:40), (scale:2119095808, shift:41), (scale:1164643712, shift:40), (scale:1432993152, shift:41), (scale:2041238784, shift:42), (scale:1675716096, shift:41), (scale:1837415680, shift:41), (scale:1590591232, shift:41), (scale:1813718400, shift:41), (scale:1440634368, shift:41), (scale:1581248256, shift:42), (scale:1094477824, shift:40), (scale:1915990656, shift:41), (scale:1650399744, shift:40), (scale:2143012736, shift:41), (scale:1419367168, shift:40), (scale:1847970816, shift:41), (scale:1388290688, shift:41), (scale:1526081536, shift:41), (scale:1340173568, shift:41), (scale:1899856896, shift:42), (scale:1429407488, shift:40), (scale:1767828736, shift:41), (scale:1780152448, shift:41), (scale:1939483392, shift:40), (scale:1944209280, shift:41), (scale:1300060672, shift:41), (scale:1145570688, shift:41), (scale:1139671808, shift:41), (scale:2115314816, shift:41), (scale:1317971456, shift:41), (scale:1490032768, shift:40), (scale:1127965824, shift:40), (scale:1738858112, shift:41), (scale:1131916544, shift:41), (scale:2036662272, shift:41), (scale:1193835136, shift:40)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource
    Output 00 Int8 scale: [(scale:1422750976, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
3 Relu functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1422750976, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
    Output 00 Int8 scale: [(scale:1422750976, shift:34)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
4 Conv2D functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
    Input 00 Int8 scale: [(scale:1422750976, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
    Input 01 Int8 scale: [(scale:1270611200, shift:39), (scale:2030643712, shift:39), (scale:1644547200, shift:39), (scale:1274715008, shift:39), (scale:2034716288, shift:39), (scale:1319735296, shift:39), (scale:1097028992, shift:39), (scale:1806930304, shift:39), (scale:1675453184, shift:39), (scale:2144237824, shift:39), (scale:1841686400, shift:39), (scale:1626432000, shift:39), (scale:1143902976, shift:38), (scale:1698825600, shift:39), (scale:1795597696, shift:39), (scale:1543490048, shift:39), (scale:1347438720, shift:39), (scale:1668319104, shift:39), (scale:2038381824, shift:39), (scale:1589206784, shift:39), (scale:1710085504, shift:39), (scale:1645939584, shift:39), (scale:1300315648, shift:38), (scale:1830330496, shift:39), (scale:1526757248, shift:39), (scale:1863892992, shift:39), (scale:1325160448, shift:39), (scale:1427883392, shift:39), (scale:1518774144, shift:39), (scale:1850537472, shift:39), (scale:2038893184, shift:39), (scale:2012493696, shift:39), (scale:1608130816, shift:39), (scale:1479658112, shift:39), (scale:1104901376, shift:38), (scale:1808917120, shift:39), (scale:1817939712, shift:39), (scale:2125389056, shift:39), (scale:2083040256, shift:39), (scale:1571339776, shift:39), (scale:1132971264, shift:38), (scale:2043926656, shift:39), (scale:1689693696, shift:39), (scale:1087454464, shift:38), (scale:1903368448, shift:39), (scale:1731485568, shift:39), (scale:1077008384, shift:39), (scale:1954194944, shift:39), (scale:1262896768, shift:39), (scale:1708360064, shift:39), (scale:1683638400, shift:39), (scale:1548113408, shift:39), (scale:1464501632, shift:39), (scale:2042817536, shift:39), (scale:2064977792, shift:39), (scale:1936098048, shift:39), (scale:1109349504, shift:39), (scale:1603760256, shift:39), (scale:1557180928, shift:39), (scale:1261184000, shift:39), (scale:1872705280, shift:39), (scale:1398821760, shift:39), (scale:1747156736, shift:39), (scale:1785712640, shift:39)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/conv2d_1/Conv2D
    Input 02 Int32 scale: [(scale:1683610752, shift:43), (scale:1345342208, shift:42), (scale:1089545472, shift:42), (scale:1689048448, shift:43), (scale:1348040320, shift:42), (scale:1748702208, shift:43), (scale:1453607424, shift:43), (scale:1197127552, shift:42), (scale:1110021376, shift:42), (scale:1420600576, shift:42), (scale:1220154112, shift:42), (scale:1077543808, shift:42), (scale:1515717376, shift:42), (scale:1125506048, shift:42), (scale:1189619456, shift:42), (scale:2045186176, shift:43), (scale:1785410304, shift:43), (scale:1105294848, shift:42), (scale:1350468864, shift:42), (scale:2105762688, shift:43), (scale:1132965888, shift:42), (scale:1090467968, shift:42), (scale:1722970368, shift:42), (scale:1212630656, shift:42), (scale:2023014528, shift:43), (scale:1234866432, shift:42), (scale:1755890688, shift:43), (scale:1892002816, shift:43), (scale:2012436608, shift:43), (scale:1226018176, shift:42), (scale:1350807680, shift:42), (scale:1333317376, shift:42), (scale:2130837760, shift:43), (scale:1960606336, shift:43), (scale:1464038656, shift:42), (scale:1198443904, shift:42), (scale:1204421504, shift:42), (scale:1408112896, shift:42), (scale:1380055936, shift:42), (scale:2082088192, shift:43), (scale:1501232384, shift:42), (scale:1354142336, shift:42), (scale:1119456000, shift:42), (scale:1440920832, shift:42), (scale:1261019776, shift:42), (scale:1147143936, shift:42), (scale:1427079296, shift:43), (scale:1294693376, shift:42), (scale:1673388800, shift:43), (scale:1131822848, shift:42), (scale:1115444224, shift:42), (scale:2051312384, shift:43), (scale:1940523392, shift:43), (scale:1353407616, shift:42), (scale:1368089216, shift:42), (scale:1282703744, shift:42), (scale:1469932544, shift:43), (scale:2125046656, shift:43), (scale:2063327232, shift:43), (scale:1671119360, shift:43), (scale:1240704768, shift:42), (scale:1853494912, shift:43), (scale:1157526400, shift:42), (scale:1183070464, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D
    Output 00 Int8 scale: [(scale:2062467200, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
5 Relu functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
    Input 00 Int8 scale: [(scale:2062467200, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
    Output 00 Int8 scale: [(scale:2062467200, shift:35)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
6 DepthwiseConv2D functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:2062467200, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
    Input 01 Int8 scale: [(scale:1792217088, shift:38), (scale:1776190720, shift:38), (scale:1770845568, shift:37), (scale:1272406144, shift:37), (scale:1814885248, shift:38), (scale:1965241728, shift:37), (scale:1624973184, shift:38), (scale:1544612480, shift:38), (scale:1698108160, shift:37), (scale:1817450240, shift:38), (scale:2040592768, shift:38), (scale:2053262464, shift:38), (scale:1941416064, shift:38), (scale:1878308864, shift:38), (scale:1215870208, shift:37), (scale:1190906112, shift:37), (scale:2133784704, shift:38), (scale:1085578624, shift:37), (scale:1814735360, shift:38), (scale:1483078016, shift:38), (scale:1287174528, shift:38), (scale:1270013696, shift:36), (scale:1952631296, shift:38), (scale:1834623872, shift:38), (scale:2137792128, shift:38), (scale:1287734656, shift:37), (scale:2137980672, shift:38), (scale:1595241984, shift:38), (scale:1935896320, shift:38), (scale:1157065856, shift:37), (scale:1493662336, shift:38), (scale:1802953344, shift:38), (scale:1137304064, shift:36), (scale:1906626688, shift:38), (scale:1792789248, shift:38), (scale:1535577088, shift:37), (scale:1342918912, shift:38), (scale:1487831552, shift:38), (scale:2146545408, shift:38), (scale:1384833664, shift:38), (scale:1199503360, shift:37), (scale:1423974528, shift:37), (scale:1109840768, shift:37), (scale:1148437888, shift:38), (scale:1714945024, shift:38), (scale:1258835584, shift:37), (scale:1484821760, shift:37), (scale:1762760576, shift:38), (scale:1948180736, shift:38), (scale:1615223296, shift:38), (scale:1544111488, shift:37), (scale:1810116224, shift:37), (scale:1129528320, shift:37), (scale:1880874624, shift:38), (scale:1576878592, shift:38), (scale:1967843072, shift:38), (scale:1340814848, shift:37), (scale:1297278464, shift:37), (scale:1349762944, shift:37), (scale:2047192576, shift:38), (scale:2040242432, shift:38), (scale:2015957760, shift:38), (scale:1827989504, shift:38), (scale:2056193920, shift:38)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 3 functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource
    Input 02 Int32 scale: [(scale:1721265280, shift:42), (scale:1705873280, shift:42), (scale:1700739840, shift:41), (scale:1222033024, shift:41), (scale:1743036032, shift:42), (scale:1887440000, shift:41), (scale:1560642304, shift:42), (scale:1483463040, shift:42), (scale:1630881920, shift:41), (scale:1745499392, shift:42), (scale:1959808000, shift:42), (scale:1971976064, shift:42), (scale:1864557568, shift:42), (scale:1803948800, shift:42), (scale:1167735296, shift:41), (scale:1143759488, shift:41), (scale:2049310592, shift:42), (scale:2085203584, shift:42), (scale:1742892032, shift:42), (scale:1424364672, shift:42), (scale:1236216704, shift:42), (scale:1219735296, shift:40), (scale:1875328896, shift:42), (scale:1761993216, shift:42), (scale:2053159296, shift:42), (scale:1236754688, shift:41), (scale:2053340416, shift:42), (scale:1532088192, shift:42), (scale:1859256320, shift:42), (scale:1111258880, shift:41), (scale:1434529920, shift:42), (scale:1731576448, shift:42), (scale:1092279424, shift:40), (scale:1831145472, shift:42), (scale:1721814784, shift:42), (scale:1474785280, shift:41), (scale:1289754240, shift:42), (scale:1428930048, shift:42), (scale:2061566080, shift:42), (scale:1330009728, shift:42), (scale:1152016384, shift:41), (scale:1367601024, shift:41), (scale:2131806848, shift:42), (scale:1102972544, shift:42), (scale:1647052288, shift:42), (scale:1208999680, shift:41), (scale:1426039296, shift:41), (scale:1692974848, shift:42), (scale:1871054464, shift:42), (scale:1551278464, shift:42), (scale:1482981888, shift:41), (scale:1738455808, shift:41), (scale:1084811520, shift:41), (scale:1806412928, shift:42), (scale:1514451712, shift:42), (scale:1889938432, shift:42), (scale:1287733504, shift:41), (scale:1245920640, shift:41), (scale:1296327296, shift:41), (scale:1966146560, shift:42), (scale:1959471488, shift:42), (scale:1936148224, shift:42), (scale:1755621504, shift:42), (scale:1974791552, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource
    Output 00 Int8 scale: [(scale:1078209024, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
7 Relu functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1078209024, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
    Output 00 Int8 scale: [(scale:1078209024, shift:34)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
8 Conv2D functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
    Input 00 Int8 scale: [(scale:1078209024, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
    Input 01 Int8 scale: [(scale:1612059136, shift:39), (scale:1775348480, shift:39), (scale:1644174208, shift:39), (scale:1761611136, shift:39), (scale:1954601984, shift:39), (scale:1292690944, shift:38), (scale:1128286592, shift:38), (scale:1686442880, shift:39), (scale:1895414912, shift:39), (scale:1503374720, shift:39), (scale:1264453248, shift:38), (scale:1539396992, shift:39), (scale:1422953856, shift:39), (scale:2026836224, shift:39), (scale:1614476672, shift:38), (scale:1475159552, shift:39), (scale:1108204544, shift:38), (scale:1272150016, shift:39), (scale:2097000960, shift:39), (scale:1201109120, shift:39), (scale:1217869696, shift:38), (scale:1302342400, shift:39), (scale:1457591040, shift:39), (scale:1382811776, shift:38), (scale:2041387008, shift:39), (scale:1850732928, shift:39), (scale:1673627776, shift:39), (scale:1730418048, shift:39), (scale:1566262144, shift:39), (scale:1545316608, shift:39), (scale:1586464256, shift:39), (scale:1925055872, shift:39), (scale:1139282432, shift:38), (scale:1972102272, shift:39), (scale:1941824000, shift:39), (scale:1075758592, shift:38), (scale:1547401984, shift:39), (scale:1668819200, shift:39), (scale:1792876032, shift:39), (scale:1926764416, shift:39), (scale:1719825408, shift:39), (scale:2022496000, shift:39), (scale:2003473920, shift:39), (scale:1557260928, shift:39), (scale:2140785664, shift:39), (scale:1805093376, shift:39), (scale:1751383808, shift:39), (scale:1919804800, shift:39), (scale:1348167552, shift:39), (scale:1570661376, shift:39), (scale:1651373440, shift:39), (scale:1701611904, shift:39), (scale:1920178944, shift:39), (scale:1074890112, shift:38), (scale:1531035008, shift:39), (scale:1860359168, shift:39), (scale:1651859840, shift:39), (scale:1482249856, shift:39), (scale:1822327552, shift:39), (scale:2091655936, shift:39), (scale:1734109440, shift:39), (scale:1922042880, shift:39), (scale:1608719744, shift:39), (scale:1604003584, shift:39)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/conv2d_2/Conv2D
    Input 02 Int32 scale: [(scale:1618765952, shift:43), (scale:1782734592, shift:43), (scale:1651014656, shift:43), (scale:1768940160, shift:43), (scale:1962733952, shift:43), (scale:1298069120, shift:42), (scale:1132980736, shift:42), (scale:1693459200, shift:43), (scale:1903300608, shift:43), (scale:1509629312, shift:43), (scale:1269713920, shift:42), (scale:1545801472, shift:43), (scale:1428873856, shift:43), (scale:2035268736, shift:43), (scale:1621193600, shift:42), (scale:1481296768, shift:43), (scale:1112815104, shift:42), (scale:1277442688, shift:43), (scale:2105725312, shift:43), (scale:1206106240, shift:43), (scale:1222936576, shift:42), (scale:1307760640, shift:43), (scale:1463655168, shift:43), (scale:1388564864, shift:42), (scale:2049880064, shift:43), (scale:1858432768, shift:43), (scale:1680590720, shift:43), (scale:1737617280, shift:43), (scale:1572778368, shift:43), (scale:1551745792, shift:43), (scale:1593064576, shift:43), (scale:1933064832, shift:43), (scale:1144022272, shift:42), (scale:1980307072, shift:43), (scale:1949902720, shift:43), (scale:1080234240, shift:42), (scale:1553839744, shift:43), (scale:1675762176, shift:43), (scale:1800335104, shift:43), (scale:1934780544, shift:43), (scale:1726980608, shift:43), (scale:2030910464, shift:43), (scale:2011809152, shift:43), (scale:1563739776, shift:43), (scale:1074846080, shift:42), (scale:1812603264, shift:43), (scale:1758670336, shift:43), (scale:1927792000, shift:43), (scale:1353776512, shift:43), (scale:1577195904, shift:43), (scale:1658243840, shift:43), (scale:1708691328, shift:43), (scale:1928167680, shift:43), (scale:1079362048, shift:42), (scale:1537404672, shift:43), (scale:1868099072, shift:43), (scale:1658732288, shift:43), (scale:1488416640, shift:43), (scale:1829909120, shift:43), (scale:2100358016, shift:43), (scale:1741324032, shift:43), (scale:1930039296, shift:43), (scale:1615412608, shift:43), (scale:1610676864, shift:43)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D
    Output 00 Int8 scale: [(scale:1285115648, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
9 Relu functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
    Input 00 Int8 scale: [(scale:1285115648, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
    Output 00 Int8 scale: [(scale:1285115648, shift:35)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
10 DepthwiseConv2D functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1285115648, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
    Input 01 Int8 scale: [(scale:1443064832, shift:37), (scale:1626474368, shift:38), (scale:1108856064, shift:37), (scale:1742836864, shift:38), (scale:1459007360, shift:38), (scale:1451106048, shift:37), (scale:1124030336, shift:38), (scale:2024264832, shift:38), (scale:1164180352, shift:38), (scale:1202871936, shift:37), (scale:1335792000, shift:37), (scale:2052092800, shift:38), (scale:1648422784, shift:38), (scale:1825270272, shift:38), (scale:2051987840, shift:38), (scale:2055072128, shift:38), (scale:1264699136, shift:37), (scale:1197251456, shift:37), (scale:2038382080, shift:38), (scale:1341286272, shift:38), (scale:1672669312, shift:38), (scale:2069471744, shift:38), (scale:1159708800, shift:38), (scale:1285290240, shift:37), (scale:1156410496, shift:38), (scale:1311717504, shift:38), (scale:1907664640, shift:38), (scale:1966439680, shift:38), (scale:1596604928, shift:37), (scale:2138117248, shift:38), (scale:1280972544, shift:38), (scale:2083718272, shift:38), (scale:2140180480, shift:38), (scale:1398972032, shift:38), (scale:1729058176, shift:38), (scale:1231629440, shift:38), (scale:1232161152, shift:37), (scale:1298262784, shift:37), (scale:1675111552, shift:38), (scale:2049285120, shift:39), (scale:1503264128, shift:38), (scale:1371875456, shift:38), (scale:1575143168, shift:38), (scale:1098279680, shift:38), (scale:1433077376, shift:38), (scale:1883795072, shift:38), (scale:1696941184, shift:38), (scale:1170690176, shift:37), (scale:1684608384, shift:38), (scale:1374521728, shift:37), (scale:1736215040, shift:38), (scale:1719291136, shift:37), (scale:1302240384, shift:38), (scale:1617303296, shift:38), (scale:1243250816, shift:37), (scale:1997172736, shift:38), (scale:2072570240, shift:38), (scale:2034194176, shift:38), (scale:1328418944, shift:38), (scale:2034920448, shift:38), (scale:1127586304, shift:37), (scale:1889290880, shift:38), (scale:1501662208, shift:37), (scale:2107579136, shift:38)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 3 functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource
    Input 02 Int32 scale: [(scale:1727142528, shift:42), (scale:1946657536, shift:43), (scale:1327142400, shift:42), (scale:2085926912, shift:43), (scale:1746223488, shift:43), (scale:1736766720, shift:42), (scale:1345303808, shift:43), (scale:1211377920, shift:42), (scale:1393357696, shift:43), (scale:1439665920, shift:42), (scale:1598752256, shift:42), (scale:1228030976, shift:42), (scale:1972926720, shift:43), (scale:1092293888, shift:42), (scale:1227968256, shift:42), (scale:1229813888, shift:42), (scale:1513664256, shift:42), (scale:1432939008, shift:42), (scale:1219826176, shift:42), (scale:1605328128, shift:43), (scale:2001946368, shift:43), (scale:1238431104, shift:42), (scale:1388005888, shift:43), (scale:1538308864, shift:42), (scale:1384058240, shift:43), (scale:1569938560, shift:43), (scale:1141601152, shift:42), (scale:1176773760, shift:42), (scale:1910908160, shift:42), (scale:1279510528, shift:42), (scale:1533141248, shift:43), (scale:1246956672, shift:42), (scale:1280745216, shift:42), (scale:1674369792, shift:43), (scale:2069435776, shift:43), (scale:1474084608, shift:43), (scale:1474721024, shift:42), (scale:1553835136, shift:42), (scale:2004869376, shift:43), (scale:1226350848, shift:43), (scale:1799192576, shift:43), (scale:1641939072, shift:43), (scale:1885221504, shift:43), (scale:1314483968, shift:43), (scale:1715188992, shift:43), (scale:1127316864, shift:42), (scale:2030996352, shift:43), (scale:1401148928, shift:42), (scale:2016235648, shift:43), (scale:1645106304, shift:42), (scale:2078001536, shift:43), (scale:2057746048, shift:42), (scale:1558595840, shift:43), (scale:1935681152, shift:43), (scale:1487993728, shift:42), (scale:1195165312, shift:42), (scale:1240285312, shift:42), (scale:1217319936, shift:42), (scale:1589927808, shift:43), (scale:1217754624, shift:42), (scale:1349559808, shift:42), (scale:1130605696, shift:42), (scale:1797275264, shift:42), (scale:1261235584, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource
    Output 00 Int8 scale: [(scale:1577148544, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
11 Relu functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1577148544, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
    Output 00 Int8 scale: [(scale:1577148544, shift:35)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
12 Conv2D functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
    Input 00 Int8 scale: [(scale:1577148544, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
    Input 01 Int8 scale: [(scale:1863724800, shift:39), (scale:2109638656, shift:40), (scale:1961520512, shift:39), (scale:1195189760, shift:38), (scale:1224187648, shift:38), (scale:1673181696, shift:39), (scale:2047420160, shift:39), (scale:1879607424, shift:39), (scale:1687176832, shift:39), (scale:1303134976, shift:39), (scale:1803716352, shift:39), (scale:1946363264, shift:39), (scale:2055114112, shift:39), (scale:1833580672, shift:39), (scale:1628952192, shift:39), (scale:1837843712, shift:39), (scale:1468153216, shift:39), (scale:1354978560, shift:39), (scale:1218520576, shift:39), (scale:1522567424, shift:39), (scale:1594123648, shift:39), (scale:2067559680, shift:39), (scale:1099234176, shift:38), (scale:1278900480, shift:39), (scale:2117757568, shift:39), (scale:1937855616, shift:40), (scale:1528192384, shift:39), (scale:1541464832, shift:39), (scale:2048757120, shift:39), (scale:1107013248, shift:38), (scale:1494630144, shift:39), (scale:1153654912, shift:38), (scale:1581562368, shift:39), (scale:1610798592, shift:39), (scale:1462448000, shift:39), (scale:1332861952, shift:39), (scale:1681374336, shift:39), (scale:1530865920, shift:39), (scale:1903420800, shift:39), (scale:1855637248, shift:39), (scale:1698240384, shift:39), (scale:1760665728, shift:39), (scale:1704585856, shift:39), (scale:1782982016, shift:39), (scale:1218571776, shift:38), (scale:1990299136, shift:39), (scale:1376934784, shift:39), (scale:2090388352, shift:39), (scale:1227487872, shift:39), (scale:2077491072, shift:39), (scale:1703966080, shift:39), (scale:1544664192, shift:39), (scale:1706559360, shift:39), (scale:1946924800, shift:39), (scale:1942351744, shift:39), (scale:1713386752, shift:39), (scale:1400965248, shift:39), (scale:1098118784, shift:38), (scale:1836725760, shift:39), (scale:1170026112, shift:38), (scale:1708500736, shift:39), (scale:1634204032, shift:39), (scale:1216194688, shift:39), (scale:1777225472, shift:39)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/conv2d_3/Conv2D
    Input 02 Int32 scale: [(scale:1368751232, shift:43), (scale:1549354496, shift:44), (scale:1440574080, shift:43), (scale:1755535360, shift:43), (scale:1798128512, shift:43), (scale:1228813056, shift:43), (scale:1503660160, shift:43), (scale:1380415744, shift:43), (scale:1239091328, shift:43), (scale:1914088960, shift:44), (scale:1324679936, shift:43), (scale:1429442304, shift:43), (scale:1509310848, shift:43), (scale:1346612864, shift:43), (scale:1196330240, shift:43), (scale:1349743744, shift:43), (scale:1078236672, shift:43), (scale:1990238592, shift:44), (scale:1789804544, shift:44), (scale:1118199424, shift:43), (scale:1170751488, shift:43), (scale:1518451072, shift:43), (scale:1614592640, shift:43), (scale:1878492544, shift:44), (scale:1555317248, shift:43), (scale:1423194112, shift:44), (scale:1122330496, shift:43), (scale:1132077952, shift:43), (scale:1504642048, shift:43), (scale:1626018688, shift:43), (scale:1097681792, shift:43), (scale:1694527616, shift:43), (scale:1161526272, shift:43), (scale:1182997888, shift:43), (scale:1074046720, shift:43), (scale:1957752960, shift:44), (scale:1234829952, shift:43), (scale:1124294016, shift:43), (scale:1397904640, shift:43), (scale:1362811520, shift:43), (scale:1247216640, shift:43), (scale:1293062912, shift:43), (scale:1251876864, shift:43), (scale:1309452288, shift:43), (scale:1789879680, shift:43), (scale:1461709568, shift:43), (scale:2022488704, shift:44), (scale:1535216768, shift:43), (scale:1802976000, shift:44), (scale:1525744768, shift:43), (scale:1251421696, shift:43), (scale:1134427648, shift:43), (scale:1253326208, shift:43), (scale:1429854720, shift:43), (scale:1426496128, shift:43), (scale:1258340352, shift:43), (scale:2057785472, shift:44), (scale:1612954240, shift:43), (scale:1348922624, shift:43), (scale:1718574208, shift:43), (scale:1254752000, shift:43), (scale:1200187264, shift:43), (scale:1786388224, shift:44), (scale:1305224576, shift:43)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D
    Output 00 Int8 scale: [(scale:1132866816, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
13 Relu functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
    Input 00 Int8 scale: [(scale:1132866816, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
    Output 00 Int8 scale: [(scale:1132866816, shift:35)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
14 DepthwiseConv2D functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1132866816, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
    Input 01 Int8 scale: [(scale:1769574528, shift:38), (scale:1436196608, shift:39), (scale:1332834944, shift:38), (scale:1882794880, shift:39), (scale:1135717888, shift:38), (scale:1140824448, shift:37), (scale:1855011072, shift:38), (scale:1521033088, shift:38), (scale:1664806784, shift:37), (scale:1240847744, shift:38), (scale:1423400320, shift:37), (scale:1118663936, shift:38), (scale:1524085376, shift:38), (scale:1225579008, shift:38), (scale:1079566208, shift:37), (scale:1432325888, shift:38), (scale:1504566272, shift:38), (scale:1597768960, shift:38), (scale:1453890944, shift:38), (scale:1279862528, shift:37), (scale:1646897408, shift:38), (scale:1187813376, shift:38), (scale:1901231616, shift:39), (scale:1535823488, shift:38), (scale:2004544512, shift:38), (scale:1255474688, shift:38), (scale:1848587392, shift:38), (scale:1125385472, shift:38), (scale:1181533824, shift:37), (scale:1731459456, shift:38), (scale:1243043200, shift:37), (scale:1215114752, shift:38), (scale:1898641792, shift:38), (scale:1976091264, shift:38), (scale:1287099136, shift:37), (scale:1961423616, shift:38), (scale:1667680000, shift:38), (scale:1447564544, shift:38), (scale:1338771968, shift:37), (scale:1458316800, shift:38), (scale:1691923328, shift:38), (scale:1093794688, shift:37), (scale:1339741568, shift:38), (scale:1621158656, shift:38), (scale:1262748160, shift:38), (scale:1245180544, shift:38), (scale:1669311872, shift:37), (scale:1121074048, shift:37), (scale:1222070784, shift:37), (scale:1197417984, shift:38), (scale:1975216768, shift:37), (scale:1576311296, shift:38), (scale:1419405312, shift:38), (scale:1565064832, shift:37), (scale:1182171392, shift:37), (scale:1713001472, shift:37), (scale:1074690304, shift:37), (scale:1725377024, shift:38), (scale:1729641472, shift:38), (scale:1532081664, shift:38), (scale:2083963392, shift:38), (scale:1782348288, shift:38), (scale:1676304512, shift:37), (scale:1076491648, shift:37)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 3 functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource
    Input 02 Int32 scale: [(scale:1867015168, shift:43), (scale:1515280000, shift:44), (scale:1406226816, shift:43), (scale:1986469888, shift:44), (scale:1198255616, shift:43), (scale:1203643264, shift:42), (scale:1957156224, shift:43), (scale:1604787968, shift:43), (scale:1756478464, shift:42), (scale:1309174272, shift:43), (scale:1501779072, shift:42), (scale:1180262528, shift:43), (scale:1608008320, shift:43), (scale:1293064832, shift:43), (scale:1139011968, shift:42), (scale:1511196160, shift:43), (scale:1587414400, shift:43), (scale:1685749248, shift:43), (scale:1533948672, shift:43), (scale:1350337408, shift:42), (scale:1737582848, shift:43), (scale:1253219712, shift:43), (scale:2005921920, shift:44), (scale:1620392704, shift:43), (scale:2114923648, shift:43), (scale:1324606720, shift:43), (scale:1950378880, shift:43), (scale:1187354240, shift:43), (scale:1246594304, shift:42), (scale:1826801280, shift:43), (scale:1311490688, shift:42), (scale:1282024320, shift:43), (scale:2003189376, shift:43), (scale:2084903680, shift:43), (scale:1357972480, shift:42), (scale:2069428352, shift:43), (scale:1759509888, shift:43), (scale:1527273856, shift:43), (scale:1412490752, shift:42), (scale:1538618240, shift:43), (scale:1785088128, shift:43), (scale:1154023936, shift:42), (scale:1413513728, shift:43), (scale:1710426880, shift:43), (scale:1332280704, shift:43), (scale:1313745664, shift:43), (scale:1761231616, shift:42), (scale:1182805376, shift:42), (scale:1289363456, shift:42), (scale:1263353088, shift:43), (scale:2083980928, shift:42), (scale:1663110016, shift:43), (scale:1497564032, shift:43), (scale:1651244288, shift:42), (scale:1247266944, shift:42), (scale:1807326976, shift:42), (scale:1133867520, shift:42), (scale:1820384000, shift:43), (scale:1824883200, shift:43), (scale:1616444928, shift:43), (scale:1099357824, shift:42), (scale:1880492288, shift:43), (scale:1768609280, shift:42), (scale:1135768064, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource
    Output 00 Int8 scale: [(scale:1609549056, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
15 Relu functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
    Input 00 Int8 scale: [(scale:1609549056, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
    Output 00 Int8 scale: [(scale:1609549056, shift:35)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
16 Conv2D functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
    Input 00 Int8 scale: [(scale:1609549056, shift:35)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
    Input 01 Int8 scale: [(scale:1103490560, shift:37), (scale:1089363840, shift:37), (scale:1941939968, shift:38), (scale:1134922112, shift:37), (scale:1322422528, shift:37), (scale:1349955072, shift:37), (scale:2142559232, shift:38), (scale:1213446272, shift:37), (scale:1076710272, shift:37), (scale:1197436800, shift:37), (scale:2025992576, shift:38), (scale:1132253696, shift:37), (scale:1151798656, shift:37), (scale:1741811840, shift:38), (scale:1472237696, shift:37), (scale:1945139584, shift:38), (scale:2004086912, shift:38), (scale:1158968064, shift:37), (scale:1331554304, shift:37), (scale:2059459712, shift:38), (scale:1826549760, shift:38), (scale:1309050496, shift:37), (scale:1278068608, shift:37), (scale:1465158784, shift:37), (scale:1969339520, shift:38), (scale:1781134208, shift:38), (scale:1081625472, shift:37), (scale:1401820288, shift:38), (scale:1138978432, shift:37), (scale:1437350400, shift:37), (scale:1752152832, shift:38), (scale:2023836032, shift:38), (scale:1261702272, shift:37), (scale:2069750144, shift:38), (scale:1704135424, shift:38), (scale:1183723520, shift:37), (scale:1783816064, shift:37), (scale:1640697856, shift:38), (scale:2132520064, shift:38), (scale:1130913408, shift:37), (scale:2000672128, shift:38), (scale:2056496896, shift:38), (scale:1687575424, shift:38), (scale:1778191872, shift:38), (scale:1227293824, shift:37), (scale:1932541952, shift:38), (scale:2127057408, shift:38), (scale:1173656704, shift:37), (scale:1674942464, shift:38), (scale:1131779456, shift:37), (scale:1077545856, shift:37), (scale:1163039104, shift:37), (scale:1117279872, shift:37), (scale:1211461888, shift:37), (scale:1098282496, shift:37), (scale:2108566528, shift:38), (scale:1250008960, shift:37), (scale:1251099520, shift:37), (scale:1328415616, shift:37), (scale:2087376384, shift:38), (scale:1938866688, shift:38), (scale:1269583104, shift:37), (scale:1581113216, shift:38), (scale:1269816064, shift:37)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/conv2d_4/Conv2D
    Input 02 Int32 scale: [(scale:1654142720, shift:42), (scale:1632966656, shift:42), (scale:1455493120, shift:42), (scale:1701258880, shift:42), (scale:1982323712, shift:42), (scale:2023595264, shift:42), (scale:1605858176, shift:42), (scale:1818967296, shift:42), (scale:1613998848, shift:42), (scale:1794968960, shift:42), (scale:1518490880, shift:42), (scale:1697258880, shift:42), (scale:1726556928, shift:42), (scale:1305496192, shift:42), (scale:1103449088, shift:41), (scale:1457891200, shift:42), (scale:1502072576, shift:42), (scale:1737303936, shift:42), (scale:1996012416, shift:42), (scale:1543574656, shift:42), (scale:1369007616, shift:42), (scale:1962278912, shift:42), (scale:1915836800, shift:42), (scale:1098143360, shift:41), (scale:1476029184, shift:42), (scale:1334968448, shift:42), (scale:1621366656, shift:42), (scale:2101341696, shift:43), (scale:1707339392, shift:42), (scale:1077300864, shift:41), (scale:1313246720, shift:42), (scale:1516874624, shift:42), (scale:1891303552, shift:42), (scale:1551287424, shift:42), (scale:1277257472, shift:42), (scale:1774412672, shift:42), (scale:1336978560, shift:41), (scale:1229710720, shift:42), (scale:1598333824, shift:42), (scale:1695249792, shift:42), (scale:1499513088, shift:42), (scale:1541354112, shift:42), (scale:1264845696, shift:42), (scale:1332763136, shift:42), (scale:1839724928, shift:42), (scale:1448449280, shift:42), (scale:1594239488, shift:42), (scale:1759322368, shift:42), (scale:1255377280, shift:42), (scale:1696547968, shift:42), (scale:1615251328, shift:42), (scale:1743406464, shift:42), (scale:1674813056, shift:42), (scale:1815992704, shift:42), (scale:1646335744, shift:42), (scale:1580380544, shift:42), (scale:1873775104, shift:42), (scale:1875409920, shift:42), (scale:1991307520, shift:42), (scale:1564498432, shift:42), (scale:1453189632, shift:42), (scale:1903116928, shift:42), (scale:1185051776, shift:42), (scale:1903466240, shift:42)], zero_point: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D
    Output 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
17 Relu functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
    Input 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
    Output 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [-128], quantMin: [-128], quantMax: [], dimension: 0 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
18 AvgPool functional_1/average_pooling2d/AvgPool
    Input 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
    Output 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/average_pooling2d/AvgPool
19 FullyConnected functional_1/dense/BiasAdd
    Input 00 Int8 scale: [(scale:1378446720, shift:34)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 functional_1/average_pooling2d/AvgPool
    Input 01 Int8 scale: [(scale:1152529408, shift:37)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/MatMul
    Input 02 Int32 scale: [(scale:1479592576, shift:41)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/ReadVariableOp/resource
    Output 00 Int8 scale: [(scale:1242899200, shift:33)], zero_point: [14], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd
20 MaxPool functional_1/dense/BiasAdd/maxpool
    Input 00 Int8 scale: [(scale:1242899200, shift:33)], zero_point: [14], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd
    Output 00 Int8 scale: [], zero_point: [14], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/maxpool
21 Sub functional_1/dense/BiasAdd/Sub
    Input 00 Int8 scale: [(scale:1242899200, shift:33)], zero_point: [14], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd
    Input 01 Int8 scale: [], zero_point: [14], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/maxpool
    Output 00 Int8 scale: [(scale:1, shift:0)], zero_point: [127], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub
22 LUT functional_1/dense/BiasAdd/Sub/lut
    Input 00 Int8 scale: [(scale:1, shift:0)], zero_point: [127], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 exp_lut
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [127], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut
23 Asr functional_1/dense/BiasAdd/Sub/lut/Asr
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 right_shift12
    Output 00 Int32 scale: [], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr
24 ReduceSum functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr
    Output 00 Int32 scale: [], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
25 CLZ functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
    Output 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
26 Sub headroom_offset/Sub
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 headroom_offset
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
    Output 00 Int32 scale: [], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 headroom_offset/Sub
27 Sub functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ/Sub
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 one_const
    Output 00 Int32 scale: [], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ/Sub
28 SHL functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ/Sub
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [-9223372036854775808], quantMax: [9223372036854775807], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
29 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 neg_32_over_17
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul
30 Add functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
    Input 00 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 const_48_over_17
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
31 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
32 Sub F2_one/Sub
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one
    Input 01 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
33 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
34 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul
    Input 00 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 four
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul
35 Add functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
36 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
37 Sub F2_one/Sub
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one
    Input 01 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
38 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
39 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul
    Input 00 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 four
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul
40 Add functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
41 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
42 Sub F2_one/Sub
    Input 00 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one
    Input 01 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
43 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 F2_one/Sub
    Output 00 Int32 scale: [(scale:2, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
44 Mul functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul
    Input 00 Int32 scale: [(scale:2, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 four
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul
45 Add functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add
46 Mul functional_1/dense/BiasAdd/Sub/lut/Mul
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut
    Input 01 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add
    Output 00 Int32 scale: [(scale:1, shift:0)], zero_point: [0], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Mul
47 Asr Identity
    Input 00 Int32 scale: [(scale:1, shift:0)], zero_point: [], quantMin: [], quantMax: [], dimension: 0 functional_1/dense/BiasAdd/Sub/lut/Mul
    Input 01 Int32 scale: [], zero_point: [], quantMin: [], quantMax: [], dimension: 0 headroom_offset/Sub
    Output 00 Int8 scale: [(scale:1073741824, shift:38)], zero_point: [-128], quantMin: [], quantMax: [], dimension: 0 Identity

Schedule: 'graph_MAX_BUFFERED'
	0: Operation Conv2D  - OFM 1, 25, 5, 64
		Kernel: size=4,10 stride=2,2, dilation=1,1 padding=[t:4,l:1,b:5,r:1,n:0,f:0]
		Time index = 0
		Operator Config = OFM Block=[1, 10, 6, 32], IFM Block=[1, 26, 14, 16], OFM UBlock=[2, 2, 8] Traversal=PartKernel, AccType=Acc32
		IFM Stripe   = [1, 49, 10, 1]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 25, 5, 64]
		Assigned Cascade = 0
		Encoded Weights = 51872 bytes
		Weight buffer = 0 bytes
		Depth slices = [0, 64]
		sub-operations: [ Relu ]
		Estimated Perf: Macs=320000 Cycles=12725
		Memory Used: 8496 bytes
	1: Operation DepthwiseConv2D  - OFM 1, 25, 5, 64
		Kernel: size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0]
		Time index = 2
		Operator Config = OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
		IFM Stripe   = [1, 25, 5, 64]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 25, 5, 64]
		Assigned Cascade = 0
		Encoded Weights = 1312 bytes
		Weight buffer = 0 bytes
		Depth slices = [0, 64]
		sub-operations: [ Relu ]
		Estimated Perf: Macs=72000 Cycles=5000
		Memory Used: 16000 bytes
	2: Operation Conv2D  - OFM 1, 25, 5, 64
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 4
		Operator Config = OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 25, 5, 64]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 25, 5, 64]
		Assigned Cascade = 0
		Encoded Weights = 4768 bytes
		Weight buffer = 0 bytes
		Depth slices = [0, 64]
		sub-operations: [ Relu ]
		Estimated Perf: Macs=512000 Cycles=2512
		Memory Used: 16000 bytes
	3: Operation DepthwiseConv2D  - OFM 1, 25, 5, 64
		Kernel: size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0]
		Time index = 6
		Operator Config = OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
		IFM Stripe   = [1, 25, 5, 64]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 25, 5, 64]
		Assigned Cascade = 0
		Encoded Weights = 1296 bytes
		Weight buffer = 0 bytes
		Depth slices = [0, 64]
		sub-operations: [ Relu ]
		Estimated Perf: Macs=72000 Cycles=5000
		Memory Used: 16000 bytes
	4: Operation Conv2D  - OFM 1, 25, 5, 64
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 8
		Operator Config = OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 25, 5, 64]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 25, 5, 64]
		Assigned Cascade = 0
		Encoded Weights = 4768 bytes
		Weight buffer = 0 bytes
		Depth slices = [0, 64]
		sub-operations: [ Relu ]
		Estimated Perf: Macs=512000 Cycles=2512
		Memory Used: 16000 bytes
	5: Operation DepthwiseConv2D  - OFM 1, 25, 5, 64
		Kernel: size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0]
		Time index = 10
		Operator Config = OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
		IFM Stripe   = [1, 25, 5, 64]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 25, 5, 64]
		Assigned Cascade = 0
		Encoded Weights = 1296 bytes
		Weight buffer = 0 bytes
		Depth slices = [0, 64]
		sub-operations: [ Relu ]
		Estimated Perf: Macs=72000 Cycles=5000
		Memory Used: 16000 bytes
	6: Operation Conv2D  - OFM 1, 25, 5, 64
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 12
		Operator Config = OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 25, 5, 64]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 25, 5, 64]
		Assigned Cascade = 0
		Encoded Weights = 4768 bytes
		Weight buffer = 0 bytes
		Depth slices = [0, 64]
		sub-operations: [ Relu ]
		Estimated Perf: Macs=512000 Cycles=2512
		Memory Used: 16000 bytes
	7: Operation DepthwiseConv2D  - OFM 1, 25, 5, 64
		Kernel: size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0]
		Time index = 14
		Operator Config = OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
		IFM Stripe   = [1, 25, 5, 64]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 25, 5, 64]
		Assigned Cascade = 0
		Encoded Weights = 1296 bytes
		Weight buffer = 0 bytes
		Depth slices = [0, 64]
		sub-operations: [ Relu ]
		Estimated Perf: Macs=72000 Cycles=5000
		Memory Used: 16000 bytes
	8: Operation Conv2D  - OFM 1, 25, 5, 64
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 16
		Operator Config = OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 25, 5, 64]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 25, 5, 64]
		Assigned Cascade = 0
		Encoded Weights = 4768 bytes
		Weight buffer = 0 bytes
		Depth slices = [0, 64]
		sub-operations: [ Relu ]
		Estimated Perf: Macs=512000 Cycles=2512
		Memory Used: 16000 bytes
	9: Operation AvgPool  - OFM 1, 1, 1, 64
		Kernel: size=5,25 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 18
		Operator Config = OFM Block=[1, 2, 64], IFM Block=[1, 8, 6, 64], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 25, 5, 64]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 1, 1, 64]
		Assigned Cascade = 0
		sub-operations: -
		Estimated Perf: Macs=8000 Cycles=2529
		Memory Used: 8064 bytes
	10: Operation FullyConnected  - OFM 1, 1, 1, 12
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 20
		Operator Config = OFM Block=[1, 1, 4, 16], IFM Block=[1, 1, 4, 64], OFM UBlock=[1, 4, 8] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 64]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 1, 1, 12]
		Assigned Cascade = 0
		Encoded Weights = 1216 bytes
		Weight buffer = 0 bytes
		Depth slices = [0, 12]
		sub-operations: -
		Estimated Perf: Macs=768 Cycles=86
		Memory Used: 80 bytes
	11: Operation MaxPool  - OFM 1, 1, 1, 1
		Kernel: size=12,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 22
		Operator Config = OFM Block=[1, 2, 16], IFM Block=[1, 2, 10, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 12, 1]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: -
		Estimated Perf: Macs=12 Cycles=69
		Memory Used: 32 bytes
	12: Operation Sub  - OFM 1, 1, 1, 12
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 24
		Operator Config = OFM Block=[1, 128, 16], IFM Block=[1, 128, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 12]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 12]
		Assigned Cascade = 0
		sub-operations: [ LUT ]
		Estimated Perf: Macs=0 Cycles=4
		Memory Used: 96 bytes
	13: Operation Asr  - OFM 1, 1, 1, 12
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 26
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 12]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 12]
		Assigned Cascade = 0
		sub-operations: -
		Estimated Perf: Macs=0 Cycles=3
		Memory Used: 112 bytes
	14: Operation ReduceSum  - OFM 1, 1, 1, 1
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 28
		Operator Config = OFM Block=[1, 4, 16], IFM Block=[1, 1, 4, 32], OFM UBlock=[1, 4, 8] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 12]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: -
		Estimated Perf: Macs=12 Cycles=167
		Memory Used: 176 bytes
	15: Operation CLZ  - OFM 1, 1, 1, 1
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 30
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 1]
		IFM2 Stripe  = []
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: -
		Estimated Perf: Macs=0 Cycles=4
		Memory Used: 192 bytes
	16: Operation Sub  - OFM 1, 1, 1, 1
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 32
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 1]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: -
		Estimated Perf: Macs=0 Cycles=4
		Memory Used: 256 bytes
	17: Operation Sub  - OFM 1, 1, 1, 1
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 34
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 1]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: [ SHL ]
		Estimated Perf: Macs=0 Cycles=4
		Memory Used: 320 bytes
	18: Operation Mul  - OFM 1, 1, 1, 1
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 36
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 1]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: [ Add ]
		Estimated Perf: Macs=0 Cycles=4
		Memory Used: 256 bytes
	19: Operation Mul  - OFM 1, 1, 1, 1
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 38
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 1]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: [ Sub Mul Mul ]
		Estimated Perf: Macs=0 Cycles=4
		Memory Used: 320 bytes
	20: Operation Add  - OFM 1, 1, 1, 1
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 40
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 1]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: -
		Estimated Perf: Macs=0 Cycles=4
		Memory Used: 320 bytes
	21: Operation Mul  - OFM 1, 1, 1, 1
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 42
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 1]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: [ Sub Mul Mul ]
		Estimated Perf: Macs=0 Cycles=4
		Memory Used: 320 bytes
	22: Operation Add  - OFM 1, 1, 1, 1
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 44
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 1]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: -
		Estimated Perf: Macs=0 Cycles=4
		Memory Used: 320 bytes
	23: Operation Mul  - OFM 1, 1, 1, 1
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 46
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 1]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: [ Sub Mul Mul ]
		Estimated Perf: Macs=0 Cycles=4
		Memory Used: 320 bytes
	24: Operation Add  - OFM 1, 1, 1, 1
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 48
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 1]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 1]
		Assigned Cascade = 0
		sub-operations: -
		Estimated Perf: Macs=0 Cycles=4
		Memory Used: 256 bytes
	25: Operation Mul  - OFM 1, 1, 1, 12
		Kernel: size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0]
		Time index = 50
		Operator Config = OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
		IFM Stripe   = [1, 1, 1, 12]
		IFM2 Stripe  = [1, 1, 1, 1]
		OFM Stripe   = [1, 1, 1, 12]
		Assigned Cascade = 0
		sub-operations: [ Asr ]
		Estimated Perf: Macs=0 Cycles=4
		Memory Used: 208 bytes
	Cascades:
################################################################################
Allocation, memory Sram, usage mask: FeatureMap|Staging
Start Time - End Time  : Start Addr -   End Addr: Tensor Size: Memory Usage : Name
         0 -          1:     0x1f40 -     0x2130:         496:         8496 : input_1
         0 -          3:        0x0 -     0x1f40:        8000:        16000 : functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1
         2 -          5:     0x1f40 -     0x3e80:        8000:        16000 : functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1
         4 -          7:        0x0 -     0x1f40:        8000:        16000 : functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1
         6 -          9:     0x1f40 -     0x3e80:        8000:        16000 : functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1
         8 -         11:        0x0 -     0x1f40:        8000:        16000 : functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1
        10 -         13:     0x1f40 -     0x3e80:        8000:        16000 : functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1
        12 -         15:        0x0 -     0x1f40:        8000:        16000 : functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1
        14 -         17:     0x1f40 -     0x3e80:        8000:        16000 : functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1
        16 -         19:        0x0 -     0x1f40:        8000:        16000 : functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1
        18 -         21:     0x1f40 -     0x1f80:          64:         8064 : functional_1/average_pooling2d/AvgPool
        20 -         25:       0x40 -       0x50:          16:           96 : functional_1/dense/BiasAdd
        22 -         25:       0x50 -       0x60:          16:           96 : functional_1/dense/BiasAdd/maxpool
        24 -         51:        0x0 -       0x40:          64:          320 : functional_1/dense/BiasAdd/Sub/lut
        26 -         29:       0x40 -       0x70:          48:          176 : functional_1/dense/BiasAdd/Sub/lut/Asr
        28 -         35:       0xc0 -      0x100:          64:          320 : functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum
        30 -         35:      0x100 -      0x140:          64:          320 : functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ
        32 -         51:       0x40 -       0x80:          64:          320 : headroom_offset/Sub
        34 -         47:       0x80 -       0xc0:          64:          320 : functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL
        36 -         41:      0x100 -      0x140:          64:          320 : functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add
        38 -         45:       0xc0 -      0x100:          64:          320 : functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add
        38 -         45:       0xc0 -      0x100:          64:          320 : functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul
        42 -         49:      0x100 -      0x140:          64:          320 : functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add
        42 -         49:      0x100 -      0x140:          64:          320 : functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul
        46 -         51:       0xc0 -      0x100:          64:          320 : functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add
        46 -         51:       0xc0 -      0x100:          64:          320 : functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul
        50 -         53:       0x80 -       0x90:          16:          208 : Identity
Allocation Peak Tensor Size: 16000 bytes == 15.625 KiB
################################################################################
Tensor Allocation for read-only NPU tensors:
Start Time - End Time  : Start Addr -   End Addr: Tensor Size: Memory Usage : Name
         0 -          1:        0x0 -     0xcaa0:       51872:        51872 : functional_1/conv2d/Conv2D
         2 -          3:     0xcaa0 -     0xcfc0:        1312:         1312 : functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource
         4 -          5:     0xcfc0 -     0xe260:        4768:         4768 : functional_1/conv2d_1/Conv2D
         6 -          7:     0xe260 -     0xe770:        1296:         1296 : functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource
         8 -          9:     0xe770 -     0xfa10:        4768:         4768 : functional_1/conv2d_2/Conv2D
        10 -         11:     0xfa10 -     0xff20:        1296:         1296 : functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource
        12 -         13:     0xff20 -    0x111c0:        4768:         4768 : functional_1/conv2d_3/Conv2D
        14 -         15:    0x111c0 -    0x116d0:        1296:         1296 : functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource
        16 -         17:    0x116d0 -    0x12970:        4768:         4768 : functional_1/conv2d_4/Conv2D
        20 -         21:    0x12970 -    0x12e30:        1216:         1216 : functional_1/dense/MatMul
        24 -         25:    0x12e30 -    0x13230:        1024:         1024 : exp_lut
        26 -         27:    0x13230 -    0x13240:          16:           16 : right_shift12
        32 -         33:    0x13240 -    0x13250:          16:           16 : headroom_offset
        34 -         35:    0x13250 -    0x13260:          16:           16 : one_const
        36 -         37:    0x13260 -    0x13270:          16:           32 : neg_32_over_17
        36 -         37:    0x13270 -    0x13280:          16:           32 : const_48_over_17
        38 -         47:    0x13280 -    0x13290:          16:           32 : F2_one
        38 -         47:    0x13290 -    0x132a0:          16:           32 : four
Allocation Peak Tensor Size: 78496 bytes == 76.65625 KiB
High level NPU operations:
0 Conv2D , subOps: Relu, size=4,10 stride=2,2, dilation=1,1 padding=[t:4,l:1,b:5,r:1,n:0,f:0] OFM Block=[1, 10, 6, 32], IFM Block=[1, 26, 14, 16], OFM UBlock=[2, 2, 8] Traversal=PartKernel, AccType=Acc32
  IFM: input_1, [1, 49, 10, 1], format: 1, Sram:FeatureMap|Staging, address: 0x1f40
  OFM: functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1, [1, 25, 5, 64], format: 2, Sram:FeatureMap|Staging, address: 0x0
  Weights: functional_1/conv2d/Conv2D, 1 ranges, buffering: 0, Sram:ReadOnly, address: 0x0, format: Fast|Sparse2_4
1 DepthwiseConv2D , subOps: Relu, size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0] OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
  IFM: functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1, [1, 25, 5, 64], format: 2, Sram:FeatureMap|Staging, address: 0x0
  OFM: functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1, [1, 25, 5, 64], format: 2, Sram:FeatureMap|Staging, address: 0x1f40
  Weights: functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource, 1 ranges, buffering: 0, Sram:ReadOnly, address: 0xcaa0, format: Default
2 Conv2D , subOps: Relu, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1, [1, 25, 5, 64], format: 2, Sram:FeatureMap|Staging, address: 0x1f40
  OFM: functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1, [1, 25, 5, 64], format: 2, Sram:FeatureMap|Staging, address: 0x0
  Weights: functional_1/conv2d_1/Conv2D, 1 ranges, buffering: 0, Sram:ReadOnly, address: 0xcfc0, format: Fast
3 DepthwiseConv2D , subOps: Relu, size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0] OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
  IFM: functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1, [1, 25, 5, 64], format: 2, Sram:FeatureMap|Staging, address: 0x0
  OFM: functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1, [1, 25, 5, 64], format: 2, Sram:FeatureMap|Staging, address: 0x1f40
  Weights: functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource, 1 ranges, buffering: 0, Sram:ReadOnly, address: 0xe260, format: Default
4 Conv2D , subOps: Relu, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1, [1, 25, 5, 64], format: 2, Sram:FeatureMap|Staging, address: 0x1f40
  OFM: functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1, [1, 25, 5, 64], format: 2, Sram:FeatureMap|Staging, address: 0x0
  Weights: functional_1/conv2d_2/Conv2D, 1 ranges, buffering: 0, Sram:ReadOnly, address: 0xe770, format: Fast
5 DepthwiseConv2D , subOps: Relu, size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0] OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
  IFM: functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1, [1, 25, 5, 64], format: 2, Sram:FeatureMap|Staging, address: 0x0
  OFM: functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1, [1, 25, 5, 64], format: 2, Sram:FeatureMap|Staging, address: 0x1f40
  Weights: functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource, 1 ranges, buffering: 0, Sram:ReadOnly, address: 0xfa10, format: Default
6 Conv2D , subOps: Relu, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1, [1, 25, 5, 64], format: 2, Sram:FeatureMap|Staging, address: 0x1f40
  OFM: functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1, [1, 25, 5, 64], format: 2, Sram:FeatureMap|Staging, address: 0x0
  Weights: functional_1/conv2d_3/Conv2D, 1 ranges, buffering: 0, Sram:ReadOnly, address: 0xff20, format: Fast
7 DepthwiseConv2D , subOps: Relu, size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0] OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
  IFM: functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1, [1, 25, 5, 64], format: 2, Sram:FeatureMap|Staging, address: 0x0
  OFM: functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1, [1, 25, 5, 64], format: 2, Sram:FeatureMap|Staging, address: 0x1f40
  Weights: functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource, 1 ranges, buffering: 0, Sram:ReadOnly, address: 0x111c0, format: Default
8 Conv2D , subOps: Relu, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1, [1, 25, 5, 64], format: 2, Sram:FeatureMap|Staging, address: 0x1f40
  OFM: functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1, [1, 25, 5, 64], format: 2, Sram:FeatureMap|Staging, address: 0x0
  Weights: functional_1/conv2d_4/Conv2D, 1 ranges, buffering: 0, Sram:ReadOnly, address: 0x116d0, format: Fast
9 AvgPool , subOps: -, size=5,25 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 2, 64], IFM Block=[1, 8, 6, 64], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1, [1, 25, 5, 64], format: 2, Sram:FeatureMap|Staging, address: 0x0
  OFM: functional_1/average_pooling2d/AvgPool, [1, 1, 1, 64], format: 2, Sram:FeatureMap|Staging, address: 0x1f40
10 FullyConnected , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 1, 4, 16], IFM Block=[1, 1, 4, 64], OFM UBlock=[1, 4, 8] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/average_pooling2d/AvgPool, [1, 1, 1, 64], format: 2, Sram:FeatureMap|Staging, address: 0x1f40
  OFM: functional_1/dense/BiasAdd, [1, 1, 1, 12], format: 1, Sram:FeatureMap|Staging, address: 0x40
  Weights: functional_1/dense/MatMul, 1 ranges, buffering: 0, Sram:ReadOnly, address: 0x12970, format: Fast
11 MaxPool , subOps: -, size=12,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 2, 16], IFM Block=[1, 2, 10, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd, [1, 1, 12, 1], format: 1, Sram:FeatureMap|Staging, address: 0x40
  OFM: functional_1/dense/BiasAdd/maxpool, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0x50
12 Sub , subOps: LUT, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 128, 16], IFM Block=[1, 128, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd, [1, 1, 1, 12], format: 1, Sram:FeatureMap|Staging, address: 0x40
  IFM2: functional_1/dense/BiasAdd/maxpool, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0x50
  OFM: functional_1/dense/BiasAdd/Sub/lut, [1, 1, 1, 12], format: 2, Sram:FeatureMap|Staging, address: 0x0
13 Asr , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut, [1, 1, 1, 12], format: 2, Sram:FeatureMap|Staging, address: 0x0
  IFM2: right_shift12, [1, 1, 1, 1], format: 1, Sram:ReadOnly, address: 0x13230
  OFM: functional_1/dense/BiasAdd/Sub/lut/Asr, [1, 1, 1, 12], format: 1, Sram:FeatureMap|Staging, address: 0x40
14 ReduceSum , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 4, 16], IFM Block=[1, 1, 4, 32], OFM UBlock=[1, 4, 8] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut/Asr, [1, 1, 1, 12], format: 1, Sram:FeatureMap|Staging, address: 0x40
  OFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0xc0
15 CLZ , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0xc0
  OFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0x100
16 Sub , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: headroom_offset, [1, 1, 1, 1], format: 1, Sram:ReadOnly, address: 0x13240
  IFM2: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0x100
  OFM: headroom_offset/Sub, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0x40
17 Sub , subOps: SHL, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0x100
  IFM2: one_const, [1, 1, 1, 1], format: 1, Sram:ReadOnly, address: 0x13250
  OFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ/Sub, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0x-1
18 Mul , subOps: Add, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0x80
  IFM2: neg_32_over_17, [1, 1, 1, 1], format: 1, Sram:ReadOnly, address: 0x13260
  OFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0x-1
19 Mul , subOps: Sub Mul Mul, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0x100
  IFM2: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0x80
  OFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0x-1
20 Add , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0x100
  IFM2: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0xc0
  OFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0xc0
21 Mul , subOps: Sub Mul Mul, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0xc0
  IFM2: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0x80
  OFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0x-1
22 Add , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0xc0
  IFM2: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0x100
  OFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0x100
23 Mul , subOps: Sub Mul Mul, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0x100
  IFM2: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0x80
  OFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0x-1
24 Add , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0x100
  IFM2: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0xc0
  OFM: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0xc0
25 Mul , subOps: Asr, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
  IFM: functional_1/dense/BiasAdd/Sub/lut, [1, 1, 1, 12], format: 2, Sram:FeatureMap|Staging, address: 0x0
  IFM2: functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add, [1, 1, 1, 1], format: 2, Sram:FeatureMap|Staging, address: 0xc0
  OFM: functional_1/dense/BiasAdd/Sub/lut/Mul, [1, 1, 1, 12], format: 2, Sram:FeatureMap|Staging, address: 0x-1
High level command stream:
0 Conv2D OFM area [0, 0, 0, 0 - 1, 25, 5, 64], IFM [0, 0, 0, 0 - 1, 49, 10, 1], padding: [top:4,left:1,bottom:5,right:1]
1 DepthwiseConv2D OFM area [0, 0, 0, 0 - 1, 25, 5, 64], IFM [0, 0, 0, 0 - 1, 25, 5, 64], padding: [top:1,left:1,bottom:1,right:1]
2 Conv2D OFM area [0, 0, 0, 0 - 1, 25, 5, 64], IFM [0, 0, 0, 0 - 1, 25, 5, 64]
3 DepthwiseConv2D OFM area [0, 0, 0, 0 - 1, 25, 5, 64], IFM [0, 0, 0, 0 - 1, 25, 5, 64], padding: [top:1,left:1,bottom:1,right:1]
4 Conv2D OFM area [0, 0, 0, 0 - 1, 25, 5, 64], IFM [0, 0, 0, 0 - 1, 25, 5, 64]
5 DepthwiseConv2D OFM area [0, 0, 0, 0 - 1, 25, 5, 64], IFM [0, 0, 0, 0 - 1, 25, 5, 64], padding: [top:1,left:1,bottom:1,right:1]
6 Conv2D OFM area [0, 0, 0, 0 - 1, 25, 5, 64], IFM [0, 0, 0, 0 - 1, 25, 5, 64]
7 DepthwiseConv2D OFM area [0, 0, 0, 0 - 1, 25, 5, 64], IFM [0, 0, 0, 0 - 1, 25, 5, 64], padding: [top:1,left:1,bottom:1,right:1]
8 Conv2D OFM area [0, 0, 0, 0 - 1, 25, 5, 64], IFM [0, 0, 0, 0 - 1, 25, 5, 64]
9 AvgPool OFM area [0, 0, 0, 0 - 1, 1, 1, 64], IFM [0, 0, 0, 0 - 1, 25, 5, 64]
10 FullyConnected OFM area [0, 0, 0, 0 - 1, 1, 1, 12], IFM [0, 0, 0, 0 - 1, 1, 1, 64]
11 MaxPool OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 12, 1]
12 Sub OFM area [0, 0, 0, 0 - 1, 1, 1, 12], IFM [0, 0, 0, 0 - 1, 1, 1, 12], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
13 Asr OFM area [0, 0, 0, 0 - 1, 1, 1, 12], IFM [0, 0, 0, 0 - 1, 1, 1, 12], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
14 ReduceSum OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 1, 12]
15 CLZ OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 1, 1]
16 Sub OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 1, 1], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
17 Sub OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 1, 1], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
18 Mul OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 1, 1], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
19 Mul OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 1, 1], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
20 Add OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 1, 1], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
21 Mul OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 1, 1], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
22 Add OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 1, 1], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
23 Mul OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 1, 1], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
24 Add OFM area [0, 0, 0, 0 - 1, 1, 1, 1], IFM [0, 0, 0, 0 - 1, 1, 1, 1], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
25 Mul OFM area [0, 0, 0, 0 - 1, 1, 1, 12], IFM [0, 0, 0, 0 - 1, 1, 1, 12], IFM2 [0, 0, 0, 0 - 1, 1, 1, 1]
Register command stream: 1212 words
  Offset: Payload Param Code - Command                        Param, Fields
// Conv2D , subOps: Relu, size=4,10 stride=2,2, dilation=1,1 padding=[t:4,l:1,b:5,r:1,n:0,f:0] OFM Block=[1, 10, 6, 32], IFM Block=[1, 26, 14, 16], OFM UBlock=[2, 2, 8] Traversal=PartKernel, AccType=Acc32
0x000000: 51088c32 0025 4024 - NPU_SET_OFM_SCALE                 37, shift = 37, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1359514674
0x000008:          0001 0105 - NPU_SET_IFM_PRECISION              1, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B8, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x00000c:          0001 010f - NPU_SET_IFM_REGION                 1, region = 1
0x000010: 00001f40 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x1f40
0x000018: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x000020: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x000028: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x000030:          0030 010b - NPU_SET_IFM_HEIGHT0_M1            48, height_m1 = 48
0x000034:          0030 010c - NPU_SET_IFM_HEIGHT1_M1            48, height_m1 = 48
0x000038:          0009 010a - NPU_SET_IFM_WIDTH0_M1              9, width_m1 = 9
0x00003c:          0000 0104 - NPU_SET_IFM_DEPTH_M1               0, depth_m1 = 0
0x000040: 0000000a 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0xa
0x000048: 00000001 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x1
0x000050: 00000001 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x1
0x000058:          0053 0109 - NPU_SET_IFM_ZERO_POINT            83, zero_point = 83
0x00005c:          0000 0107 - NPU_SET_IFM_UPSCALE                0, mode = IFM_UPSCALE_MODE_NONE
0x000060:          0004 0100 - NPU_SET_IFM_PAD_TOP                4, pad = 4
0x000064:          0001 0101 - NPU_SET_IFM_PAD_LEFT               1, pad = 1
0x000068:          0005 0103 - NPU_SET_IFM_PAD_BOTTOM             5, pad = 5
0x00006c:          0001 0102 - NPU_SET_IFM_PAD_RIGHT              1, pad = 1
0x000070:          0041 0114 - NPU_SET_OFM_PRECISION             65, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B8, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_PER_CHANNEL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000074:          0001 011f - NPU_SET_OFM_REGION                 1, region = 1
0x000078: 00000000 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x0
0x000080: 00000000 0000 4011 - NPU_SET_OFM_BASE1                  0, addr = 0x0
0x000088: 00000000 0000 4012 - NPU_SET_OFM_BASE2                  0, addr = 0x0
0x000090: 00000000 0000 4013 - NPU_SET_OFM_BASE3                  0, addr = 0x0
0x000098:          0018 0112 - NPU_SET_OFM_HEIGHT_M1             24, height_m1 = 24
0x00009c:          0004 0111 - NPU_SET_OFM_WIDTH_M1               4, width_m1 = 4
0x0000a0:          003f 0113 - NPU_SET_OFM_DEPTH_M1              63, depth_m1 = 63
0x0000a4:          0018 011b - NPU_SET_OFM_HEIGHT0_M1            24, height_m1 = 24
0x0000a8:          0018 011c - NPU_SET_OFM_HEIGHT1_M1            24, height_m1 = 24
0x0000ac:          0004 011a - NPU_SET_OFM_WIDTH0_M1              4, width_m1 = 4
0x0000b0: 00000140 0000 4015 - NPU_SET_OFM_STRIDE_Y               0, addr = 0x140
0x0000b8: 00000010 0000 4014 - NPU_SET_OFM_STRIDE_X               0, addr = 0x10
0x0000c0: 00000050 0000 4016 - NPU_SET_OFM_STRIDE_C               0, addr = 0x50
0x0000c8:          ff80 0118 - NPU_SET_OFM_ZERO_POINT         65408, zero_point = 65408
0x0000cc:          0009 0121 - NPU_SET_KERNEL_HEIGHT_M1           9, height_m1 = 9
0x0000d0:          0003 0120 - NPU_SET_KERNEL_WIDTH_M1            3, width_m1 = 3
0x0000d4:          0007 0122 - NPU_SET_KERNEL_STRIDE              7, stride_x_lsb = 1, stride_y_lsb = 1, weight_order = WEIGHT_ORDER_PART_KERNEL_FIRST, dilation_x = KERNEL_DILATION_NONE, dilation_y = KERNEL_DILATION_NONE, decomposition = KERNEL_DECOMPOSITION_D8X8, stride_x_msb = 0, stride_y_msb = 0
0x0000d8:          0011 012e - NPU_SET_WEIGHT_FORMAT             17, weight_format = WEIGHT_FORMAT_FWD, weight_sparsity = WEIGHT_SPARSITY_SPARSE_2_4
0x0000dc:          0000 0128 - NPU_SET_WEIGHT_REGION              0, region = 0
0x0000e0: 00000280 0000 4020 - NPU_SET_WEIGHT_BASE                0, addr = 0x280
0x0000e8: 0000c820 0000 4021 - NPU_SET_WEIGHT_LENGTH              0, length = 51232
0x0000f0:          0000 0129 - NPU_SET_SCALE_REGION               0, region = 0
0x0000f4: 00000000 0000 4022 - NPU_SET_SCALE_BASE                 0, addr = 0x0
0x0000fc: 00000280 0000 4023 - NPU_SET_SCALE_LENGTH               0, length = 640
0x000104:          0000 0125 - NPU_SET_ACTIVATION                 0, activation_function = ACTIVATION_FUNCTION_LUT_NONE, table = 0, activation_clip_range = ACTIVATION_CLIP_RANGE_B16
0x000108:          ff80 0126 - NPU_SET_ACTIVATION_MIN         65408, clip_boundary = 65408
0x00010c:          007f 0127 - NPU_SET_ACTIVATION_MAX           127, clip_boundary = 127
0x000110:          0009 0116 - NPU_SET_OFM_BLK_HEIGHT_M1          9, height_m1 = 9
0x000114:          0005 0115 - NPU_SET_OFM_BLK_WIDTH_M1           5, width_m1 = 5
0x000118:          001f 0117 - NPU_SET_OFM_BLK_DEPTH_M1          31, depth_m1 = 31
0x00011c:          0300 0124 - NPU_SET_ACC_FORMAT               768, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U2X2
0x000120:          0000 012f - NPU_SET_BLOCKDEP                   0, blockdep = 0
0x000124:          0000 0002 - NPU_OP_CONV                        0, weights_ifm2 = 0
// DepthwiseConv2D , subOps: Relu, size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0] OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
0x000128: 42983810 0025 4024 - NPU_SET_OFM_SCALE                 37, shift = 37, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1117272080
0x000130:          0041 0105 - NPU_SET_IFM_PRECISION             65, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B8, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000134: 00000000 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x0
0x00013c:          0018 010b - NPU_SET_IFM_HEIGHT0_M1            24, height_m1 = 24
0x000140:          0018 010c - NPU_SET_IFM_HEIGHT1_M1            24, height_m1 = 24
0x000144:          0004 010a - NPU_SET_IFM_WIDTH0_M1              4, width_m1 = 4
0x000148:          003f 0104 - NPU_SET_IFM_DEPTH_M1              63, depth_m1 = 63
0x00014c: 00000140 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x140
0x000154: 00000010 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x10
0x00015c: 00000050 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x50
0x000164:          ff80 0109 - NPU_SET_IFM_ZERO_POINT         65408, zero_point = 65408
0x000168:          0001 0100 - NPU_SET_IFM_PAD_TOP                1, pad = 1
0x00016c:          0001 0103 - NPU_SET_IFM_PAD_BOTTOM             1, pad = 1
0x000170: 00001f40 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x1f40
0x000178:          0002 0121 - NPU_SET_KERNEL_HEIGHT_M1           2, height_m1 = 2
0x00017c:          0002 0120 - NPU_SET_KERNEL_WIDTH_M1            2, width_m1 = 2
0x000180:          0000 0122 - NPU_SET_KERNEL_STRIDE              0, stride_x_lsb = 0, stride_y_lsb = 0, weight_order = WEIGHT_ORDER_DEPTH_FIRST, dilation_x = KERNEL_DILATION_NONE, dilation_y = KERNEL_DILATION_NONE, decomposition = KERNEL_DECOMPOSITION_D8X8, stride_x_msb = 0, stride_y_msb = 0
0x000184:          0000 012e - NPU_SET_WEIGHT_FORMAT              0, weight_format = WEIGHT_FORMAT_SWD, weight_sparsity = WEIGHT_SPARSITY_NONE
0x000188: 0000cd20 0000 4020 - NPU_SET_WEIGHT_BASE                0, addr = 0xcd20
0x000190: 000002a0 0000 4021 - NPU_SET_WEIGHT_LENGTH              0, length = 672
0x000198: 0000caa0 0000 4022 - NPU_SET_SCALE_BASE                 0, addr = 0xcaa0
0x0001a0:          0018 0116 - NPU_SET_OFM_BLK_HEIGHT_M1         24, height_m1 = 24
0x0001a4:          000f 0117 - NPU_SET_OFM_BLK_DEPTH_M1          15, depth_m1 = 15
0x0001a8:          0100 0124 - NPU_SET_ACC_FORMAT               256, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U1X2
0x0001ac:          0001 012f - NPU_SET_BLOCKDEP                   1, blockdep = 1
0x0001b0:          0000 0003 - NPU_OP_DEPTHWISE                   0
// Conv2D , subOps: Relu, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
0x0001b4: 687cd140 0027 4024 - NPU_SET_OFM_SCALE                 39, shift = 39, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1753010496
0x0001bc: 00001f40 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x1f40
0x0001c4:          0000 0100 - NPU_SET_IFM_PAD_TOP                0, pad = 0
0x0001c8:          0000 0101 - NPU_SET_IFM_PAD_LEFT               0, pad = 0
0x0001cc:          0000 0103 - NPU_SET_IFM_PAD_BOTTOM             0, pad = 0
0x0001d0:          0000 0102 - NPU_SET_IFM_PAD_RIGHT              0, pad = 0
0x0001d4: 00000000 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x0
0x0001dc:          0000 0121 - NPU_SET_KERNEL_HEIGHT_M1           0, height_m1 = 0
0x0001e0:          0000 0120 - NPU_SET_KERNEL_WIDTH_M1            0, width_m1 = 0
0x0001e4:          0001 012e - NPU_SET_WEIGHT_FORMAT              1, weight_format = WEIGHT_FORMAT_FWD, weight_sparsity = WEIGHT_SPARSITY_NONE
0x0001e8: 0000d240 0000 4020 - NPU_SET_WEIGHT_BASE                0, addr = 0xd240
0x0001f0: 00001020 0000 4021 - NPU_SET_WEIGHT_LENGTH              0, length = 4128
0x0001f8: 0000cfc0 0000 4022 - NPU_SET_SCALE_BASE                 0, addr = 0xcfc0
0x000200:          000f 0116 - NPU_SET_OFM_BLK_HEIGHT_M1         15, height_m1 = 15
0x000204:          0003 0115 - NPU_SET_OFM_BLK_WIDTH_M1           3, width_m1 = 3
0x000208:          001f 0117 - NPU_SET_OFM_BLK_DEPTH_M1          31, depth_m1 = 31
0x00020c:          0300 0124 - NPU_SET_ACC_FORMAT               768, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U2X2
0x000210:          0000 012f - NPU_SET_BLOCKDEP                   0, blockdep = 0
0x000214:          0000 0002 - NPU_OP_CONV                        0, weights_ifm2 = 0
// DepthwiseConv2D , subOps: Relu, size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0] OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
0x000218: 662b9af8 0026 4024 - NPU_SET_OFM_SCALE                 38, shift = 38, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1714133752
0x000220: 00000000 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x0
0x000228:          0001 0100 - NPU_SET_IFM_PAD_TOP                1, pad = 1
0x00022c:          0001 0101 - NPU_SET_IFM_PAD_LEFT               1, pad = 1
0x000230:          0001 0103 - NPU_SET_IFM_PAD_BOTTOM             1, pad = 1
0x000234:          0001 0102 - NPU_SET_IFM_PAD_RIGHT              1, pad = 1
0x000238: 00001f40 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x1f40
0x000240:          0002 0121 - NPU_SET_KERNEL_HEIGHT_M1           2, height_m1 = 2
0x000244:          0002 0120 - NPU_SET_KERNEL_WIDTH_M1            2, width_m1 = 2
0x000248:          0000 012e - NPU_SET_WEIGHT_FORMAT              0, weight_format = WEIGHT_FORMAT_SWD, weight_sparsity = WEIGHT_SPARSITY_NONE
0x00024c: 0000e4e0 0000 4020 - NPU_SET_WEIGHT_BASE                0, addr = 0xe4e0
0x000254: 00000290 0000 4021 - NPU_SET_WEIGHT_LENGTH              0, length = 656
0x00025c: 0000e260 0000 4022 - NPU_SET_SCALE_BASE                 0, addr = 0xe260
0x000264:          0018 0116 - NPU_SET_OFM_BLK_HEIGHT_M1         24, height_m1 = 24
0x000268:          0005 0115 - NPU_SET_OFM_BLK_WIDTH_M1           5, width_m1 = 5
0x00026c:          000f 0117 - NPU_SET_OFM_BLK_DEPTH_M1          15, depth_m1 = 15
0x000270:          0100 0124 - NPU_SET_ACC_FORMAT               256, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U1X2
0x000274:          0001 012f - NPU_SET_BLOCKDEP                   1, blockdep = 1
0x000278:          0000 0003 - NPU_OP_DEPTHWISE                   0
// Conv2D , subOps: Relu, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
0x00027c: 509db936 0026 4024 - NPU_SET_OFM_SCALE                 38, shift = 38, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1352513846
0x000284: 00001f40 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x1f40
0x00028c:          0000 0100 - NPU_SET_IFM_PAD_TOP                0, pad = 0
0x000290:          0000 0101 - NPU_SET_IFM_PAD_LEFT               0, pad = 0
0x000294:          0000 0103 - NPU_SET_IFM_PAD_BOTTOM             0, pad = 0
0x000298:          0000 0102 - NPU_SET_IFM_PAD_RIGHT              0, pad = 0
0x00029c: 00000000 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x0
0x0002a4:          0000 0121 - NPU_SET_KERNEL_HEIGHT_M1           0, height_m1 = 0
0x0002a8:          0000 0120 - NPU_SET_KERNEL_WIDTH_M1            0, width_m1 = 0
0x0002ac:          0001 012e - NPU_SET_WEIGHT_FORMAT              1, weight_format = WEIGHT_FORMAT_FWD, weight_sparsity = WEIGHT_SPARSITY_NONE
0x0002b0: 0000e9f0 0000 4020 - NPU_SET_WEIGHT_BASE                0, addr = 0xe9f0
0x0002b8: 00001020 0000 4021 - NPU_SET_WEIGHT_LENGTH              0, length = 4128
0x0002c0: 0000e770 0000 4022 - NPU_SET_SCALE_BASE                 0, addr = 0xe770
0x0002c8:          000f 0116 - NPU_SET_OFM_BLK_HEIGHT_M1         15, height_m1 = 15
0x0002cc:          0003 0115 - NPU_SET_OFM_BLK_WIDTH_M1           3, width_m1 = 3
0x0002d0:          001f 0117 - NPU_SET_OFM_BLK_DEPTH_M1          31, depth_m1 = 31
0x0002d4:          0300 0124 - NPU_SET_ACC_FORMAT               768, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U2X2
0x0002d8:          0000 012f - NPU_SET_BLOCKDEP                   0, blockdep = 0
0x0002dc:          0000 0002 - NPU_OP_CONV                        0, weights_ifm2 = 0
// DepthwiseConv2D , subOps: Relu, size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0] OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
0x0002e0: 4616316a 0025 4024 - NPU_SET_OFM_SCALE                 37, shift = 37, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1175859562
0x0002e8: 00000000 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x0
0x0002f0:          0001 0100 - NPU_SET_IFM_PAD_TOP                1, pad = 1
0x0002f4:          0001 0101 - NPU_SET_IFM_PAD_LEFT               1, pad = 1
0x0002f8:          0001 0103 - NPU_SET_IFM_PAD_BOTTOM             1, pad = 1
0x0002fc:          0001 0102 - NPU_SET_IFM_PAD_RIGHT              1, pad = 1
0x000300: 00001f40 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x1f40
0x000308:          0002 0121 - NPU_SET_KERNEL_HEIGHT_M1           2, height_m1 = 2
0x00030c:          0002 0120 - NPU_SET_KERNEL_WIDTH_M1            2, width_m1 = 2
0x000310:          0000 012e - NPU_SET_WEIGHT_FORMAT              0, weight_format = WEIGHT_FORMAT_SWD, weight_sparsity = WEIGHT_SPARSITY_NONE
0x000314: 0000fc90 0000 4020 - NPU_SET_WEIGHT_BASE                0, addr = 0xfc90
0x00031c: 00000290 0000 4021 - NPU_SET_WEIGHT_LENGTH              0, length = 656
0x000324: 0000fa10 0000 4022 - NPU_SET_SCALE_BASE                 0, addr = 0xfa10
0x00032c:          0018 0116 - NPU_SET_OFM_BLK_HEIGHT_M1         24, height_m1 = 24
0x000330:          0005 0115 - NPU_SET_OFM_BLK_WIDTH_M1           5, width_m1 = 5
0x000334:          000f 0117 - NPU_SET_OFM_BLK_DEPTH_M1          15, depth_m1 = 15
0x000338:          0100 0124 - NPU_SET_ACC_FORMAT               256, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U1X2
0x00033c:          0001 012f - NPU_SET_BLOCKDEP                   1, blockdep = 1
0x000340:          0000 0003 - NPU_OP_DEPTHWISE                   0
// Conv2D , subOps: Relu, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
0x000344: 4d5375cd 0026 4024 - NPU_SET_OFM_SCALE                 38, shift = 38, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1297315277
0x00034c: 00001f40 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x1f40
0x000354:          0000 0100 - NPU_SET_IFM_PAD_TOP                0, pad = 0
0x000358:          0000 0101 - NPU_SET_IFM_PAD_LEFT               0, pad = 0
0x00035c:          0000 0103 - NPU_SET_IFM_PAD_BOTTOM             0, pad = 0
0x000360:          0000 0102 - NPU_SET_IFM_PAD_RIGHT              0, pad = 0
0x000364: 00000000 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x0
0x00036c:          0000 0121 - NPU_SET_KERNEL_HEIGHT_M1           0, height_m1 = 0
0x000370:          0000 0120 - NPU_SET_KERNEL_WIDTH_M1            0, width_m1 = 0
0x000374:          0001 012e - NPU_SET_WEIGHT_FORMAT              1, weight_format = WEIGHT_FORMAT_FWD, weight_sparsity = WEIGHT_SPARSITY_NONE
0x000378: 000101a0 0000 4020 - NPU_SET_WEIGHT_BASE                0, addr = 0x101a0
0x000380: 00001020 0000 4021 - NPU_SET_WEIGHT_LENGTH              0, length = 4128
0x000388: 0000ff20 0000 4022 - NPU_SET_SCALE_BASE                 0, addr = 0xff20
0x000390:          000f 0116 - NPU_SET_OFM_BLK_HEIGHT_M1         15, height_m1 = 15
0x000394:          0003 0115 - NPU_SET_OFM_BLK_WIDTH_M1           3, width_m1 = 3
0x000398:          001f 0117 - NPU_SET_OFM_BLK_DEPTH_M1          31, depth_m1 = 31
0x00039c:          0300 0124 - NPU_SET_ACC_FORMAT               768, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U2X2
0x0003a0:          0000 012f - NPU_SET_BLOCKDEP                   0, blockdep = 0
0x0003a4:          0000 0002 - NPU_OP_CONV                        0, weights_ifm2 = 0
// DepthwiseConv2D , subOps: Relu, size=3,3 stride=1,1, dilation=1,1 padding=[t:1,l:1,b:1,r:1,n:0,f:0] OFM Block=[25, 6, 16], IFM Block=[1, 28, 8, 16], OFM UBlock=[1, 2, 16] Traversal=Depthwise, AccType=Acc32
0x0003a8: 4a3ccfbc 0026 4024 - NPU_SET_OFM_SCALE                 38, shift = 38, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1245499324
0x0003b0: 00000000 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x0
0x0003b8:          0001 0100 - NPU_SET_IFM_PAD_TOP                1, pad = 1
0x0003bc:          0001 0101 - NPU_SET_IFM_PAD_LEFT               1, pad = 1
0x0003c0:          0001 0103 - NPU_SET_IFM_PAD_BOTTOM             1, pad = 1
0x0003c4:          0001 0102 - NPU_SET_IFM_PAD_RIGHT              1, pad = 1
0x0003c8: 00001f40 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x1f40
0x0003d0:          0002 0121 - NPU_SET_KERNEL_HEIGHT_M1           2, height_m1 = 2
0x0003d4:          0002 0120 - NPU_SET_KERNEL_WIDTH_M1            2, width_m1 = 2
0x0003d8:          0000 012e - NPU_SET_WEIGHT_FORMAT              0, weight_format = WEIGHT_FORMAT_SWD, weight_sparsity = WEIGHT_SPARSITY_NONE
0x0003dc: 00011440 0000 4020 - NPU_SET_WEIGHT_BASE                0, addr = 0x11440
0x0003e4: 00000290 0000 4021 - NPU_SET_WEIGHT_LENGTH              0, length = 656
0x0003ec: 000111c0 0000 4022 - NPU_SET_SCALE_BASE                 0, addr = 0x111c0
0x0003f4:          0018 0116 - NPU_SET_OFM_BLK_HEIGHT_M1         24, height_m1 = 24
0x0003f8:          0005 0115 - NPU_SET_OFM_BLK_WIDTH_M1           5, width_m1 = 5
0x0003fc:          000f 0117 - NPU_SET_OFM_BLK_DEPTH_M1          15, depth_m1 = 15
0x000400:          0100 0124 - NPU_SET_ACC_FORMAT               256, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U1X2
0x000404:          0001 012f - NPU_SET_BLOCKDEP                   1, blockdep = 1
0x000408:          0000 0003 - NPU_OP_DEPTHWISE                   0
// Conv2D , subOps: Relu, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 16, 4, 32], IFM Block=[1, 16, 4, 64], OFM UBlock=[2, 2, 8] Traversal=DepthFirst, AccType=Acc32
0x00040c: 4ccce0f6 0026 4024 - NPU_SET_OFM_SCALE                 38, shift = 38, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1288495350
0x000414: 00001f40 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x1f40
0x00041c:          0000 0100 - NPU_SET_IFM_PAD_TOP                0, pad = 0
0x000420:          0000 0101 - NPU_SET_IFM_PAD_LEFT               0, pad = 0
0x000424:          0000 0103 - NPU_SET_IFM_PAD_BOTTOM             0, pad = 0
0x000428:          0000 0102 - NPU_SET_IFM_PAD_RIGHT              0, pad = 0
0x00042c: 00000000 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x0
0x000434:          0000 0121 - NPU_SET_KERNEL_HEIGHT_M1           0, height_m1 = 0
0x000438:          0000 0120 - NPU_SET_KERNEL_WIDTH_M1            0, width_m1 = 0
0x00043c:          0001 012e - NPU_SET_WEIGHT_FORMAT              1, weight_format = WEIGHT_FORMAT_FWD, weight_sparsity = WEIGHT_SPARSITY_NONE
0x000440: 00011950 0000 4020 - NPU_SET_WEIGHT_BASE                0, addr = 0x11950
0x000448: 00001020 0000 4021 - NPU_SET_WEIGHT_LENGTH              0, length = 4128
0x000450: 000116d0 0000 4022 - NPU_SET_SCALE_BASE                 0, addr = 0x116d0
0x000458:          000f 0116 - NPU_SET_OFM_BLK_HEIGHT_M1         15, height_m1 = 15
0x00045c:          0003 0115 - NPU_SET_OFM_BLK_WIDTH_M1           3, width_m1 = 3
0x000460:          001f 0117 - NPU_SET_OFM_BLK_DEPTH_M1          31, depth_m1 = 31
0x000464:          0300 0124 - NPU_SET_ACC_FORMAT               768, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U2X2
0x000468:          0000 012f - NPU_SET_BLOCKDEP                   0, blockdep = 0
0x00046c:          0000 0002 - NPU_OP_CONV                        0, weights_ifm2 = 0
// AvgPool , subOps: -, size=5,25 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 2, 64], IFM Block=[1, 8, 6, 64], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000470: 00000000 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x0
0x000478:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x00047c:          0141 0114 - NPU_SET_OFM_PRECISION            321, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B8, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000480: 00001f40 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x1f40
0x000488:          0000 0112 - NPU_SET_OFM_HEIGHT_M1              0, height_m1 = 0
0x00048c:          0000 0111 - NPU_SET_OFM_WIDTH_M1               0, width_m1 = 0
0x000490:          0000 011b - NPU_SET_OFM_HEIGHT0_M1             0, height_m1 = 0
0x000494:          0000 011c - NPU_SET_OFM_HEIGHT1_M1             0, height_m1 = 0
0x000498:          0000 011a - NPU_SET_OFM_WIDTH0_M1              0, width_m1 = 0
0x00049c: 00000040 0000 4015 - NPU_SET_OFM_STRIDE_Y               0, addr = 0x40
0x0004a4: 00000010 0000 4016 - NPU_SET_OFM_STRIDE_C               0, addr = 0x10
0x0004ac:          0000 0118 - NPU_SET_OFM_ZERO_POINT             0, zero_point = 0
0x0004b0:          0018 0121 - NPU_SET_KERNEL_HEIGHT_M1          24, height_m1 = 24
0x0004b4:          0004 0120 - NPU_SET_KERNEL_WIDTH_M1            4, width_m1 = 4
0x0004b8: 4189374c 2025 4024 - NPU_SET_OFM_SCALE               8229, shift = 37, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_NATURAL, scale = 1099511628
0x0004c0:          0000 0116 - NPU_SET_OFM_BLK_HEIGHT_M1          0, height_m1 = 0
0x0004c4:          0001 0115 - NPU_SET_OFM_BLK_WIDTH_M1           1, width_m1 = 1
0x0004c8:          003f 0117 - NPU_SET_OFM_BLK_DEPTH_M1          63, depth_m1 = 63
0x0004cc:          0100 0124 - NPU_SET_ACC_FORMAT               256, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U1X2
0x0004d0:          0003 0005 - NPU_OP_POOL                        3, pooling_mode = POOLING_MODE_SUM
// FullyConnected , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 1, 4, 16], IFM Block=[1, 1, 4, 64], OFM UBlock=[1, 4, 8] Traversal=DepthFirst, AccType=Acc32
0x0004d4: 4c301c95 0026 4024 - NPU_SET_OFM_SCALE                 38, shift = 38, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1278221461
0x0004dc: 00001f40 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x1f40
0x0004e4:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x0004e8:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x0004ec:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x0004f0: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x0004f8: 00000010 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x10
0x000500:          ff80 0109 - NPU_SET_IFM_ZERO_POINT         65408, zero_point = 65408
0x000504:          0001 0114 - NPU_SET_OFM_PRECISION              1, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B8, activation_format = ACTIVATION_FORMAT_NHWC, scale_mode = OFM_SCALE_MODE_PER_CHANNEL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000508: 00000040 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x40
0x000510:          000b 0113 - NPU_SET_OFM_DEPTH_M1              11, depth_m1 = 11
0x000514: 0000000c 0000 4015 - NPU_SET_OFM_STRIDE_Y               0, addr = 0xc
0x00051c: 0000000c 0000 4014 - NPU_SET_OFM_STRIDE_X               0, addr = 0xc
0x000524: 00000001 0000 4016 - NPU_SET_OFM_STRIDE_C               0, addr = 0x1
0x00052c:          000e 0118 - NPU_SET_OFM_ZERO_POINT            14, zero_point = 14
0x000530:          0000 0121 - NPU_SET_KERNEL_HEIGHT_M1           0, height_m1 = 0
0x000534:          0000 0120 - NPU_SET_KERNEL_WIDTH_M1            0, width_m1 = 0
0x000538: 00012a10 0000 4020 - NPU_SET_WEIGHT_BASE                0, addr = 0x12a10
0x000540: 00000420 0000 4021 - NPU_SET_WEIGHT_LENGTH              0, length = 1056
0x000548: 00012970 0000 4022 - NPU_SET_SCALE_BASE                 0, addr = 0x12970
0x000550: 000000a0 0000 4023 - NPU_SET_SCALE_LENGTH               0, length = 160
0x000558:          0003 0115 - NPU_SET_OFM_BLK_WIDTH_M1           3, width_m1 = 3
0x00055c:          000f 0117 - NPU_SET_OFM_BLK_DEPTH_M1          15, depth_m1 = 15
0x000560:          0200 0124 - NPU_SET_ACC_FORMAT               512, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U1X4
0x000564:          0000 0002 - NPU_OP_CONV                        0, weights_ifm2 = 0
// MaxPool , subOps: -, size=12,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 2, 16], IFM Block=[1, 2, 10, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000568:          0001 0105 - NPU_SET_IFM_PRECISION              1, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B8, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x00056c: 00000040 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x40
0x000574:          000b 010a - NPU_SET_IFM_WIDTH0_M1             11, width_m1 = 11
0x000578:          0000 0104 - NPU_SET_IFM_DEPTH_M1               0, depth_m1 = 0
0x00057c: 0000000c 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0xc
0x000584: 00000001 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x1
0x00058c: 00000001 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x1
0x000594:          000e 0109 - NPU_SET_IFM_ZERO_POINT            14, zero_point = 14
0x000598:          0141 0114 - NPU_SET_OFM_PRECISION            321, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B8, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x00059c: 00000050 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x50
0x0005a4:          0000 0113 - NPU_SET_OFM_DEPTH_M1               0, depth_m1 = 0
0x0005a8: 00000010 0000 4015 - NPU_SET_OFM_STRIDE_Y               0, addr = 0x10
0x0005b0: 00000010 0000 4014 - NPU_SET_OFM_STRIDE_X               0, addr = 0x10
0x0005b8: 00000010 0000 4016 - NPU_SET_OFM_STRIDE_C               0, addr = 0x10
0x0005c0:          000b 0120 - NPU_SET_KERNEL_WIDTH_M1           11, width_m1 = 11
0x0005c4: 00000001 0000 4024 - NPU_SET_OFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1
0x0005cc:          0001 0115 - NPU_SET_OFM_BLK_WIDTH_M1           1, width_m1 = 1
0x0005d0:          0100 0124 - NPU_SET_ACC_FORMAT               256, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U1X2
0x0005d4:          0000 0005 - NPU_OP_POOL                        0, pooling_mode = POOLING_MODE_MAX
// DMA src: Sram:ReadOnly, address: 0x12e30, dest: lutram:LUT, address: 0x0, sizes: (N/A), length: 1024
0x0005d8:          0000 0130 - NPU_SET_DMA0_SRC_REGION            0, region = 0, region_mode = DMA_REGION_MODE_EXTERNAL, stride_mode = DMA_STRIDE_MODE_D1, idx_mode = DMA_IDX_MODE_DISABLED
0x0005dc: 00012e30 0000 4030 - NPU_SET_DMA0_SRC                   0, addr = 0x12e30
0x0005e4:          0103 0131 - NPU_SET_DMA0_DST_REGION          259, region = 3, region_mode = DMA_REGION_MODE_INTERNAL, idx_mode = DMA_IDX_MODE_DISABLED
0x0005e8: 00000000 0000 4031 - NPU_SET_DMA0_DST                   0, addr = 0x0
0x0005f0: 00000400 0000 4032 - NPU_SET_DMA0_LEN                   0, addr = 0x400
0x0005f8:          0000 0010 - NPU_OP_DMA_START                   0
// Sub , subOps: LUT, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 128, 16], IFM Block=[1, 128, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x0005fc: 00000001 0500 4025 - NPU_SET_IFM_SCALE               1280, shift = 0, dbl_rnd = 20, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000604: 00000001 0500 4026 - NPU_SET_IFM2_SCALE              1280, shift = 0, dbl_rnd = 20, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x00060c:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x000610:          000b 0104 - NPU_SET_IFM_DEPTH_M1              11, depth_m1 = 11
0x000614: 0000000c 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0xc
0x00061c:          0145 0114 - NPU_SET_OFM_PRECISION            325, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000620: 00000000 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x0
0x000628:          000b 0113 - NPU_SET_OFM_DEPTH_M1              11, depth_m1 = 11
0x00062c: 00000040 0000 4015 - NPU_SET_OFM_STRIDE_Y               0, addr = 0x40
0x000634: 00000040 0000 4014 - NPU_SET_OFM_STRIDE_X               0, addr = 0x40
0x00063c: 00000040 0000 4016 - NPU_SET_OFM_STRIDE_C               0, addr = 0x40
0x000644:          007f 0118 - NPU_SET_OFM_ZERO_POINT           127, zero_point = 127
0x000648:          0007 0125 - NPU_SET_ACTIVATION                 7, activation_function = ACTIVATION_FUNCTION_LUT_S8_S32, table = 0, activation_clip_range = ACTIVATION_CLIP_RANGE_B16
0x00064c:          0041 0185 - NPU_SET_IFM2_PRECISION            65, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B8, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000650:          0001 018f - NPU_SET_IFM2_REGION                1, region = 1
0x000654: 00000050 0000 4080 - NPU_SET_IFM2_BASE0                 0, addr = 0x50
0x00065c: 00000000 0000 4081 - NPU_SET_IFM2_BASE1                 0, addr = 0x0
0x000664: 00000000 0000 4082 - NPU_SET_IFM2_BASE2                 0, addr = 0x0
0x00066c: 00000000 0000 4083 - NPU_SET_IFM2_BASE3                 0, addr = 0x0
0x000674:          0000 018b - NPU_SET_IFM2_HEIGHT0_M1            0, height_m1 = 0
0x000678:          0000 018c - NPU_SET_IFM2_HEIGHT1_M1            0, height_m1 = 0
0x00067c:          0000 018a - NPU_SET_IFM2_WIDTH0_M1             0, width_m1 = 0
0x000680: 00000010 0000 4085 - NPU_SET_IFM2_STRIDE_Y              0, addr = 0x10
0x000688: 00000010 0000 4084 - NPU_SET_IFM2_STRIDE_X              0, addr = 0x10
0x000690: 00000010 0000 4086 - NPU_SET_IFM2_STRIDE_C              0, addr = 0x10
0x000698:          000e 0189 - NPU_SET_IFM2_ZERO_POINT           14, zero_point = 14
0x00069c:          0000 0108 - NPU_SET_IFM_BROADCAST              0, broadcast_mode = BROADCAST_MODE_NONE
0x0006a0:          0004 0180 - NPU_SET_IFM2_BROADCAST             4, broadcast_mode = BROADCAST_MODE_C
0x0006a4:          007f 0115 - NPU_SET_OFM_BLK_WIDTH_M1         127, width_m1 = 127
0x0006a8:          0000 0011 - NPU_OP_DMA_WAIT                    0, k = 0
0x0006ac:          0002 0006 - NPU_OP_ELEMENTWISE                 2, elementwise_mode = ELEMENTWISE_MODE_SUB
// Asr , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x0006b0: 00000001 0000 4025 - NPU_SET_IFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x0006b8: 00000001 0000 4026 - NPU_SET_IFM2_SCALE                 0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x0006c0: 00000001 2000 4024 - NPU_SET_OFM_SCALE               8192, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_NATURAL, scale = 1
0x0006c8:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x0006cc: 00000000 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x0
0x0006d4: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x0006dc: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x0006e4: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x0006ec:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x0006f0:          0105 0114 - NPU_SET_OFM_PRECISION            261, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x0006f4: 00000040 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x40
0x0006fc: 00000030 0000 4015 - NPU_SET_OFM_STRIDE_Y               0, addr = 0x30
0x000704: 00000030 0000 4014 - NPU_SET_OFM_STRIDE_X               0, addr = 0x30
0x00070c: 00000004 0000 4016 - NPU_SET_OFM_STRIDE_C               0, addr = 0x4
0x000714:          0000 0118 - NPU_SET_OFM_ZERO_POINT             0, zero_point = 0
0x000718:          1000 0125 - NPU_SET_ACTIVATION              4096, activation_function = ACTIVATION_FUNCTION_LUT_NONE, table = 0, activation_clip_range = ACTIVATION_CLIP_RANGE_NONE
0x00071c:          8000 0126 - NPU_SET_ACTIVATION_MIN         32768, clip_boundary = 32768
0x000720:          ffff 0127 - NPU_SET_ACTIVATION_MAX         65535, clip_boundary = 65535
0x000724:          c009 0185 - NPU_SET_IFM2_PRECISION         49161, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_NONE
0x000728: 0000000c 0000 4027 - NPU_SET_OP_SCALAR                  0, scalar = 12
0x000730:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000734:          0008 0180 - NPU_SET_IFM2_BROADCAST             8, broadcast_mode = BROADCAST_MODE_SCALAR
0x000738:          001f 0115 - NPU_SET_OFM_BLK_WIDTH_M1          31, width_m1 = 31
0x00073c:          0008 0006 - NPU_OP_ELEMENTWISE                 8, elementwise_mode = ELEMENTWISE_MODE_SHR
// ReduceSum , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 4, 16], IFM Block=[1, 1, 4, 32], OFM UBlock=[1, 4, 8] Traversal=DepthFirst, AccType=Acc32
0x000740:          0009 0105 - NPU_SET_IFM_PRECISION              9, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000744: 00000040 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x40
0x00074c: 00000030 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x30
0x000754: 00000030 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x30
0x00075c: 00000004 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x4
0x000764:          0145 0114 - NPU_SET_OFM_PRECISION            325, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000768: 000000c0 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0xc0
0x000770:          0000 0113 - NPU_SET_OFM_DEPTH_M1               0, depth_m1 = 0
0x000774: 00000040 0000 4015 - NPU_SET_OFM_STRIDE_Y               0, addr = 0x40
0x00077c: 00000040 0000 4014 - NPU_SET_OFM_STRIDE_X               0, addr = 0x40
0x000784: 00000040 0000 4016 - NPU_SET_OFM_STRIDE_C               0, addr = 0x40
0x00078c:          0000 0120 - NPU_SET_KERNEL_WIDTH_M1            0, width_m1 = 0
0x000790:          0003 0115 - NPU_SET_OFM_BLK_WIDTH_M1           3, width_m1 = 3
0x000794:          0200 0124 - NPU_SET_ACC_FORMAT               512, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U1X4
0x000798:          0002 0005 - NPU_OP_POOL                        2, pooling_mode = POOLING_MODE_REDUCE_SUM
// CLZ , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x00079c: 00000001 0000 4024 - NPU_SET_OFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1
0x0007a4:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x0007a8: 000000c0 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0xc0
0x0007b0:          0000 0104 - NPU_SET_IFM_DEPTH_M1               0, depth_m1 = 0
0x0007b4: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x0007bc: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x0007c4: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x0007cc: 00000100 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x100
0x0007d4:          0000 0180 - NPU_SET_IFM2_BROADCAST             0, broadcast_mode = BROADCAST_MODE_NONE
0x0007d8:          001f 0115 - NPU_SET_OFM_BLK_WIDTH_M1          31, width_m1 = 31
0x0007dc:          0100 0124 - NPU_SET_ACC_FORMAT               256, acc_format = ACC_FORMAT_I32, acc_input = ACC_INPUT_RESET, acc_output = ACC_OUTPUT_ENABLE, microblock = MICROBLOCK_U1X2
0x0007e0:          0007 0006 - NPU_OP_ELEMENTWISE                 7, elementwise_mode = ELEMENTWISE_MODE_CLZ
// Sub , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x0007e4: 00000001 03c0 4025 - NPU_SET_IFM_SCALE                960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x0007ec: 00000001 03c0 4026 - NPU_SET_IFM2_SCALE               960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x0007f4:          c009 0105 - NPU_SET_IFM_PRECISION          49161, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_NONE
0x0007f8: 00000023 0000 4027 - NPU_SET_OP_SCALAR                  0, scalar = 35
0x000800: 00000040 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x40
0x000808:          0049 0185 - NPU_SET_IFM2_PRECISION            73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x00080c: 00000100 0000 4080 - NPU_SET_IFM2_BASE0                 0, addr = 0x100
0x000814: 00000040 0000 4085 - NPU_SET_IFM2_STRIDE_Y              0, addr = 0x40
0x00081c: 00000040 0000 4084 - NPU_SET_IFM2_STRIDE_X              0, addr = 0x40
0x000824: 00000040 0000 4086 - NPU_SET_IFM2_STRIDE_C              0, addr = 0x40
0x00082c:          0008 0108 - NPU_SET_IFM_BROADCAST              8, broadcast_mode = BROADCAST_MODE_SCALAR
0x000830:          0002 0006 - NPU_OP_ELEMENTWISE                 2, elementwise_mode = ELEMENTWISE_MODE_SUB
// Sub , subOps: SHL, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000834:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000838:          0001 010f - NPU_SET_IFM_REGION                 1, region = 1
0x00083c: 00000100 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x100
0x000844: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x00084c: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x000854: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x00085c:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x000860:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x000864:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x000868: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x000870: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x000878: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x000880:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000884:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000888:          0000 011f - NPU_SET_OFM_REGION                 0, region = 0
0x00088c:          c009 0185 - NPU_SET_IFM2_PRECISION         49161, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_NONE
0x000890: 00000001 0000 4027 - NPU_SET_OP_SCALAR                  0, scalar = 1
0x000898:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x00089c:          0000 0108 - NPU_SET_IFM_BROADCAST              0, broadcast_mode = BROADCAST_MODE_NONE
0x0008a0:          0008 0180 - NPU_SET_IFM2_BROADCAST             8, broadcast_mode = BROADCAST_MODE_SCALAR
0x0008a4:          0002 0006 - NPU_OP_ELEMENTWISE                 2, elementwise_mode = ELEMENTWISE_MODE_SUB
// SHL , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x0008a8: 00000001 0000 4025 - NPU_SET_IFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x0008b0: 00000001 0000 4026 - NPU_SET_IFM2_SCALE                 0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x0008b8:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x0008bc:          0001 010f - NPU_SET_IFM_REGION                 1, region = 1
0x0008c0: 000000c0 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0xc0
0x0008c8: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x0008d0: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x0008d8: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x0008e0:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x0008e4:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x0008e8:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x0008ec: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x0008f4: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x0008fc: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x000904:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000908:          0145 0114 - NPU_SET_OFM_PRECISION            325, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x00090c:          0001 011f - NPU_SET_OFM_REGION                 1, region = 1
0x000910: 00000080 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x80
0x000918:          8049 0185 - NPU_SET_IFM2_PRECISION         32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x00091c:          0000 018f - NPU_SET_IFM2_REGION                0, region = 0
0x000920:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000924:          0000 0180 - NPU_SET_IFM2_BROADCAST             0, broadcast_mode = BROADCAST_MODE_NONE
0x000928:          0009 0006 - NPU_OP_ELEMENTWISE                 9, elementwise_mode = ELEMENTWISE_MODE_SHL
// Mul , subOps: Add, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x00092c: 40000000 001f 4024 - NPU_SET_OFM_SCALE                 31, shift = 31, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1073741824
0x000934:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000938:          0001 010f - NPU_SET_IFM_REGION                 1, region = 1
0x00093c: 00000080 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x80
0x000944: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x00094c: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x000954: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x00095c:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x000960:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x000964:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x000968: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x000970: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x000978: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x000980:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000984:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000988:          0000 011f - NPU_SET_OFM_REGION                 0, region = 0
0x00098c:          c009 0185 - NPU_SET_IFM2_PRECISION         49161, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_NONE
0x000990: c3c3c3c4 0000 4027 - NPU_SET_OP_SCALAR                  0, scalar = 3284386755
0x000998:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x00099c:          0008 0180 - NPU_SET_IFM2_BROADCAST             8, broadcast_mode = BROADCAST_MODE_SCALAR
0x0009a0:          0000 0006 - NPU_OP_ELEMENTWISE                 0, elementwise_mode = ELEMENTWISE_MODE_MUL
// Add , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x0009a4: 00000001 03c0 4025 - NPU_SET_IFM_SCALE                960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x0009ac: 00000001 03c0 4026 - NPU_SET_IFM2_SCALE               960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x0009b4: 00000001 0000 4024 - NPU_SET_OFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1
0x0009bc:          8049 0105 - NPU_SET_IFM_PRECISION          32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x0009c0:          0000 010f - NPU_SET_IFM_REGION                 0, region = 0
0x0009c4:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x0009c8:          0145 0114 - NPU_SET_OFM_PRECISION            325, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x0009cc:          0001 011f - NPU_SET_OFM_REGION                 1, region = 1
0x0009d0: 00000100 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x100
0x0009d8:          c009 0185 - NPU_SET_IFM2_PRECISION         49161, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_NONE
0x0009dc: 5a5a5a5a 0000 4027 - NPU_SET_OP_SCALAR                  0, scalar = 1515870810
0x0009e4:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x0009e8:          0001 0006 - NPU_OP_ELEMENTWISE                 1, elementwise_mode = ELEMENTWISE_MODE_ADD
// Mul , subOps: Sub Mul Mul, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x0009ec: 00000001 0000 4025 - NPU_SET_IFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x0009f4: 00000001 0000 4026 - NPU_SET_IFM2_SCALE                 0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x0009fc: 40000000 001f 4024 - NPU_SET_OFM_SCALE                 31, shift = 31, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1073741824
0x000a04:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000a08:          0001 010f - NPU_SET_IFM_REGION                 1, region = 1
0x000a0c: 00000100 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x100
0x000a14: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x000a1c: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x000a24: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x000a2c:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x000a30:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x000a34:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x000a38: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x000a40: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x000a48: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x000a50:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000a54:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000a58:          0000 011f - NPU_SET_OFM_REGION                 0, region = 0
0x000a5c:          0049 0185 - NPU_SET_IFM2_PRECISION            73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000a60:          0001 018f - NPU_SET_IFM2_REGION                1, region = 1
0x000a64: 00000080 0000 4080 - NPU_SET_IFM2_BASE0                 0, addr = 0x80
0x000a6c: 00000000 0000 4081 - NPU_SET_IFM2_BASE1                 0, addr = 0x0
0x000a74: 00000000 0000 4082 - NPU_SET_IFM2_BASE2                 0, addr = 0x0
0x000a7c: 00000000 0000 4083 - NPU_SET_IFM2_BASE3                 0, addr = 0x0
0x000a84:          0000 018b - NPU_SET_IFM2_HEIGHT0_M1            0, height_m1 = 0
0x000a88:          0000 018c - NPU_SET_IFM2_HEIGHT1_M1            0, height_m1 = 0
0x000a8c:          0000 018a - NPU_SET_IFM2_WIDTH0_M1             0, width_m1 = 0
0x000a90: 00000040 0000 4085 - NPU_SET_IFM2_STRIDE_Y              0, addr = 0x40
0x000a98: 00000040 0000 4084 - NPU_SET_IFM2_STRIDE_X              0, addr = 0x40
0x000aa0: 00000040 0000 4086 - NPU_SET_IFM2_STRIDE_C              0, addr = 0x40
0x000aa8:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000aac:          0000 0180 - NPU_SET_IFM2_BROADCAST             0, broadcast_mode = BROADCAST_MODE_NONE
0x000ab0:          0000 0006 - NPU_OP_ELEMENTWISE                 0, elementwise_mode = ELEMENTWISE_MODE_MUL
// Sub , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000ab4: 00000001 03c0 4025 - NPU_SET_IFM_SCALE                960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000abc: 00000001 03c0 4026 - NPU_SET_IFM2_SCALE               960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000ac4: 00000001 0000 4024 - NPU_SET_OFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1
0x000acc:          c009 0105 - NPU_SET_IFM_PRECISION          49161, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_NONE
0x000ad0: 20000000 0000 4027 - NPU_SET_OP_SCALAR                  0, scalar = 536870912
0x000ad8:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000adc:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000ae0:          0001 011f - NPU_SET_OFM_REGION                 1, region = 1
0x000ae4:          8049 0185 - NPU_SET_IFM2_PRECISION         32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000ae8:          0000 018f - NPU_SET_IFM2_REGION                0, region = 0
0x000aec:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000af0:          0008 0108 - NPU_SET_IFM_BROADCAST              8, broadcast_mode = BROADCAST_MODE_SCALAR
0x000af4:          0002 0006 - NPU_OP_ELEMENTWISE                 2, elementwise_mode = ELEMENTWISE_MODE_SUB
// Mul , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000af8: 00000001 0000 4025 - NPU_SET_IFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000b00: 00000001 0000 4026 - NPU_SET_IFM2_SCALE                 0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000b08: 40000000 001f 4024 - NPU_SET_OFM_SCALE                 31, shift = 31, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1073741824
0x000b10:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000b14:          0001 010f - NPU_SET_IFM_REGION                 1, region = 1
0x000b18: 00000100 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x100
0x000b20: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x000b28: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x000b30: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x000b38:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x000b3c:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x000b40:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x000b44: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x000b4c: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x000b54: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x000b5c:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000b60:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000b64:          0002 011f - NPU_SET_OFM_REGION                 2, region = 2
0x000b68:          8049 0185 - NPU_SET_IFM2_PRECISION         32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000b6c:          0001 018f - NPU_SET_IFM2_REGION                1, region = 1
0x000b70:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000b74:          0000 0108 - NPU_SET_IFM_BROADCAST              0, broadcast_mode = BROADCAST_MODE_NONE
0x000b78:          0000 0006 - NPU_OP_ELEMENTWISE                 0, elementwise_mode = ELEMENTWISE_MODE_MUL
// Mul , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000b7c: 00000001 0000 4024 - NPU_SET_OFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1
0x000b84:          8049 0105 - NPU_SET_IFM_PRECISION          32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000b88:          0002 010f - NPU_SET_IFM_REGION                 2, region = 2
0x000b8c:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000b90:          0145 0114 - NPU_SET_OFM_PRECISION            325, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000b94:          0001 011f - NPU_SET_OFM_REGION                 1, region = 1
0x000b98: 000000c0 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0xc0
0x000ba0:          c009 0185 - NPU_SET_IFM2_PRECISION         49161, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_NONE
0x000ba4: 00000004 0000 4027 - NPU_SET_OP_SCALAR                  0, scalar = 4
0x000bac:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000bb0:          0008 0180 - NPU_SET_IFM2_BROADCAST             8, broadcast_mode = BROADCAST_MODE_SCALAR
0x000bb4:          0000 0006 - NPU_OP_ELEMENTWISE                 0, elementwise_mode = ELEMENTWISE_MODE_MUL
// Add , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000bb8: 00000001 03c0 4025 - NPU_SET_IFM_SCALE                960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000bc0: 00000001 03c0 4026 - NPU_SET_IFM2_SCALE               960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000bc8:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000bcc:          0001 010f - NPU_SET_IFM_REGION                 1, region = 1
0x000bd0: 00000100 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x100
0x000bd8: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x000be0: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x000be8: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x000bf0:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x000bf4:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x000bf8:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x000bfc: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x000c04: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x000c0c: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x000c14:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000c18:          0145 0114 - NPU_SET_OFM_PRECISION            325, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000c1c:          0049 0185 - NPU_SET_IFM2_PRECISION            73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000c20:          0001 018f - NPU_SET_IFM2_REGION                1, region = 1
0x000c24: 000000c0 0000 4080 - NPU_SET_IFM2_BASE0                 0, addr = 0xc0
0x000c2c: 00000000 0000 4081 - NPU_SET_IFM2_BASE1                 0, addr = 0x0
0x000c34: 00000000 0000 4082 - NPU_SET_IFM2_BASE2                 0, addr = 0x0
0x000c3c: 00000000 0000 4083 - NPU_SET_IFM2_BASE3                 0, addr = 0x0
0x000c44:          0000 018b - NPU_SET_IFM2_HEIGHT0_M1            0, height_m1 = 0
0x000c48:          0000 018c - NPU_SET_IFM2_HEIGHT1_M1            0, height_m1 = 0
0x000c4c:          0000 018a - NPU_SET_IFM2_WIDTH0_M1             0, width_m1 = 0
0x000c50: 00000040 0000 4085 - NPU_SET_IFM2_STRIDE_Y              0, addr = 0x40
0x000c58: 00000040 0000 4084 - NPU_SET_IFM2_STRIDE_X              0, addr = 0x40
0x000c60: 00000040 0000 4086 - NPU_SET_IFM2_STRIDE_C              0, addr = 0x40
0x000c68:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000c6c:          0000 0180 - NPU_SET_IFM2_BROADCAST             0, broadcast_mode = BROADCAST_MODE_NONE
0x000c70:          0001 0006 - NPU_OP_ELEMENTWISE                 1, elementwise_mode = ELEMENTWISE_MODE_ADD
// Mul , subOps: Sub Mul Mul, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000c74: 00000001 0000 4025 - NPU_SET_IFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000c7c: 00000001 0000 4026 - NPU_SET_IFM2_SCALE                 0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000c84: 40000000 001f 4024 - NPU_SET_OFM_SCALE                 31, shift = 31, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1073741824
0x000c8c:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000c90:          0001 010f - NPU_SET_IFM_REGION                 1, region = 1
0x000c94: 000000c0 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0xc0
0x000c9c: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x000ca4: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x000cac: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x000cb4:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x000cb8:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x000cbc:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x000cc0: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x000cc8: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x000cd0: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x000cd8:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000cdc:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000ce0:          0000 011f - NPU_SET_OFM_REGION                 0, region = 0
0x000ce4:          0049 0185 - NPU_SET_IFM2_PRECISION            73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000ce8:          0001 018f - NPU_SET_IFM2_REGION                1, region = 1
0x000cec: 00000080 0000 4080 - NPU_SET_IFM2_BASE0                 0, addr = 0x80
0x000cf4: 00000000 0000 4081 - NPU_SET_IFM2_BASE1                 0, addr = 0x0
0x000cfc: 00000000 0000 4082 - NPU_SET_IFM2_BASE2                 0, addr = 0x0
0x000d04: 00000000 0000 4083 - NPU_SET_IFM2_BASE3                 0, addr = 0x0
0x000d0c:          0000 018b - NPU_SET_IFM2_HEIGHT0_M1            0, height_m1 = 0
0x000d10:          0000 018c - NPU_SET_IFM2_HEIGHT1_M1            0, height_m1 = 0
0x000d14:          0000 018a - NPU_SET_IFM2_WIDTH0_M1             0, width_m1 = 0
0x000d18: 00000040 0000 4085 - NPU_SET_IFM2_STRIDE_Y              0, addr = 0x40
0x000d20: 00000040 0000 4084 - NPU_SET_IFM2_STRIDE_X              0, addr = 0x40
0x000d28: 00000040 0000 4086 - NPU_SET_IFM2_STRIDE_C              0, addr = 0x40
0x000d30:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000d34:          0000 0006 - NPU_OP_ELEMENTWISE                 0, elementwise_mode = ELEMENTWISE_MODE_MUL
// Sub , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000d38: 00000001 03c0 4025 - NPU_SET_IFM_SCALE                960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000d40: 00000001 03c0 4026 - NPU_SET_IFM2_SCALE               960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000d48: 00000001 0000 4024 - NPU_SET_OFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1
0x000d50:          c009 0105 - NPU_SET_IFM_PRECISION          49161, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_NONE
0x000d54: 20000000 0000 4027 - NPU_SET_OP_SCALAR                  0, scalar = 536870912
0x000d5c:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000d60:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000d64:          0001 011f - NPU_SET_OFM_REGION                 1, region = 1
0x000d68:          8049 0185 - NPU_SET_IFM2_PRECISION         32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000d6c:          0000 018f - NPU_SET_IFM2_REGION                0, region = 0
0x000d70:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000d74:          0008 0108 - NPU_SET_IFM_BROADCAST              8, broadcast_mode = BROADCAST_MODE_SCALAR
0x000d78:          0002 0006 - NPU_OP_ELEMENTWISE                 2, elementwise_mode = ELEMENTWISE_MODE_SUB
// Mul , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000d7c: 00000001 0000 4025 - NPU_SET_IFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000d84: 00000001 0000 4026 - NPU_SET_IFM2_SCALE                 0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000d8c: 40000000 001f 4024 - NPU_SET_OFM_SCALE                 31, shift = 31, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1073741824
0x000d94:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000d98:          0001 010f - NPU_SET_IFM_REGION                 1, region = 1
0x000d9c: 000000c0 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0xc0
0x000da4: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x000dac: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x000db4: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x000dbc:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x000dc0:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x000dc4:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x000dc8: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x000dd0: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x000dd8: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x000de0:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000de4:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000de8:          0002 011f - NPU_SET_OFM_REGION                 2, region = 2
0x000dec:          8049 0185 - NPU_SET_IFM2_PRECISION         32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000df0:          0001 018f - NPU_SET_IFM2_REGION                1, region = 1
0x000df4:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000df8:          0000 0108 - NPU_SET_IFM_BROADCAST              0, broadcast_mode = BROADCAST_MODE_NONE
0x000dfc:          0000 0006 - NPU_OP_ELEMENTWISE                 0, elementwise_mode = ELEMENTWISE_MODE_MUL
// Mul , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000e00: 00000001 0000 4024 - NPU_SET_OFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1
0x000e08:          8049 0105 - NPU_SET_IFM_PRECISION          32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000e0c:          0002 010f - NPU_SET_IFM_REGION                 2, region = 2
0x000e10:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000e14:          0145 0114 - NPU_SET_OFM_PRECISION            325, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000e18:          0001 011f - NPU_SET_OFM_REGION                 1, region = 1
0x000e1c: 00000100 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x100
0x000e24:          c009 0185 - NPU_SET_IFM2_PRECISION         49161, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_NONE
0x000e28: 00000004 0000 4027 - NPU_SET_OP_SCALAR                  0, scalar = 4
0x000e30:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000e34:          0008 0180 - NPU_SET_IFM2_BROADCAST             8, broadcast_mode = BROADCAST_MODE_SCALAR
0x000e38:          0000 0006 - NPU_OP_ELEMENTWISE                 0, elementwise_mode = ELEMENTWISE_MODE_MUL
// Add , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000e3c: 00000001 03c0 4025 - NPU_SET_IFM_SCALE                960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000e44: 00000001 03c0 4026 - NPU_SET_IFM2_SCALE               960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000e4c:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000e50:          0001 010f - NPU_SET_IFM_REGION                 1, region = 1
0x000e54: 000000c0 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0xc0
0x000e5c: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x000e64: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x000e6c: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x000e74:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x000e78:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x000e7c:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x000e80: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x000e88: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x000e90: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x000e98:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000e9c:          0145 0114 - NPU_SET_OFM_PRECISION            325, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000ea0:          0049 0185 - NPU_SET_IFM2_PRECISION            73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000ea4:          0001 018f - NPU_SET_IFM2_REGION                1, region = 1
0x000ea8: 00000100 0000 4080 - NPU_SET_IFM2_BASE0                 0, addr = 0x100
0x000eb0: 00000000 0000 4081 - NPU_SET_IFM2_BASE1                 0, addr = 0x0
0x000eb8: 00000000 0000 4082 - NPU_SET_IFM2_BASE2                 0, addr = 0x0
0x000ec0: 00000000 0000 4083 - NPU_SET_IFM2_BASE3                 0, addr = 0x0
0x000ec8:          0000 018b - NPU_SET_IFM2_HEIGHT0_M1            0, height_m1 = 0
0x000ecc:          0000 018c - NPU_SET_IFM2_HEIGHT1_M1            0, height_m1 = 0
0x000ed0:          0000 018a - NPU_SET_IFM2_WIDTH0_M1             0, width_m1 = 0
0x000ed4: 00000040 0000 4085 - NPU_SET_IFM2_STRIDE_Y              0, addr = 0x40
0x000edc: 00000040 0000 4084 - NPU_SET_IFM2_STRIDE_X              0, addr = 0x40
0x000ee4: 00000040 0000 4086 - NPU_SET_IFM2_STRIDE_C              0, addr = 0x40
0x000eec:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000ef0:          0000 0180 - NPU_SET_IFM2_BROADCAST             0, broadcast_mode = BROADCAST_MODE_NONE
0x000ef4:          0001 0006 - NPU_OP_ELEMENTWISE                 1, elementwise_mode = ELEMENTWISE_MODE_ADD
// Mul , subOps: Sub Mul Mul, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000ef8: 00000001 0000 4025 - NPU_SET_IFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000f00: 00000001 0000 4026 - NPU_SET_IFM2_SCALE                 0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000f08: 40000000 001f 4024 - NPU_SET_OFM_SCALE                 31, shift = 31, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1073741824
0x000f10:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000f14:          0001 010f - NPU_SET_IFM_REGION                 1, region = 1
0x000f18: 00000100 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x100
0x000f20: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x000f28: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x000f30: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x000f38:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x000f3c:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x000f40:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x000f44: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x000f4c: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x000f54: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x000f5c:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000f60:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000f64:          0000 011f - NPU_SET_OFM_REGION                 0, region = 0
0x000f68:          0049 0185 - NPU_SET_IFM2_PRECISION            73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x000f6c:          0001 018f - NPU_SET_IFM2_REGION                1, region = 1
0x000f70: 00000080 0000 4080 - NPU_SET_IFM2_BASE0                 0, addr = 0x80
0x000f78: 00000000 0000 4081 - NPU_SET_IFM2_BASE1                 0, addr = 0x0
0x000f80: 00000000 0000 4082 - NPU_SET_IFM2_BASE2                 0, addr = 0x0
0x000f88: 00000000 0000 4083 - NPU_SET_IFM2_BASE3                 0, addr = 0x0
0x000f90:          0000 018b - NPU_SET_IFM2_HEIGHT0_M1            0, height_m1 = 0
0x000f94:          0000 018c - NPU_SET_IFM2_HEIGHT1_M1            0, height_m1 = 0
0x000f98:          0000 018a - NPU_SET_IFM2_WIDTH0_M1             0, width_m1 = 0
0x000f9c: 00000040 0000 4085 - NPU_SET_IFM2_STRIDE_Y              0, addr = 0x40
0x000fa4: 00000040 0000 4084 - NPU_SET_IFM2_STRIDE_X              0, addr = 0x40
0x000fac: 00000040 0000 4086 - NPU_SET_IFM2_STRIDE_C              0, addr = 0x40
0x000fb4:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000fb8:          0000 0006 - NPU_OP_ELEMENTWISE                 0, elementwise_mode = ELEMENTWISE_MODE_MUL
// Sub , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x000fbc: 00000001 03c0 4025 - NPU_SET_IFM_SCALE                960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000fc4: 00000001 03c0 4026 - NPU_SET_IFM2_SCALE               960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x000fcc: 00000001 0000 4024 - NPU_SET_OFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1
0x000fd4:          c009 0105 - NPU_SET_IFM_PRECISION          49161, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_NONE
0x000fd8: 20000000 0000 4027 - NPU_SET_OP_SCALAR                  0, scalar = 536870912
0x000fe0:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x000fe4:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000fe8:          0001 011f - NPU_SET_OFM_REGION                 1, region = 1
0x000fec:          8049 0185 - NPU_SET_IFM2_PRECISION         32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x000ff0:          0000 018f - NPU_SET_IFM2_REGION                0, region = 0
0x000ff4:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x000ff8:          0008 0108 - NPU_SET_IFM_BROADCAST              8, broadcast_mode = BROADCAST_MODE_SCALAR
0x000ffc:          0002 0006 - NPU_OP_ELEMENTWISE                 2, elementwise_mode = ELEMENTWISE_MODE_SUB
// Mul , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x001000: 00000001 0000 4025 - NPU_SET_IFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x001008: 00000001 0000 4026 - NPU_SET_IFM2_SCALE                 0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x001010: 40000000 001f 4024 - NPU_SET_OFM_SCALE                 31, shift = 31, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1073741824
0x001018:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x00101c:          0001 010f - NPU_SET_IFM_REGION                 1, region = 1
0x001020: 00000100 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x100
0x001028: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x001030: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x001038: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x001040:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x001044:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x001048:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x00104c: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x001054: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x00105c: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x001064:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x001068:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x00106c:          0002 011f - NPU_SET_OFM_REGION                 2, region = 2
0x001070:          8049 0185 - NPU_SET_IFM2_PRECISION         32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x001074:          0001 018f - NPU_SET_IFM2_REGION                1, region = 1
0x001078:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x00107c:          0000 0108 - NPU_SET_IFM_BROADCAST              0, broadcast_mode = BROADCAST_MODE_NONE
0x001080:          0000 0006 - NPU_OP_ELEMENTWISE                 0, elementwise_mode = ELEMENTWISE_MODE_MUL
// Mul , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x001084: 00000001 0000 4024 - NPU_SET_OFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1
0x00108c:          8049 0105 - NPU_SET_IFM_PRECISION          32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x001090:          0002 010f - NPU_SET_IFM_REGION                 2, region = 2
0x001094:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x001098:          0145 0114 - NPU_SET_OFM_PRECISION            325, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x00109c:          0001 011f - NPU_SET_OFM_REGION                 1, region = 1
0x0010a0: 000000c0 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0xc0
0x0010a8:          c009 0185 - NPU_SET_IFM2_PRECISION         49161, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHWC, activation_storage = ACTIVATION_STORAGE_NONE
0x0010ac: 00000004 0000 4027 - NPU_SET_OP_SCALAR                  0, scalar = 4
0x0010b4:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x0010b8:          0008 0180 - NPU_SET_IFM2_BROADCAST             8, broadcast_mode = BROADCAST_MODE_SCALAR
0x0010bc:          0000 0006 - NPU_OP_ELEMENTWISE                 0, elementwise_mode = ELEMENTWISE_MODE_MUL
// Add , subOps: -, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x0010c0: 00000001 03c0 4025 - NPU_SET_IFM_SCALE                960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x0010c8: 00000001 03c0 4026 - NPU_SET_IFM2_SCALE               960, shift = 0, dbl_rnd = 15, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x0010d0:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x0010d4:          0001 010f - NPU_SET_IFM_REGION                 1, region = 1
0x0010d8: 00000100 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x100
0x0010e0: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x0010e8: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x0010f0: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x0010f8:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x0010fc:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x001100:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x001104: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x00110c: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x001114: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x00111c:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x001120:          0145 0114 - NPU_SET_OFM_PRECISION            325, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x001124:          0049 0185 - NPU_SET_IFM2_PRECISION            73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x001128:          0001 018f - NPU_SET_IFM2_REGION                1, region = 1
0x00112c: 000000c0 0000 4080 - NPU_SET_IFM2_BASE0                 0, addr = 0xc0
0x001134: 00000000 0000 4081 - NPU_SET_IFM2_BASE1                 0, addr = 0x0
0x00113c: 00000000 0000 4082 - NPU_SET_IFM2_BASE2                 0, addr = 0x0
0x001144: 00000000 0000 4083 - NPU_SET_IFM2_BASE3                 0, addr = 0x0
0x00114c:          0000 018b - NPU_SET_IFM2_HEIGHT0_M1            0, height_m1 = 0
0x001150:          0000 018c - NPU_SET_IFM2_HEIGHT1_M1            0, height_m1 = 0
0x001154:          0000 018a - NPU_SET_IFM2_WIDTH0_M1             0, width_m1 = 0
0x001158: 00000040 0000 4085 - NPU_SET_IFM2_STRIDE_Y              0, addr = 0x40
0x001160: 00000040 0000 4084 - NPU_SET_IFM2_STRIDE_X              0, addr = 0x40
0x001168: 00000040 0000 4086 - NPU_SET_IFM2_STRIDE_C              0, addr = 0x40
0x001170:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x001174:          0000 0180 - NPU_SET_IFM2_BROADCAST             0, broadcast_mode = BROADCAST_MODE_NONE
0x001178:          0001 0006 - NPU_OP_ELEMENTWISE                 1, elementwise_mode = ELEMENTWISE_MODE_ADD
// Mul , subOps: Asr, size=1,1 stride=1,1, dilation=1,1 padding=[t:0,l:0,b:0,r:0,n:0,f:0] OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x00117c: 00000001 0000 4025 - NPU_SET_IFM_SCALE                  0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x001184: 00000001 0000 4026 - NPU_SET_IFM2_SCALE                 0, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_IFM_DOUBLE_SYMMETRIC, scale = 1
0x00118c: 40000000 001e 4024 - NPU_SET_OFM_SCALE                 30, shift = 30, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_DOUBLE_SYMMETRIC, scale = 1073741824
0x001194:          0049 0105 - NPU_SET_IFM_PRECISION             73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x001198:          0001 010f - NPU_SET_IFM_REGION                 1, region = 1
0x00119c: 00000000 0000 4000 - NPU_SET_IFM_BASE0                  0, addr = 0x0
0x0011a4: 00000000 0000 4001 - NPU_SET_IFM_BASE1                  0, addr = 0x0
0x0011ac: 00000000 0000 4002 - NPU_SET_IFM_BASE2                  0, addr = 0x0
0x0011b4: 00000000 0000 4003 - NPU_SET_IFM_BASE3                  0, addr = 0x0
0x0011bc:          0000 010b - NPU_SET_IFM_HEIGHT0_M1             0, height_m1 = 0
0x0011c0:          0000 010c - NPU_SET_IFM_HEIGHT1_M1             0, height_m1 = 0
0x0011c4:          0000 010a - NPU_SET_IFM_WIDTH0_M1              0, width_m1 = 0
0x0011c8:          000b 0104 - NPU_SET_IFM_DEPTH_M1              11, depth_m1 = 11
0x0011cc: 00000040 0000 4005 - NPU_SET_IFM_STRIDE_Y               0, addr = 0x40
0x0011d4: 00000040 0000 4004 - NPU_SET_IFM_STRIDE_X               0, addr = 0x40
0x0011dc: 00000040 0000 4006 - NPU_SET_IFM_STRIDE_C               0, addr = 0x40
0x0011e4:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x0011e8:          8145 0114 - NPU_SET_OFM_PRECISION          33093, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_CHAINED
0x0011ec:          0000 011f - NPU_SET_OFM_REGION                 0, region = 0
0x0011f0:          000b 0113 - NPU_SET_OFM_DEPTH_M1              11, depth_m1 = 11
0x0011f4:          0049 0185 - NPU_SET_IFM2_PRECISION            73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x0011f8:          0001 018f - NPU_SET_IFM2_REGION                1, region = 1
0x0011fc: 000000c0 0000 4080 - NPU_SET_IFM2_BASE0                 0, addr = 0xc0
0x001204: 00000000 0000 4081 - NPU_SET_IFM2_BASE1                 0, addr = 0x0
0x00120c: 00000000 0000 4082 - NPU_SET_IFM2_BASE2                 0, addr = 0x0
0x001214: 00000000 0000 4083 - NPU_SET_IFM2_BASE3                 0, addr = 0x0
0x00121c:          0000 018b - NPU_SET_IFM2_HEIGHT0_M1            0, height_m1 = 0
0x001220:          0000 018c - NPU_SET_IFM2_HEIGHT1_M1            0, height_m1 = 0
0x001224:          0000 018a - NPU_SET_IFM2_WIDTH0_M1             0, width_m1 = 0
0x001228: 00000040 0000 4085 - NPU_SET_IFM2_STRIDE_Y              0, addr = 0x40
0x001230: 00000040 0000 4084 - NPU_SET_IFM2_STRIDE_X              0, addr = 0x40
0x001238: 00000040 0000 4086 - NPU_SET_IFM2_STRIDE_C              0, addr = 0x40
0x001240:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x001244:          0004 0180 - NPU_SET_IFM2_BROADCAST             4, broadcast_mode = BROADCAST_MODE_C
0x001248:          0000 0006 - NPU_OP_ELEMENTWISE                 0, elementwise_mode = ELEMENTWISE_MODE_MUL
// Asr , subOps: -,  OFM Block=[1, 32, 16], IFM Block=[1, 32, 16], OFM UBlock=[1, 2, 16] Traversal=DepthFirst, AccType=Acc32
0x00124c: 00000001 2000 4024 - NPU_SET_OFM_SCALE               8192, shift = 0, dbl_rnd = 0, round_mode = ROUND_MODE_OFM_NATURAL, scale = 1
0x001254:          8049 0105 - NPU_SET_IFM_PRECISION          32841, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_CHAINED
0x001258:          0000 010f - NPU_SET_IFM_REGION                 0, region = 0
0x00125c:          0000 0109 - NPU_SET_IFM_ZERO_POINT             0, zero_point = 0
0x001260:          0101 0114 - NPU_SET_OFM_PRECISION            257, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B8, activation_format = ACTIVATION_FORMAT_NHWC, scale_mode = OFM_SCALE_MODE_GLOBAL, activation_reverse = ACTIVATION_REVERSE_NONE, activation_transpose = ACTIVATION_TRANSPOSE_HWC, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x001264:          0001 011f - NPU_SET_OFM_REGION                 1, region = 1
0x001268: 00000080 0000 4010 - NPU_SET_OFM_BASE0                  0, addr = 0x80
0x001270: 0000000c 0000 4015 - NPU_SET_OFM_STRIDE_Y               0, addr = 0xc
0x001278: 0000000c 0000 4014 - NPU_SET_OFM_STRIDE_X               0, addr = 0xc
0x001280: 00000001 0000 4016 - NPU_SET_OFM_STRIDE_C               0, addr = 0x1
0x001288:          ff80 0118 - NPU_SET_OFM_ZERO_POINT         65408, zero_point = 65408
0x00128c:          0000 0125 - NPU_SET_ACTIVATION                 0, activation_function = ACTIVATION_FUNCTION_LUT_NONE, table = 0, activation_clip_range = ACTIVATION_CLIP_RANGE_B16
0x001290:          ff80 0126 - NPU_SET_ACTIVATION_MIN         65408, clip_boundary = 65408
0x001294:          007f 0127 - NPU_SET_ACTIVATION_MAX           127, clip_boundary = 127
0x001298:          0049 0185 - NPU_SET_IFM2_PRECISION            73, activation_type = ACTIVATION_TYPE_SIGNED, activation_precision = ACTIVATION_PRECISION_B32, activation_format = ACTIVATION_FORMAT_NHCWB16, activation_storage = ACTIVATION_STORAGE_TILE2X2
0x00129c:          0001 018f - NPU_SET_IFM2_REGION                1, region = 1
0x0012a0: 00000040 0000 4080 - NPU_SET_IFM2_BASE0                 0, addr = 0x40
0x0012a8: 00000000 0000 4081 - NPU_SET_IFM2_BASE1                 0, addr = 0x0
0x0012b0: 00000000 0000 4082 - NPU_SET_IFM2_BASE2                 0, addr = 0x0
0x0012b8: 00000000 0000 4083 - NPU_SET_IFM2_BASE3                 0, addr = 0x0
0x0012c0:          0000 018b - NPU_SET_IFM2_HEIGHT0_M1            0, height_m1 = 0
0x0012c4:          0000 018c - NPU_SET_IFM2_HEIGHT1_M1            0, height_m1 = 0
0x0012c8:          0000 018a - NPU_SET_IFM2_WIDTH0_M1             0, width_m1 = 0
0x0012cc: 00000040 0000 4085 - NPU_SET_IFM2_STRIDE_Y              0, addr = 0x40
0x0012d4: 00000040 0000 4084 - NPU_SET_IFM2_STRIDE_X              0, addr = 0x40
0x0012dc: 00000040 0000 4086 - NPU_SET_IFM2_STRIDE_C              0, addr = 0x40
0x0012e4:          0000 0189 - NPU_SET_IFM2_ZERO_POINT            0, zero_point = 0
0x0012e8:          0008 0006 - NPU_OP_ELEMENTWISE                 8, elementwise_mode = ELEMENTWISE_MODE_SHR
0x0012ec:          ffff 0000 - NPU_OP_STOP                    65535, mask = 65535
Info: Changing const_mem_area from Sram to OnChipFlash. This will use the same characteristics as Sram.
Configuration files:
   original = ['bobby.ini']
   used = ['bobby.ini']
System Configuration (AmbiqLP):
   core_clock = 100000000.0
   axi0_port = Sram
   axi1_port = OnChipFlash
   Sram_clock_scales = 1.0
   Sram_burst_length = 64
   Sram_read_latency = 9
   Sram_write_latency = 9
   Dram_clock_scales = 1.0
   Dram_burst_length = 128
   Dram_read_latency = 9
   Dram_write_latency = 9
   OnChipFlash_clock_scales = 1.0
   OnChipFlash_burst_length = 64
   OnChipFlash_read_latency = 9
   OnChipFlash_write_latency = 9
   OffChipFlash_clock_scales = 1.0
   OffChipFlash_burst_length = 1
   OffChipFlash_read_latency = 0
   OffChipFlash_write_latency = 0
Memory Mode (Sram_Only):
   const_mem_area = Axi1
   arena_mem_area = Axi0
   cache_mem_area = Axi0
   arena_cache_size = 1099511627776 from Default
Architecture Settings:
   permanent_storage_mem_area = OnChipFlash
   feature_map_storage_mem_area = Sram
   fast_storage_mem_area = Sram

################################################################################
Performance for NPU Grap output/kws_ref_model_aligned
Original Operator    NNG Operator         Target Staging Usage  Peak% (Staging)  Op Cycles Network% (cycles)        NPU    SRAM AC    DRAM AC OnFlash AC OffFlash AC  MAC Count Network% (MAC)  Util% (MAC) Name                 
-------------------- -------------------- ------ ------------- ---------------- ---------- ----------------- ---------- ---------- ---------- ---------- ----------- ---------- -------------- ------------ -------------------- 
Conv2D               Conv2D               NPU             8496             8.99       6425             16.30       6425       5503          0          0           0     160000           6.39         9.73 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1 
Conv2D               Relu                 NPU             8496             8.99       5200             13.19       5200       1000          0          0           0       8000           0.32         0.60 functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1 
DepthwiseConv2D      DepthwiseConv2D      NPU            16000            16.93       5000             12.68       5000        541          0          0           0      72000           2.87         5.62 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1 
DepthwiseConv2D      Relu                 NPU            16000            16.93       6500             16.49       6500        500          0          0           0       8000           0.32         0.48 functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1 
Conv2D               Conv2D               NPU            16000            16.93       2512              6.37       2512       1870          0          0           0     512000          20.44        79.62 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1 
Conv2D               Relu                 NPU            16000            16.93       4512             11.45       4512        762          0          0           0       8000           0.32         0.69 functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1 
DepthwiseConv2D      DepthwiseConv2D      NPU            16000            16.93       5000             12.68       5000        540          0          0           0      72000           2.87         5.62 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1 
DepthwiseConv2D      Relu                 NPU            16000            16.93       6500             16.49       6500        500          0          0           0       8000           0.32         0.48 functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1 
Conv2D               Conv2D               NPU            16000            16.93       2512              6.37       2512       1870          0          0           0     512000          20.44        79.62 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1 
Conv2D               Relu                 NPU            16000            16.93       4512             11.45       4512        762          0          0           0       8000           0.32         0.69 functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1 
DepthwiseConv2D      DepthwiseConv2D      NPU            16000            16.93       5000             12.68       5000        540          0          0           0      72000           2.87         5.62 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1 
DepthwiseConv2D      Relu                 NPU            16000            16.93       6500             16.49       6500        500          0          0           0       8000           0.32         0.48 functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1 
Conv2D               Conv2D               NPU            16000            16.93       2512              6.37       2512       1870          0          0           0     512000          20.44        79.62 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1 
Conv2D               Relu                 NPU            16000            16.93       4512             11.45       4512        762          0          0           0       8000           0.32         0.69 functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1 
DepthwiseConv2D      DepthwiseConv2D      NPU            16000            16.93       5000             12.68       5000        540          0          0           0      72000           2.87         5.62 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1 
DepthwiseConv2D      Relu                 NPU            16000            16.93       6500             16.49       6500        500          0          0           0       8000           0.32         0.48 functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1 
Conv2D               Conv2D               NPU            16000            16.93       2512              6.37       2512       1870          0          0           0     512000          20.44        79.62 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1 
Conv2D               Relu                 NPU            16000            16.93       4512             11.45       4512        762          0          0           0       8000           0.32         0.69 functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1 
AvgPool              AvgPool              NPU             8064             8.53       2529              6.42       2529        324          0          0           0       8000           0.32         1.24 functional_1/average_pooling2d/AvgPool 
FullyConnected       FullyConnected       NPU               80             0.08         86              0.22         86         41          0          0           0        768           0.03         3.49 functional_1/dense/BiasAdd 
Softmax              MaxPool              NPU               32             0.03         69              0.18         69          3          0          0           0         12           0.00         0.07 functional_1/dense/BiasAdd/maxpool 
Softmax              Sub                  NPU               96             0.10          4              0.01          4          2          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut 
Softmax              LUT                  NPU               96             0.10       1048              2.66       1048          1          0          0           0         12           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut 
Softmax              Asr                  NPU              112             0.12          3              0.01          3          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr 
Softmax              ReduceSum            NPU              176             0.19        167              0.42        167          0          0          0           0         12           0.00         0.03 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum 
Softmax              CLZ                  NPU              192             0.20          4              0.01          4          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ 
Softmax              Sub                  NPU              256             0.27          4              0.01          4          0          0          0           0          0           0.00         0.00 headroom_offset/Sub  
Softmax              Sub                  NPU              320             0.34          4              0.01          4          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/CLZ/Sub 
Softmax              SHL                  NPU              320             0.34          4              0.01          4          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL 
Softmax              Mul                  NPU              256             0.27          4              0.01          4          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul 
Softmax              Add                  NPU              256             0.27          4              0.01          4          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add 
Softmax              Mul                  NPU              320             0.34          4              0.01          4          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul 
Softmax              Sub                  NPU              320             0.34          4              0.01          4          0          0          0           0          0           0.00         0.00 F2_one/Sub           
Softmax              Mul                  NPU              320             0.34          4              0.01          4          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul 
Softmax              Mul                  NPU              320             0.34          4              0.01          4          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Mul/Mul 
Softmax              Add                  NPU              320             0.34          4              0.01          4          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add 
Softmax              Mul                  NPU              320             0.34          4              0.01          4          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul 
Softmax              Sub                  NPU              320             0.34          4              0.01          4          0          0          0           0          0           0.00         0.00 F2_one/Sub           
Softmax              Mul                  NPU              320             0.34          4              0.01          4          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul 
Softmax              Mul                  NPU              320             0.34          4              0.01          4          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Mul/Mul 
Softmax              Add                  NPU              320             0.34          4              0.01          4          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add 
Softmax              Mul                  NPU              320             0.34          4              0.01          4          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul 
Softmax              Sub                  NPU              320             0.34          4              0.01          4          0          0          0           0          0           0.00         0.00 F2_one/Sub           
Softmax              Mul                  NPU              320             0.34          4              0.01          4          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul 
Softmax              Mul                  NPU              320             0.34          4              0.01          4          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Mul/Mul 
Softmax              Add                  NPU              256             0.27          4              0.01          4          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Asr/reducesum/SHL/Mul/Add/Add/Add/Add 
Softmax              Mul                  NPU              208             0.22          4              0.01          4          1          0          0           0          0           0.00         0.00 functional_1/dense/BiasAdd/Sub/lut/Mul 
Softmax              Asr                  NPU              208             0.22          3              0.01          3          2          0          0           0          0           0.00         0.00 Identity             

Network summary for kws_ref_model_aligned
Accelerator configuration               Ethos_U85_256
System configuration                          AmbiqLP
Memory mode                                 Sram_Only
Accelerator clock                                 100 MHz
Design peak SRAM bandwidth                       2.98 GB/s

Total SRAM used                                 92.28 KiB

CPU operators = 0 (0.0%)
NPU operators = 38 (100.0%)

Average SRAM bandwidth                           1.20 GB/s
Input   SRAM bandwidth                           0.18 MB/batch
Weight  SRAM bandwidth                           0.21 MB/batch
Output  SRAM bandwidth                           0.07 MB/batch
Total   SRAM bandwidth                           0.47 MB/batch
Total   SRAM bandwidth            per input      0.47 MB/inference (batch size 1)

Original Weights Size                           21.50 KiB
NPU Encoded Weights Size                        69.77 KiB

Neural network macs                           2504792 MACs/batch

Info: The numbers below are internal compiler estimates.
For performance numbers the compiled network should be run on an FVP Model or FPGA.

Network Tops/s                                   0.01 Tops/s

NPU cycles                                      39422 cycles/batch
SRAM Access cycles                              15721 cycles/batch
DRAM Access cycles                                  0 cycles/batch
On-chip Flash Access cycles                         0 cycles/batch
Off-chip Flash Access cycles                        0 cycles/batch
Total cycles                                    39422 cycles/batch

Batch Inference time                 0.39 ms, 2536.65 inferences/s (batch size 1)

